{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"Welcome to Elysia","text":"<p>Elysia is an agentic platform designed to use tools in a decision tree. A decision agent decides which tools to use dynamically based on its environment and context. You can use custom tools or use the pre-built tools designed to retrieve your data in a Weaviate cluster.</p> <p>See the basic example to get started right away! Or if you want to make your own tools and customise Elysia, see how to easily add your own tools.</p>"},{"location":"#get-started","title":"Get Started","text":"<p>To use Elysia, you need to either set up your models and API keys in your <code>.env</code> file, or specify them in the config. See the setup page to get started.</p> <p>Elysia can be used very simply: <pre><code>from elysia import tool, Tree\n\ntree = Tree()\n\n@tool(tree=tree)\nasync def add(x: int, y: int) -&gt; int:\n    return x + y\n\ntree(\"What is the sum of 9009 and 6006?\")\n</code></pre></p> <p>Elysia is pre-configured to be capable of connecting to and interacting with your Weaviate clusters! <pre><code>from elysia import Tree\ntree = Tree()\nresponse, objects = tree(\n    \"What are the 10 most expensive items in the Ecommerce collection?\",\n    collection_names = [\"Ecommerce\"]\n)\n</code></pre> This will use the built-in open source query tool or aggregate tool to interact with your Weaviate collections. To get started connecting to Weaviate, see the setting up page.</p>"},{"location":"#installation","title":"Installation","text":"<pre><code>pip install elysia-ai\n</code></pre>"},{"location":"#usage","title":"Usage","text":"<p>Elysia is free, open source, and available to anyone.</p> <p>Unlike other agent-based packages, Elysia is pre-configured to run a wide range of tools and has a lot of capabilities straight away. For example, you could just call Elysia on your Weaviate collections and it will immediately and dynamically search your data, using custom queries with filters or aggregations.</p> <p>Or you could customise Elysia to your liking, create your own custom tools and add them to the Elysia decision tree.</p> <p>To use Elysia to search your data, you need a Weaviate cluster (or you can define your own custom tool to search another data source!).</p> <p>Sign up to Weaviate! A 14 day sandbox cluster is free.</p> <p>For more information on signing up to Weaviate, click here. </p> <p>From your weaviate cluster, you can upload data via a CSV on the cloud console, or you can upload via the Weaviate APIs.</p>"},{"location":"#about","title":"About","text":"<p>Check out the Github Repositories for the backend and the frontend</p> <ul> <li> <p>elysia (backend)</p> </li> <li> <p>elysia-frontend (frontend)</p> </li> </ul> <p>Elysia was developed by Edward Schmuhl (frontend) and Danny Williams (backend). Check out our socials below:</p> <ul> <li> <p>Edward's Linkedin</p> </li> <li> <p>Danny's Linkedin</p> </li> </ul> <p>Documentation built with mkdocs.</p>"},{"location":"advanced_usage/","title":"Customising the Elysia Decision Tree","text":"<p>If you haven't followed the basic guide yet, check that out first before you go into more detail here.</p> <p>See the setup page for details on setting up models and API keys.</p>"},{"location":"advanced_usage/#changing-the-style-agent-description-or-end-goal","title":"Changing the Style, Agent Description or End Goal","text":"<p>You can initialise these parameters at the startup of the tree, for example <pre><code>from elysia import Tree\ntree = Tree(\n    style = \"...\",\n    agent_description = \"...\",\n    end_goal = \"...\"\n)\n</code></pre> Each of these options is described below.</p>"},{"location":"advanced_usage/#style","title":"Style","text":"<p>You can customise the style of Elysia's text responses by either initialising the decision tree with the <code>style</code> argument,  or creating a tree and then modifying the style later. <pre><code>tree = Tree()\ntree.change_style(\"Always speak in rhyming couplets.\")\n</code></pre></p> <p>You should see the changes in Elysia's textual responses! <pre><code>response, _ = tree(\"Hi Elysia, how are you?\")\nprint(response)\n</code></pre> <pre><code>## Hello there, it's Elly, I'm doing fine, I hope you are as well, in this rhyme!\n</code></pre></p>"},{"location":"advanced_usage/#agent-description","title":"Agent Description","text":"<p>The <code>agent_description</code> parameter in Elysia assigns the agent a unique identity, which you can use to customise the objective of the agent. </p> <p>Change this via <code>change_agent_description</code>, e.g. <pre><code>tree.change_agent_description(\"You are a travel agent, specialised in creating unique travel plans for customers that interact with you.\")\n</code></pre></p>"},{"location":"advanced_usage/#end-goal","title":"End Goal","text":"<p>The <code>end_goal</code> parameter describes to Elysia what criteria it will use to decide when the decision tree should end. Normally, this is something similar to 'When you have either achieved all the user has asked of you, or you can no longer do any actions that have not failed already, and you have no other options to explore.'. But this could be unique to your use case, for example, <pre><code>tree.change_end_goal(\"The user has been recommended a hotel, travel options as well as activities to do in the local area. Or, you have exhausted all options. Or, you have asked the user for more clarification about their request.\")\n</code></pre></p>"},{"location":"advanced_usage/#creating-a-title","title":"Creating a Title","text":"<p>You can run <code>tree.create_conversation_title()</code> to use the base LM in the tree to create a title for the conversation (which uses the conversation history as inspiration). This saves the title as the <code>tree.conversation_title</code> attribute, which you can also directly overwrite or access if needed. An async version of this method is available at <code>tree.create_conversation_title_async()</code>.</p>"},{"location":"advanced_usage/#loading-and-saving-trees","title":"Loading and Saving Trees","text":""},{"location":"advanced_usage/#locally","title":"Locally","text":"<p>You can export a decision tree to a JSON serialisable dictionary object via <code>tree.export_to_json()</code>. This saves certain aspects, including:</p> <ul> <li>The Tree Data, which includes:<ul> <li>The environment, including all retrieved objects from previous tool runs or otherwise</li> <li>The collection metadata, if processed</li> </ul> </li> <li>Class variables used to initialise the tree</li> <li>The config options, such as the settings (including the model choices) and the style, agent description and end goal.</li> <li>The branch initialisation, which will be re-run when the tree is loaded.</li> </ul> <p>The tree can be loaded from the dictionary via running the <code>Tree.import_from_json(json_data=...)</code> method, passing as the first argument <code>json_data</code> which is the output from <code>tree.export_to_json()</code>.</p> <p>Note that any custom tools or branches added to the decision tree are not saved and need to be manually re-added, in the same way that your tree was originally initialised.</p>"},{"location":"advanced_usage/#with-weaviate","title":"With Weaviate","text":"<p>Also included are two similar functions for saving and loading a decision tree within a Weaviate instance. To save a tree in a Weaviate instance, you can use <code>tree.export_to_weaviate(collection_name, client_manager)</code>. You can specify the collection that you will be saving to via the <code>collection_name</code> argument. You can specify the Weaviate cluster information by passing a <code>ClientManager</code>. If you do not provide a ClientManager, it will automatically create one from the specification set in the environment variables. It will save the tree according to the <code>conversation_id</code> used to initialise the tree (which is randomly generated via a UUID if not set).</p> <p>To load a tree from Weaviate, you can use the class method <code>Tree.import_from_weaviate(collection_name, conversation_id, client_manager)</code>. You must use the correct <code>conversation_id</code> to load a tree. If you do not know the conversation ID, you can view all available conversation IDs saved to a Weaviate collection via <pre><code>from elysia.tree.util import get_saved_trees_weaviate\nget_saved_trees_weaviate()\n</code></pre> Which will return a dictionary whose keys correspond to the available conversation IDs, and whose values are the titles as strings of the conversations (if one was created via <code>tree.create_conversation_title()</code>).</p> <p>Note that any custom tools or branches added to the decision tree are not saved and need to be manually re-added, in the same way that your tree was originally initialised.</p>"},{"location":"basic/","title":"Basic Example","text":"<p>Let's assume we have access to the following Weaviate collections:</p> <ul> <li> <p><code>ecommerce</code>: a fashion dataset with fields such as <code>price</code>, <code>category</code>, <code>description</code>, etc.</p> </li> <li> <p><code>ml_wikipedia</code>: a collection of long Wikipedia articles related to machine learning, with fields such as <code>categories</code>, <code>content</code>, <code>title</code> etc.</p> </li> <li> <p><code>Tickets</code>: Github issues for a fictional company</p> </li> </ul> <p>These Weaviate collections are those which we want to search over using Elysia.</p>"},{"location":"basic/#setup","title":"Setup","text":"<p>You need to specify what models you want to use, as well as any API keys. To set up the models, you can use <code>configure</code>. For example, if you want to use the GPT-4o family of models:</p> <pre><code>from elysia import configure\nconfigure(\n    base_model=\"gpt-4o-mini\",\n    base_provider=\"openai\",\n    complex_model=\"gpt-4o\",\n    complex_provider=\"openai\",\n    openai_api_key=\"sk-...\", # replace with your API key\n    wcd_url=\"...\",    # replace with your weaviate cloud url\n    wcd_api_key=\"...\" # replace with your weaviate cloud api key\n)\n</code></pre> <p>You need to specify both a <code>base_model</code> and a <code>complex_model</code>, as well as their providers. This hooks into LiteLLM through DSPy, so any LiteLLM supported models and providers will work. See the setup page for more details.</p> <p>Then for a collection to be accessible within Elysia, we need to preprocess it - so that the models are aware of the schemas and information about the collection.</p> <pre><code>from elysia import preprocess\npreprocess(\"Tickets\")\n</code></pre>"},{"location":"basic/#running-elysia","title":"Running Elysia","text":"<p>To run the Elysia decision tree, using the default setup, just call the <code>Tree</code> object!</p> <p><pre><code>from elysia import Tree\ntree = Tree()\nresponse, objects = tree(\"what were the 10 most recent Github issues?\")\n</code></pre> Elysia will dynamically run through the decision tree, choosing tools to use based on the decision agent LM based on the input. The decision tree returns the concatenation of all text responses from the models, as well as any retrieved objects (anything that was added to the environment during this call).</p> <p><pre><code>print(response)\n</code></pre> <pre><code>I will now query the Tickets collection to retrieve the 10 most recent issues for you. I applied a descending sort on the \"issue_created_at\" field to retrieve the 10 most recent issues. I will now summarize the 10 most recent Github issues for you. The latest tickets reflect ongoing discussions and developments within the Verba project. Notable entries include a closed issue regarding the use of specific model inputs, a report on a breaking change affecting the code chunker functionality, and requests for enhancements like custom JSON support and improved metadata handling during file uploads. The issues also highlight user concerns about application performance when processing large document uploads and the integration of external language models. Overall, these issues illustrate a dynamic environment with active contributions and feedback from the community.\n</code></pre> <pre><code>print(objects)\n</code></pre> <pre><code>[\n    [\n        {\n            'issue_id': 2843638219.0,\n            'issue_content': \"If you set OLLAMA_MODEL and OLLAMA_EMBED_MODEL they will be the ones suggested instead of the first on Ollama's list.\",\n            'issue_created_at': '2025-02-10T21:06:00Z',\n            'issue_labels': [],\n            'issue_url': 'https://github.com/weaviate/Verba/pull/372',\n            'issue_comments': 0.0,\n            'issue_title': 'use OLLAMA_MODEL OLLAMA_EMBED_MODEL as input suggestion when using Ollama',\n            'issue_author': 'dudanogueira',\n            'issue_updated_at': '2025-02-27T10:38:02Z',\n            'issue_state': 'closed',\n            'uuid': 'bc56b4b2fc6a541c94969721bd895a7c',\n            'ELYSIA_SUMMARY': ''\n        },\n    ...\n        {\n            'issue_id': 2845625123.0,\n            'issue_content': \"Pull request for feature #2.\",\n            'issue_created_at': '2025-01-4T22:16:05Z',\n            'issue_labels': [],\n            'issue_url': 'https://github.com/weaviate/Verba/pull/373',\n            'issue_comments': 2.0,\n            'issue_title': 'Feature PR #2',\n            'issue_author': 'thomashacker',\n            'issue_updated_at': '2025-01-15T11:06:08Z',\n            'issue_state': 'closed',\n            'uuid': '05dae4214e9050a59d4e9985892cdc10',\n            'ELYSIA_SUMMARY': ''\n        }\n    ]\n]\n</code></pre></p>"},{"location":"creating_tools/","title":"Creating a Tool","text":"<p>You can use the custom tool decorator within Elysia to very simply add a tool to the tree. For example:</p> <pre><code>from elysia import tool\n\n@tool\nasync def add(x: int, y: int) -&gt; int:\n    \"\"\"\n    Return the sum of two numbers.\n    \"\"\"\n    return x + y\n</code></pre> <p>The docstring of the function serves as the tool description, and it's important this is as detailed as possible. This tool can be added to an Elysia <code>Tree</code> via</p> <pre><code>from elysia import Tree\ntree = Tree()\ntree.add_tool(add)\n</code></pre> <p>Then when calling the tree, the decision agent should use the tool if it recognises it as the best tool for the task.</p> <p><pre><code>response, objects = tree(\"What is 1238213 + 1238213?\")\nprint(response)\n</code></pre> <pre><code>'I will calculate the sum for you using the add tool. The sum of 1238213 + 1238213 is 2476426.'\n</code></pre></p> <p>And this is all you need to do to add a tool to Elysia! Some things to note:</p> <ul> <li>Your tool must be an async function (must be defined via <code>async def</code> instead of <code>def</code>).</li> <li><code>tree.add_tool(add)</code> added this tool to the root decision node (at the base of the tree). If you are using a tree with multiple branches, you can specify which branch it is added to via <code>tree.add_tool(add, branch_id=...)</code> where <code>...</code> should be replaced with the <code>branch_id</code>.</li> <li>You can add a tool to the tree automatically via customising the decorator function, e.g.     <pre><code>@tool(tree=tree, branch_id=\"base\")\nasync def add(x: int, y: int) -&gt; int:\n    return x + y    \n</code></pre>     which will automatically add it to a pre-defined tree (<code>tree</code>) at branch ID <code>\"base\"</code>.</li> <li>Type hinting (e.g. declaring <code>x: int</code> and <code>y: int</code>) helps the LLM choose the correct input types to the function.</li> </ul>"},{"location":"creating_tools/#more-detail","title":"More Detail","text":"<p>Elysia works by adding objects to its internal environment. For example, when we called the <code>add</code> function above, it automatically added a <code>Result</code> type object to the Elysia tree environment. Any objects directly returned by the function will be added to the environment under a generic set of keys. To have more control over this, you can create your tool as an async generator function, which yields objects. For example, let's extend our basic calculator a bit further:</p> <pre><code>@tool\nasync def calculate_two_numbers(x: int, y: int):\n    \"\"\"\n    This function calculates the sum, product, and difference of two numbers.\n    \"\"\"\n    yield {\n        \"sum\": x + y,\n        \"product\": x * y,\n        \"difference\": x - y,\n    }\n    yield f\"I just performed some calculations on {x} and {y}.\"\n</code></pre> <p>This now returns two items to the decision tree, a string and a dictionary. There is no limit to the amount of objects you can yield. </p> <p>When a string is returned, it automatically becomes a response from Elysia, so it will be displayed to the user as if the agent is talking back to them. When any other type of item is yielded, it becomes a <code>Result</code> type object which means it becomes part of the tree's environment. Yielding or returning a dictionary means you can customise what specific object is added to the environment. Returning or yielding a list of dictionaries will add multiple objects to the <code>Result</code>. You can also return or yield one or more <code>Result</code> objects directly.</p>"},{"location":"creating_tools/#assigning-inputs","title":"Assigning Inputs","text":"<p>The decision agent LLM is responsible for choosing the correct inputs to the tool. Any inputs added to the declaration of your tool will be automatically chosen by the LLM. Let's extend the calculator even more:</p> <pre><code>from math import prod\n@tool\nasync def perform_mathematical_operations(numbers: list[int | float], operation: str = \"sum\"):\n    \"\"\"\n    This function calculates a mathematical operation on the `numbers` list.\n    The `numbers` input must be a list of integers or floats.\n    The `operation` input must be one of: \"sum\" or \"product\". These are the only options.\n    \"\"\"\n\n    if operation == \"sum\":\n        yield sum(numbers)\n    elif operation == \"product\":\n        yield prod(numbers)\n\n    yield f\"I just performed a {operation} on {numbers}.\"    \n</code></pre> <p>Now the LLM should choose the operation in addition to the numbers. We also extended it so that the values can be a list of integers or floats, not just two numbers. The default argument, indicated by <code>operation: str = \"sum\"</code>, give the decision agent awareness of what the default argument for that particular input is - and it is no longer a required input and can be ignored, in which case the default argument is used. Note how the tool description details the descriptions of each input. In more advanced tool construction, you can assign descriptions to each input separately.</p>"},{"location":"creating_tools/#advanced-features","title":"Advanced Features","text":"<p>If your tool may error, then you can return or yield a custom Elysia <code>Error</code> object which will not cause a halt in the execution of the program. Instead, the error message will be logged in the decision tree for which the decision agent can judge whether the error is avoidable on another run of the tool. For example, if our decision agent tries to choose the wrong <code>operation</code> in the above <code>perform_mathematical_operations</code> tool, we can do something like this: <pre><code>from elysia import Error\n@tool\nasync def perform_mathematical_operations(numbers: list[int | float], operation: str = \"sum\"):\n    \"\"\"\n    This function calculates a mathematical operation on the `numbers` list.\n    The `numbers` input must be a list of integers or floats.\n    The `operation` input must be one of: \"sum\" or \"product\". These are the only options.\n    \"\"\"\n\n    if operation == \"sum\":\n        yield sum(numbers)\n    elif operation == \"product\":\n        yield prod(numbers)\n    else:\n        # This will return an error back to the decision tree\n        yield Error(f\"You picked the input {operation}, but it was not in the available operations: 'sum' or 'product'\")\n        return # Then return out of the tool early\n\n    yield f\"I just performed a {operation} on {numbers}.\"    \n</code></pre></p> <p>Finally, tools can interact with Elysia's environment, LMs and the Weaviate client through specific inputs to the function. To use the <code>TreeData</code> class, you can use the argument <code>tree_data</code> in the function signature (for which you can access the Elysia environment). Likewise, for the base LM you can use <code>base_lm</code>, for the complex LM you can use <code>complex_lm</code> and for the Client Manager you can use <code>client_manager</code>. For example:</p> <pre><code>@tool\nasync def some_tool(\n    tree_data, base_lm, complex_lm, tree_data, # these inputs are automatically assigned as Elysia variables\n    x: str, y: int # these inputs are not assigned automatically and get assigned by the decision agent\n):\n    # do something\n    pass\n</code></pre> <p>All optional arguments you can pass to the <code>@tool</code> decorator are:</p> <ul> <li><code>tree</code> (<code>Tree</code>): the tree that you will automatically add the tool to.</li> <li><code>branch_id</code> (<code>str</code>): the ID of the branch on the tree to add the tool to.</li> <li><code>status</code> (<code>str</code>): a custom message to display whilst the tool is running.</li> <li><code>end</code> (<code>bool</code>): when <code>True</code>, this tool can be the end of the conversation if the decision agent decides it should end after the completion of this tool.</li> </ul>"},{"location":"setting_up/","title":"Setting up Elysia","text":"<p>Elysia requires setting up your LMs and API keys for the decision tree functionality to work. Additionally, to use Elysia to its full potential (adaptively searching and retrieving Weaviate data), it requires a preprocessing step.</p> <p>Elysia can be configured in three different ways: via the configure function, by creating a Settings object, or by setting environment variables (in a <code>.env</code> file).</p>"},{"location":"setting_up/#model-setup","title":"Model Setup","text":"<p>Elysia uses two language models for different types of tasks;</p> <ul> <li>The base model is responsible for the decision agent, as well as any tools that specify its use.</li> <li>The complex model is used for more complex tasks, and is responsible for any tools that specify its use (such as the inbuilt query and aggregate tools).</li> </ul>"},{"location":"setting_up/#configuring-models","title":"Configuring Models","text":"<p>To configure different LMs as default for all functions within Elysia, you can use the global <code>configure</code> function. For example, to use the GPT family of models, you can set:</p> <p><pre><code>from elysia import configure\n\nconfigure(\n    base_model=\"gpt-4.1-mini\",\n    base_provider=\"openai\",\n    complex_model=\"gpt-4.1\",\n    complex_provider=\"openai\",\n    openai_api_key=\"...\" # replace with your API key\n)\n</code></pre> The <code>configure</code> function can be used to specify both the <code>base_model</code> and <code>complex_model</code>. Both require separately setting a provider; in this case <code>openai</code> Instead, you can create your own <code>Settings</code> object which can be passed to any of the Elysia functions that use LMs to have a separate settings instance for each initialisation. E.g.,</p> <p><pre><code>from elysia import Settings, Tree\nmy_settings = Settings()\ntree = Tree(settings=my_settings)\n</code></pre> This tree will use the <code>my_settings</code> object instead of the global one. If not specified, it will use the global settings. You can configure <code>my_settings</code> manually, either by <code>my_settings.configure(...)</code> (which takes exactly the same arguments as <code>configure</code>), or by using <code>my_settings.smart_setup()</code>, which uses recommended models based on the API keys and/or models set in the <code>.env</code> file, prioritising Gemini 2.0 Flash for the base and complex model. See the reference page for more details.</p> <p>The third alternative: you can set everything in advance via creating a <code>.env</code> file in the root directory of your working directory, including the models, providers, and api keys. For example:</p> <pre><code>BASE_MODEL=gpt-4.1-mini\nBASE_PROVIDER=openai\nCOMPLEX_MODEL=gpt-4.1\nCOMPLEX_PROVIDER=anthropic\nOPENAI_API_KEY=... # replace with your OpenAI API key\n</code></pre> <p>Then, the global <code>settings</code> object will always use these values, and the <code>smart_setup()</code> or <code>my_settings.smart_setup()</code> (local settings object) will use these models and providers instead of the recommended ones.</p>"},{"location":"setting_up/#local-model-integration-via-ollama","title":"Local Model Integration via Ollama","text":"<p>First, make sure your Ollama server is running either via the Ollama app or <code>ollama run &lt;model_name&gt;</code>. E.g., <code>ollama run gpt-oss:20b</code>, which we'll use in this example. Within Python, you can configure your model API base to your Ollama api endpoint (default to <code>http://localhost:11434</code>) via the <code>model_api_base</code> parameter of <code>configure</code>.</p> <pre><code>from elysia import configure\nconfigure(\n    base_provider=\"ollama\",\n    complex_provider=\"ollama\",\n    base_model=\"gpt-oss:20b\",\n    complex_model=\"gpt-oss:20b\",\n    model_api_base=\"http://localhost:11434\",\n)\n</code></pre> <p>On the app side, this is configurable via the 'Api Base URL' parameter in the Settings. Set both of your providers to <code>ollama</code>, and your base and complex model to whatever model you are currently hosting, and this should work out-of-the-box.</p> <p>Warning: Elysia uses a long context, quite long context, due to the nature of the collection schemas, environment and more being included in every prompt. So these models will run quite slowly. However, on the backend, you can configure this to be faster by disabling connection to your Weaviate cluster, if applicable, by removing your weaviate api key and url. Also, there is an optional setting <pre><code>settings.configure(\n    base_use_reasoning=False,\n    complex_use_reasoning=False\n)\n</code></pre> which will remove chain of thought prompting for the base and complex model, respectively. Use this with caution though, as it will degrade accuracy significantly. Additionally, some smaller models struggle with the complex nature of multiple outputs in DSPy and Elysia, so you might encounter some errors. In testing, the <code>gpt-oss</code> models work relatively well.</p>"},{"location":"setting_up/#weaviate-integration","title":"Weaviate Integration","text":"<p>To use Elysia with Weaviate, you need to specify your Weaviate cluster details. These can be set via the Weaviate Cluster URL (<code>WCD_URL</code>) and the Weaviate Cluster API Key (<code>WCD_API_KEY</code>). To set these values, you can use <code>configure</code> on the settings: <pre><code>from elysia import configure\nconfigure(\n    wcd_url=..., # replace with your WCD_URL\n    wcd_api_key=... # replace with your WCD_API_KEY\n)\n</code></pre> or by setting them as environment variables <pre><code>WCD_URL=... # replace with your WCD_URL\nWCD_API_KEY=... # replace with your WCD_API_KEY\n</code></pre></p> <p>Additionally, you need to preprocess your collections for Elysia to use the built in Weaviate-based tools, see below for details.</p> <p>*Note: using a local Weaviate instance is currently not supported. This is coming soon! You can sign up for a 14-day sandbox for free.</p>"},{"location":"setting_up/#preprocessing-collections","title":"Preprocessing Collections","text":"<p>The <code>preprocess</code> function must be used on the Weaviate collections you plan to use within Elysia. </p> <pre><code>from elysia import preprocess\npreprocess(\"&lt;your_collection_name&gt;\")\n</code></pre> <p>Preprocessing does several things:</p> <ul> <li>Creates an LLM generated summary of the collection, including descriptions of the fields in the dataset.</li> <li>Creates 'mappings', so that fields in the collection can be mapped to frontend-specific fields. This enables the Elysia frontend app to display items from the collection when retrieved in the app.</li> <li>Calculates summary statistics, such as the mean, maximum and minimum values of number fields, as well as statistics for other fields.</li> <li>Collects other metadata such as any named vectors, what index types are used, if the inverted index is configured to index e.g. creation time.</li> </ul> <p>Since preprocessing uses LLM created summaries of the collections, you must configure your models in advance. See above for details.</p>"},{"location":"setting_up/#running-the-preprocessing-function","title":"Running the Preprocessing Function","text":"<p>You have access to two functions, <code>preprocess_async</code>, which must be awaited, and <code>preprocess</code>, which is a sync wrapper for its async sister. The basic arguments for either function are:</p> <ul> <li><code>collection_names</code> (list[str]): The names of the collections to preprocess.</li> <li><code>client_manager</code> (ClientManager): The client manager to use.     The ClientManager class is how Elysia interacts with Weaviate client.     If you are unsure of this, do not provide this argument, it will default to the Weaviate cluster you selected via the <code>Settings</code>, or via <code>configure</code>/environment variables.</li> </ul> <p>As well, the LLM requires a number of objects retrieved from the collection, at random, to help provide its summary. Since objects in collections vary greatly in token size (and hence LLM compute time/cost), you can adjust the following parameters to change how many objects are used for this sample.</p> <ul> <li><code>min_sample_size</code> (int): The minimum number of objects in the sample.</li> <li><code>max_sample_size</code> (int): The maximum number of objects to sample.</li> <li><code>num_sample_tokens</code> (int): The maximum number of tokens in the sample objects used to evaluate the summary.</li> </ul> <p>The <code>num_sample_tokens</code> parameter controls how many objects are actually used. Provided it is between <code>min_sample_size</code> and <code>max_sample_size</code>, the preprocessor will select the closest number of objects that are estimated to be in total <code>num_sample_tokens</code> tokens.</p> <p>Additionally, you have: - <code>settings</code> (Settings): The settings to use. - <code>force</code> (bool): Whether to force the preprocessor to run even if the collection already exists.</p>"},{"location":"setting_up/#additional-functions","title":"Additional Functions","text":"<p>You can also use <code>preprocessed_collection_exists</code>, which returns True/False if the collection has been preprocessed (and it can be accessed within the Weaviate cluster):</p> <p><pre><code>from elysia import preprocessed_collection_exists\npreprocessed_collection_exists(collection_name = ...)\n</code></pre> which returns True/False if the preprocess exists within this Weaviate cluster</p> <p>You can use <code>edit_preprocessed_collection</code> to update the values manually: <pre><code>from elysia import edit_preprocessed_collection\nproperties = edit_preprocessed_collection(\n    collection_name = ...,\n    named_vectors = ...,\n    summary = ...,\n    mappings = ...,\n    fields = ...\n)\n</code></pre> which will change the LLM generated values with manually input values. Any fields not provided will not be updated.</p> <p>You can use <code>delete_preprocessed_collection</code> which will delete the cached preprocessed metadata.</p> <p><pre><code>delete_preprocessed_collection(collection_name = ...) \n</code></pre> which permanently deletes the preprocessed collection (not the original collection). You will need to rerun preprocess for the original collection to be used for the Weaviate integration in Elysia again.</p>"},{"location":"API/","title":"Overview","text":"<p>Within the Elysia package, the API endpoints are included but are specific to the Elysia Frontend. </p> <p>However, there are a range of functionalities included that can be useful for using Elysia in an app environment.</p>"},{"location":"API/payload_formats/","title":"Payload Formats","text":"<p>Whenever a <code>Result</code> object is yielded from an Elysia tool or decision agent, two things happen:</p> <ol> <li>Any objects and metadata in the <code>Result</code> are automatically added to Elysia's Environment for future use in the decision tree.</li> <li>The <code>.to_frontend()</code> method of the <code>Result</code> parses the objects and metadata to a frontend-acceptable format and are yielded outside of the tree (to send payloads to a connected frontend).</li> </ol> <p>Similarly, an <code>Update</code> class also yields a payload outside of the tree, but does not add any objects to the environment.</p> <p>All payloads that are sent from the decision tree to the frontend have the same structure: <pre><code>{\n    \"type\": str, \n    \"id\": str,\n    \"user_id\": str,\n    \"conversation_id\": str, \n    \"query_id\": str,\n    \"payload\": dict\n}\n</code></pre></p> <p>Where the <code>\"payload\"</code> dictionary always contains:</p> <p><pre><code>{\n    \"type\": str, \n    \"metadata\": dict\n    \"objects\": list[dict],\n    ... # additional fields\n}\n</code></pre> where the additional fields are based on the <code>\"type\"</code> of the output. The dictionaries in the <code>list[dict]</code> of the <code>objects</code> is normally unique to each <code>\"type\"</code> that is returned, but will always include a <code>_REF_ID</code> field containing a unique identifier for its place in the Elysia environment. </p> <p>For example, any objects returned by the Elysia query tool will be mapped to specific fields that the frontend is 'aware' of. Items in the Weaviate collection that are returned are not known how to be displayed by the frontend as the fields are unique to the user's collection. So instead they are mapped to frontend-specific fields that are decided in advance by the preprocessing step before they are returned outside of the tree.</p> <ul> <li></li> </ul>"},{"location":"API/user_and_tree_managers/","title":"User Manager and Tree Manager","text":"<p>There exist two manager classes in Elysia designed to help structure and handle multiple users, each interacting with multiple decision trees. These are: - The TreeManager, which tracks and stores multiple decision trees. - The UserManager, which handles multiple <code>TreeManager</code>s per user, as well as a <code>[ClientManager](../Reference/Client.md)</code> object for each user.</p>"},{"location":"API/user_and_tree_managers/#treemanager-overview","title":"TreeManager Overview","text":"<p>The <code>TreeManager</code> is initialised with a <code>user_id</code>, which is the identifier for the user this manager is responsible for.</p> <p>The <code>TreeManager</code> includes configs options which is shared amongst all default trees in the <code>TreeManager</code>, which is created at initialisation of the object. Since each <code>TreeManager</code> instance is unique to each user, this is intended to be the default user configuration for a specific user. These options are </p> <ul> <li><code>style</code> - a string defining the 'style' passed to each tree. This can be used to customize the behaviour of the writing of the LLMs within the decision tree.</li> <li><code>agent_description</code> - A description of the agent that will be used in the tree. This helps define the agent's capabilities and behaviour.</li> <li><code>end_goal</code> - The ultimate objective or goal that the tree should work towards achieving, how it decides when the decision tree ends.</li> <li><code>branch_initialisation</code> - What tools are initialised as a default configuration of the tree.</li> <li><code>settings</code> - Optional configuration settings, see the Settings reference page.</li> </ul> <p>The class can also be initialised with <code>tree_timeout</code>, which controls the length of time before a particular conversation is cleaned up. See below for more details.</p> <p>Methods within <code>TreeManager</code> include:</p> <ul> <li><code>add_tree</code> - create a tree object with a <code>conversation_id</code> parameter, and optionally pass unique configuration options for that specific tree (which will not be overrided if the default <code>settings</code> object in the <code>TreeManager</code> is changed).</li> <li><code>configure</code> - a wrapper for the <code>configure</code> method for the <code>TreeManager</code>'s user <code>settings</code> object.</li> <li><code>process_tree</code> - an async function which runs the tree initialised with a <code>conversation_id</code> for a given <code>query</code> (user prompt).</li> <li><code>check_all_trees_timeout</code> - checks if any trees have been active for longer than <code>tree_timeout</code>, and removes them from the <code>TreeManager</code> if so.</li> </ul> <p>For a complete view of all the methods, see the reference page.</p>"},{"location":"API/user_and_tree_managers/#usermanager-overview","title":"UserManager Overview","text":"<p>The <code>UserManager</code> manages both a <code>TreeManager</code> and a <code>ClientManager</code> per user. Essentially, it contains a <code>users</code> dictionary which is keyed by different <code>user_id</code>s and has these managers for each user.</p> <p>It has initialisations: - <code>user_timeout</code> - controls how many minutes a user needs to be inactive before getting timed out (if you run the <code>check_all_users_timeout</code> method) - <code>tree_timeout</code> - initialisation parameter passed down to all <code>TreeManager</code> instances for each user. - <code>client_timeout</code> - initialisation parameter passed down to all <code>ClientManager</code> instances for each user.</p> <p>It has methods such as:</p> <ul> <li><code>add_user_local</code> - creates a user as well as their <code>TreeManager</code> and <code>ClientManager</code>. Can pass configuration options to create the user with these default configurations.</li> <li><code>get_user_local</code> - retrieve a user from the users dictionary, will raise an error if there is no user with that ID.</li> <li><code>initialise_tree</code> - create a tree within the tree manager for a particular user.</li> <li><code>process_tree</code> - runs the tree for a given <code>user_id</code> and <code>conversation_id</code> (tree within that user). Automatically sends error payloads if the user or tree has been timed out.</li> <li><code>check_all_users_timeout</code> - loop over all users stored in the user manager and removes any that have timed out.</li> <li><code>check_all_trees_timeout</code> - loop over all trees for all users in the user manager and removes any that have timed out.</li> <li><code>check_restart_clients</code> - loop over all clients for all users and call the <code>restart_client</code> functions, which only restarts clients if they have exceeded the <code>client_timeout</code> parameter since they were last used.</li> </ul> <p>For a complete view of all the methods, see the reference page.</p>"},{"location":"API/user_and_tree_managers/#timeouts","title":"Timeouts","text":"<p>If you're using the UserManager, you can set a scheduled <code>user_manager.check_all_trees_timeout()</code>, <code>user_manager.check_all_users_timeout()</code> and/or <code>user_manager.check_restart_clients()</code>; which will remove empty trees/users if they've been inactive for a period of time, or restart the Weaviate clients if they are also inactive. These time periods can be configured on initialisation of the UserManager, i.e.</p> <pre><code>UserManager(tree_timeout: datetime.timedelta | int, user_timeout: datetime.timedelta | int, client_timeout: datetime.timedelta | int))\n</code></pre> <p>This defaults to <code>TREE_TIMEOUT</code>, <code>USER_TIMEOUT</code> and <code>CLIENT_TIMEOUT</code> respectively in the environment variables if not set (in minutes), which itself defaults to 10 minutes. If they are set to 0, then no users/trees/clients will be restart. Not restarting the clients is not recommended.</p> <p>If you're using a TreeManager only (and not a <code>UserManager</code>), you can do the same with <code>tree_manager.check_all_trees_timeout()</code>, with same defaults.</p> <p>If you're only using the [ClientManager], you can call <code>restart_client</code> and <code>restart_async_client</code>, which automatically checks and restarts the clients individually if they have passed the <code>client_timeout</code> threshold.</p>"},{"location":"API/user_and_tree_managers/#example-scheduler-with-fastapi-lifespan","title":"Example Scheduler with FastAPI lifespan","text":"<p>For example, if using FastAPI, you can set an automatic scheduler such as:</p> <p><pre><code>from fastapi import FastAPI\nfrom apscheduler.schedulers.asyncio import AsyncIOScheduler\n\nasync def check_user_timeouts():\n    user_manager = get_user_manager()\n    await user_manager.check_all_users_timeout()\n\nasync def check_tree_timeouts():\n    user_manager = get_user_manager()\n    await user_manager.check_all_trees_timeout()\n\nasync def check_restart_clients():\n    user_manager = get_user_manager()\n    await user_manager.check_restart_clients()\n\n@asynccontextmanager\nasync def lifespan(app: FastAPI):\n    user_manager = get_user_manager()\n\n    scheduler = AsyncIOScheduler()\n    scheduler.add_job(check_tree_timeouts, \"interval\", seconds=23)\n    scheduler.add_job(check_user_timeouts, \"interval\", seconds=29)\n    scheduler.add_job(check_restart_clients, \"interval\", seconds=31)\n\n    scheduler.start()\n    yield\n    scheduler.shutdown()\n\n    await user_manager.close_all_clients()\n</code></pre> Where the <code>get_user_manager()</code> function returns a globally defined <code>UserManager</code> (and doesn't create a new one when it's called).</p> <p>This automatically runs the functions in the user manager every 23, 29 and 31 seconds, respectively.</p>"},{"location":"Advanced/","title":"Customising Elysia Overview","text":"<p>If you haven't already, you should read the basic usage guide and the advanced usage guide (which details exactly how to specify custom agent descriptions and styles).</p> <p>There are many ways you can make Elysia into a completely custom app with its own goals and tools. This section will detail exactly how you can create tools, how to interact with the Elysia decision tree's objects and to create your own.</p> <ul> <li>Technical Overview</li> <li>How to create your own tools</li> <li>How to interact with the Elysia Environment</li> <li>How to create your own objects</li> </ul>"},{"location":"Advanced/advanced_tool_construction/","title":"Advanced Tool Construction Overview","text":"<p>This page details how to create more custom and flexible tools in Elysia, by inheriting the <code>Tool</code> class and adding it to the decision tree via the <code>.add_tool</code> of the <code>Tree</code> object.</p> <p>To see an easier method of creating tools, see the Creating a Tool guide.</p> <p>This page will detail all relevant information for tool construction, to get started with an example, see - A basic text response example - A more complex example dealing cards to Elysia</p>"},{"location":"Advanced/advanced_tool_construction/#initialisation","title":"Initialisation","text":"<p>A tool must be initialised with <pre><code>    def __init__(self, logger: Logger | None = None, **kwargs):\n        super().__init__(\n            name=...,\n            description=...,\n            status=..., # optional\n            inputs=..., # optional\n            end=..., # optional\n            **kwargs # required\n        )\n</code></pre></p> <ul> <li><code>name</code>: A short, one or two word name of the tool.</li> <li><code>description</code>: A detailed description of what the tool will do and what it will accomplish. This is how the LLM decides whether to call the tool or not, so it is important that this is comprehensive and detailed.</li> <li><code>status</code> (optional): A short 'update' message that is displayed whilst the tool is running.</li> <li><code>inputs</code> (optional): A dictionary of inputs to your tool, which the LLM will decide on, which conform to the following structure:     <pre><code>{\n    input_name: {\n        \"description\": str,\n        \"type\": Any,\n        \"default\": Any,\n        \"required\": bool\n    },\n    ...\n}\n</code></pre>     You can have as many inputs as you want, but similar to the description field, the descriptions here need to be informative so that the LLM knows exactly what to choose.</li> <li><code>end</code> (optional): A bool denoting whether the tool is capable of ending the entire decision tree. For example, a <code>text_response</code> tool can end the process, but a <code>query</code> tool cannot. This is because a query tool returns some information which is then parsed by the decision tree afterwards, to see if the retrieved information was worthwhile. Note that setting <code>end=True</code> does not guarantee that after this tool is finished running, the decision process ends, it only allows the model to choose that performing this action can end the tree.</li> <li><code>**kwargs</code> (required)</li> </ul> <p>The <code>logger</code> can be automatically assigned to the initialisation of the tool and is passed by default into the Elysia decision tree. Save this as <code>self.logger = logger</code> to use it in the tool call later.</p>"},{"location":"Advanced/advanced_tool_construction/#tool-call","title":"Tool Call","text":"<p>The tool should have an async <code>__call__</code> method, <pre><code>    async def __call__(\n        tree_data: TreeData,\n        inputs: dict,\n        base_lm: dspy.LM,\n        complex_lm: dspy.LM,\n        client_manager: ClientManager,\n        **kwargs\n    ):\n        # tool call here\n</code></pre> which has the following inputs:</p> <ul> <li><code>tree_data</code>, an object of type <code>TreeData</code> which contains some information about the state of the decision making process at this point. This is likely the most relevant data to use in your tool calls, if the tool will affect the decision tree in some way. Here, you can access the environment (via <code>tree_data.environment</code>), the tasks completed dictionary (<code>tree_data.tasks_completed</code>), the collection metadata (<code>tree_data.collection_data</code>) and more - see here for all data you can access.</li> <li><code>inputs</code>: the inputs previously defined, formatted as      <pre><code>{\n    input_name_1: value,\n    input_name_2: value,\n    ...\n}\n</code></pre>     which were given by the LLM (or reverted to their default values, if the LLM chose nothing for a particular input).</li> <li><code>base_lm</code>: a <code>dspy.LM</code> object that can be used to interface with LLMs within the tool. This model is the same picked in the <code>elysia.configure(base_model=\"...\", base_provider=\"...\")</code> call. You can use this directly, e.g.     <pre><code>base_lm(\"hello, world!\")\n</code></pre>     or via a DSPy signature or module.</li> <li><code>complex_lm</code>: same as above for the complex LM specified.</li> <li><code>client_manager</code>: the interface to the Weaviate cluster you are connected to.</li> </ul> <p>The <code>__call__</code> method is automatically run when the LLM decision agent chooses to use that tool. You can use any of these inputs within your tool method and the code will be executed.</p> <p>Within the <code>__call__</code> method of the tool, you will want to interact with the decision tree in some way. There are multiple ways of doing this, either via returning various objects that Elysia defines within <code>elysia.objects</code>, or by interacting with the environment.</p>"},{"location":"Advanced/advanced_tool_construction/#returning-objects","title":"Returning Objects","text":"<p>If you return an Elysia specific object, they will be returned to the decision tree and automatically parsed in different ways which automatically add the relevant objects to the environment, and send any payloads to the frontend.</p> <p>Within your tool's call method, you may want to <code>yield</code> different objects to bring them back to the tree.</p> <ul> <li>Any class that inherits from the <code>Update</code> class will send updates to the frontend, such as a status message.</li> <li>Any class that inherits from the <code>Result</code> class have their corresponding objects added to the tree's environment, which the decision agent will 'look at', so that it can continue making decisions and respond accordingly to the user. Then, if applicable, relevant payloads will be sent to the frontend.</li> </ul>"},{"location":"Advanced/advanced_tool_construction/#status","title":"Status","text":"<p>A <code>Status</code> message is initialised with a single string argument, this displays on the frontend or the progress bar a unique message.</p>"},{"location":"Advanced/advanced_tool_construction/#result","title":"Result","text":"<p>Running inside of the call something like: <pre><code>    yield Result(\n        objects = [\n            {\n                \"title\": \"Example Result\",\n                \"content\": \"This is just an example of a result\"\n            }\n        ]\n    )\n</code></pre> will mean that this particular object gets added to the Tree's 'Environment', and the LLM can look at this to make further decisions. This will also automatically parse this object as a payload to a frontend, if one is connected.</p> <p>The arguments for the <code>Result</code> are:  - <code>objects</code>: a list of dictionaries that contain your specific objects. Currently, the keys of the dictionary do not matter, but if you want to display these items on the frontend, they need to conform to specific keys (see later)  - <code>metadata</code>: a dictionary of metadata items. You can use this to separate global information from object-specific information.  - <code>payload_type</code>: a string describing the type of objects you are giving.  - <code>mapping</code>: a dictionary mapping frontend-aware fields to the fields in <code>objects</code> (see here).</p> <p>See the custom objects page for more detail.</p>"},{"location":"Advanced/advanced_tool_construction/#interacting-with-the-environment","title":"Interacting with the Environment","text":"<p>See here a full description of the methods that you can use to interact with the environment.</p> <p>In short, the environment can be modified either by yielding <code>Result</code> objects, or by calling the environment methods explicitly.  You can do so via calling the <code>.add()</code>, <code>.add_objects()</code>, <code>.replace()</code> or <code>.remove()</code> from the <code>tree_data</code>.</p> <p>Note: If you add items to the environment and also yield a <code>Result</code> object with the same items, there will likely be duplicate items in the environment.</p>"},{"location":"Advanced/advanced_tool_construction/#displaying-objects-frontend-only","title":"Displaying Objects (Frontend Only)","text":"<p>You can yield a <code>Result</code> to the frontend, and by specifying the <code>payload_type</code>, the frontend will be aware of the type of object sent. The payload type currently must be one of the objects in the reference page, and you must also either conform to the field structure for each type or provide a <code>mapping</code> that maps from the expected fields to the fields in the objects.</p> <p>To display your objects without any mappings or display types, you can specify the payload type as <code>table</code>.</p>"},{"location":"Advanced/advanced_tool_construction/#easy-llm-calls-with-elysia-chain-of-thought","title":"Easy LLM calls with Elysia Chain of Thought","text":"<p>An easy way to access attributes from the tree (if you are calling an LLM within the tool) is to use the custom <code>ElysiaChainOfThought</code> DSPy module with specific arguments. This automatically adds information from the <code>tree_data</code> to an LLM prompt as inputs in a DSPy signature, as well as some specific outputs deemed useful within the decision tree environment (and a chain of thought reasoning field output field).</p> <p>To call this, you can do, for example <pre><code>from elysia.util.elysia_chain_of_thought import ElysiaChainOfThought\nmy_module = ElysiaChainOfThought(\n    MyCustomSignature, # a dspy signature needing to be defined\n    tree_data=tree_data, # tree_data input from the tool\n    message_update: bool = True,\n    environment: bool = False,\n    collection_schemas: bool = False,\n    tasks_completed: bool = False,\n    collection_names: list[str] = [],\n)\n</code></pre> By setting the boolean flags for the different variables, you can control the inputs and outputs assigned, whereas some inputs are always included (such as user prompt).</p> <p>To use the augmented module via <code>ElysiaChainOfThought</code>, call the <code>.aforward()</code> method of the new module, passing all your new inputs as keyword arguments. You do not need to include keyword arguments for the other inputs, like the <code>environment</code> or <code>user_prompt</code>, they are automatically added, e.g. <pre><code>my_module.aforward(input1=..., input2=..., lm=...)\n</code></pre> The <code>lm</code> parameter can be inherited from the tool inputs, i.e. <code>base_lm</code> or <code>complex_lm</code>. Or you can define your own LMs via <code>dspy.LM</code>.</p> <p>See the description for more details</p>"},{"location":"Advanced/advanced_tool_construction/#adding-tools-to-the-tree","title":"Adding Tools to the Tree","text":"<p>To add a Tool to be evaluated in the tree, just run <code>.add_tool</code>. For example</p> <p><pre><code>.add_tool(TextResponse)\n</code></pre> This will add the <code>TextResponse</code> tool to the root branch, by default (the base of the decision tree).</p> <p>Elysia sometimes has branches in the decision tree, which can be created via <code>add_branch</code>. If you want to add a tool to a particular branch, specify the <code>branch_id</code>, e..g if we have a branch called \"responses\", then</p> <pre><code>.add_tool(TextResponse, branch_id=\"responses\")\n</code></pre> <p>You can add tools on top of existing tools. Assume that the decision tree has the <code>multi_branch</code> structure, so that at the root node there are two options: <code>search</code> and <code>text_response</code>. The <code>text_response</code> option is a single tool, whereas the <code>search</code> option is in fact a branch with two options: <code>query</code> and <code>aggregate</code>.</p> <p>If you wanted to add a tool called <code>CheckOutput</code> to be run after the query tool, then you can do: <pre><code>.add_tool(CheckOutput, branch_id=\"search\", from_tool_ids = [\"query\"])\n</code></pre> which will add the <code>CheckOutput</code> tool to the line <code>search -&gt; query</code>, resulting in <code>search -&gt; query -&gt; check_output</code>.</p> <p>Note that the <code>search</code> branch still has two options, but if the decision LLM chooses to do the <code>query</code> tool, then the <code>check_output</code> tool is available for choice after querying. Also note that if a tool has no inputs and is alone in a decision node (it is the only option for the LLM to pick), the LLM decision will be skipped and the node will be automatically added. You can add more nodes to after the <code>query</code> tool and then the decision LLM will now resume operations at that node.</p>"},{"location":"Advanced/advanced_tool_construction/#self-healing-errors","title":"Self Healing Errors","text":"<p>You can yield an <code>Error</code> object to 'return' an error from the tool to the decision tree. These errors are saved within the tree data and automatically added to the decision nodes as well as any LLM calls made with <code>ElysiaChainOfThought</code> called within that tool. The LLM is 'informed' about these errors via an input to the prompts. The LLM can choose to continue calling the tool again, in spite of the error (if it seems fixable), or it can use the information to end the conversation and inform the user of an error, or to try a different tool that will not error.</p> <p>The <code>Error</code> object is initialised with a single string argument, which should be informative and descriptive.</p> <p>Note that this does not raise an error within Python, it is used to 'inform' the LLM that a potentially preventable error has occurred somewhere within the tool.</p> <p>For example, the Query tool built into Elysia will yield <code>Error</code> objects if the LLM creates a query which fails to run in Weaviate, such as not having the correct filter type for a particular property. The decision agent will read the error, and perhaps try to call the query tool again. Upon seeing the previous error in the error history, the query LLM agent should see that it should instead use a different filter property type, and correct itself.</p>"},{"location":"Advanced/advanced_tool_construction/#advanced-tool-methods","title":"Advanced Tool Methods","text":""},{"location":"Advanced/advanced_tool_construction/#run_if_true","title":"<code>run_if_true</code>","text":"<p>You can optionally choose to add another method to your Tool - <code>run_if_true</code>. This is a method that will be checked at the start of every decision tree, for every tool that has this method. If you don't wish to use this method, then simply do not define one.</p> <p>The <code>run_if_true</code> method returns two arguments (<code>tuple[bool, dict]</code>):</p> <ul> <li>a boolean value indicating whether the tool should be called straight away,</li> <li>a dictionary of <code>inputs</code> for if this tool gets called.</li> </ul> <p>If <code>run_if_true</code> returns <code>True</code>, then the <code>__call__</code> method of your tool will be called and carried out regardless of if the LLM wishes to use this tool or not. It is a hardcoded rule to run the tool. Some potential examples of using this include:</p> <ul> <li>The <code>run_if_true</code> method can count the number of tokens in the environment, and if the environment is getting too large, it runs the tool. Then the <code>__call__</code> method will be shrinking the environment in some way (e.g. using an LLM or just taking one particular item from it).</li> <li>If the user is asking about a particular subject, e.g. if the <code>user_prompt</code> (inside of <code>tree_data</code>) contains a specific word, then you could augment the <code>tree_data</code> to include some more specific information.</li> </ul> <pre><code>async def run_if_true(\n    self,\n    tree_data,\n    base_lm,\n    complex_lm,\n    client_manager,\n) -&gt; tuple[bool, dict]:\n    ...\n</code></pre> <p>Like the <code>__call__</code> and <code>is_tool_available</code> methods, this method has access to the tree data object, as well as some language models used by the tree and the ClientManager, to use a Weaviate client.</p> <p>See the reference for more details.</p>"},{"location":"Advanced/advanced_tool_construction/#is_tool_available","title":"<code>is_tool_available</code>","text":"<p>This method should return <code>True</code> if the tool is available to be used by the LLM. It should return <code>False</code> if the LLM should not have access to it. This can depend on the environment. For example, you can use <code>tree_data.environment.is_empty()</code> and the tool is only accessible if the environment is empty. Likewise you can use <code>not tree_data.environment.is_empty()</code> for it only to be available if the environment has something in it.</p> <pre><code>async def is_tool_available(\n    self,\n    tree_data,\n    base_lm,\n    complex_lm,\n    client_manager,\n) -&gt; bool:\n    \"\"\"A brief reason when this tool will become available goes here.\"\"\"\n    ...\n</code></pre> <p>Like the <code>__call__</code> and <code>run_if_true</code> methods, this method has access to the tree data object, as well as some language models used by the tree and the ClientManager, to use a Weaviate client.</p> <p>You should give a brief reason in the docstring of <code>is_tool_available</code> as to when it will become available, so that the LLM can perform actions towards completing this goal if it judges the tool to be useful to the current prompt.</p> <p>See the reference for more details. </p>"},{"location":"Advanced/advanced_tool_construction/#example-text-response-basic","title":"Example: Text Response (basic)","text":"<p>Consider the generic text response tool that Elysia will use if the conversation ends without a sufficient answer.</p> <pre><code>import dspy\nfrom elysia.objects import Response, Tool\nfrom elysia.tree.objects import TreeData\nfrom elysia.util.client import ClientManager\nfrom elysia.tools.text.prompt_templates import TextResponsePrompt\nfrom elysia.util.elysia_chain_of_thought import ElysiaChainOfThought\n\nclass TextResponse(Tool):\n    def __init__(self, **kwargs):\n        super().__init__(\n            name=\"final_text_response\",\n            description=\"\",\n            status=\"Writing response...\",\n            inputs={},\n            end=True,\n        )\n\n    async def __call__(\n        self,\n        tree_data: TreeData,\n        inputs: dict,\n        base_lm: dspy.LM,\n        complex_lm: dspy.LM,\n        client_manager: ClientManager | None = None,\n        **kwargs\n    ):\n        text_response = ElysiaChainOfThought(\n            TextResponsePrompt,\n            tree_data=tree_data,\n            environment=True,\n            tasks_completed=True,\n            message_update=False,\n        )\n\n        output = await text_response.aforward(\n            lm=base_lm,\n        )\n\n        yield Response(text=output.response)\n</code></pre> <p>The tool is simple, it is initialised and the descriptions are added to the Tool. Then the <code>__call__</code> method simply runs the text_response agent. Whilst the <code>TextResponsePrompt</code> is not shown here, it is a simple input -&gt; output call, where different parts of the <code>tree_data</code> are used as inputs to the LLM to give it context before answering. The relevant information from the <code>tree_data</code> are automatically inserted into the prompt via the <code>ElysiaChainOfThought</code> custom DSPy module.</p> <p>Note: If using DSPy within your tool, make sure to always call <code>aforward</code> method on the module so that it can be used async.</p>"},{"location":"Advanced/advanced_tool_construction/#example-dealing-cards-randomly-from-a-deck-intermediate","title":"Example: Dealing Cards Randomly from a Deck (Intermediate)","text":"<p>Let's create a tool that deals cards, adds them to the environment and displays them on the frontend.</p> <p>Just for fun, these cards, when they are dealt, change the Elysia conversation somewhat, by some modifiers we will define ourselves.</p> <pre><code>import random\nfrom elysia import Tool\nfrom elysia.tools import Ecommerce\n\nclass DealCards(Tool):\n    def __init__(self, **kwargs):\n        super().__init__(\n            name=\"deal_cards\",\n            description=\"\"\"\n            This tool should always be run at the start of any interaction with the user.\n            It defines any modifiers that get added to the conversation, from a random pool.\n            It does so by 'dealing cards' to the user as if they were a player of a card game.\n            These then will be displayed.\n            Call this tool when specifically asked for, or at the start of any conversation.\n            \"\"\",\n            status=\"Dealing cards...\",\n            inputs={\n                \"num_cards\": {\n                    \"description\": \"The number of cards to deal\",\n                    \"type\": int,\n                    \"default\": 3,\n                    \"required\": False,\n                }\n            },\n            end=False,\n        )\n        self.logger = kwargs.get(\"logger\", None)\n\n    def select_random_cards(self, num_cards=3):\n        possible_cards = [\n            {\n                \"title\": \"The Jumbled\",\n                \"effect\": \"Sometimes, the Elysia agent will say words in the wrong order.\",\n                \"rarity\": 3,\n                \"image\": \"https://i.imgur.com/KdGeZTp.png\",\n            },\n            {\n                \"title\": \"The Comedian\",\n                \"effect\": \"At the end of every sentence, the Elysia agent will tell a joke.\",\n                \"rarity\": 2,\n                \"image\": \"https://i.imgur.com/I8yVXHa.png\",\n            },\n            {\n                \"title\": \"The Sarcastic\",\n                \"effect\": \"Most interactions end with the Elysia agent making a sarcastic remark.\",\n                \"rarity\": 1,\n                \"image\": \"https://i.imgur.com/oFkwt1M.png\",\n            },\n            {\n                \"title\": \"The Bro\",\n                \"effect\": \"Elysia must now use the word 'bro' a lot more, and apply similar slang everywhere.\",\n                \"rarity\": 1,\n                \"image\": \"https://i.imgur.com/J6dLbTZ.png\",\n            },\n            {\n                \"title\": \"The Philosopher\",\n                \"effect\": \"The Elysia agent will now try to philosophise at every opportunity.\",\n                \"rarity\": 3,\n                \"image\": \"https://i.imgur.com/D6VSitF.png\",\n            },\n        ]\n        return random.choices(\n            possible_cards, weights=[1 / card[\"rarity\"] for card in possible_cards], k=3\n        )\n\n    async def __call__(self, tree_data, inputs, base_lm, complex_lm, client_manager, **kwargs):\n        self.logger.info(f\"Dealing {inputs['num_cards']} cards\")\n        cards = self.select_random_cards(inputs[\"num_cards\"])\n\n        yield Ecommerce(\n            objects=cards,\n            mapping={\n                \"description\": \"effect\",\n                \"name\": \"title\",\n                \"price\": \"rarity\",\n                \"image\": \"image\",\n            },\n            metadata={\n                \"num_cards\": inputs[\"num_cards\"],\n            },\n            name=\"cards\",\n            llm_message=\"\"\"\n            Cards have been successfully dealt for this prompt! \n            Dealt {num_cards} out of a possible 5.\n            Look at them in the environment to apply their modifiers to the conversation.\n            Pay attention to what these cards do, and how they affect the conversation.\n            You should apply the modifiers together, in a combination, not only one at a time.\n            \"\"\",\n        )\n</code></pre> <p>Let's break down the different components of this tool.</p> <ol> <li>In the <code>__init__</code>, we gave the tool name, a hefty description as well as a single input - the number of cards to deal. Make sure you provide the <code>**kwargs</code> argument also.</li> <li>There is a custom method that randomly chooses <code>num_cards</code> out of 5 possible cards, hand-written.</li> <li> <ul> <li>The <code>__call__</code> method, when the tool gets chosen, simply calls the <code>select_random_cards</code> method with the input that has come from the decision agent. </li> <li>Then it yields an <code>Ecommerce</code> object (placeholder) which will display the card. </li> <li>Since the <code>Ecommerce</code> object has pre-defined fields, to choose which of the card's fields go where, the <code>mapping</code> places the card <code>effect</code> in the Ecommerce <code>description</code>, the card <code>title</code> in place of the <code>name</code> field, the <code>rarity</code> becomes the <code>price</code> and the image field name is the same, but it is mapped anyway.</li> <li>The <code>llm_message</code> argument of the Ecommerce <code>Result</code>, describes what happens to the LLM whenever this tool is completed. This <code>llm_message</code> is persistent through further calls in Elysia, it will remain there for all future events in this conversation. In this case, it re-iterates the point that the cards add custom modifiers, and shows how many cards were dealt to the user at this point.</li> </ul> </li> </ol> <p>We could add more features to this card, for example, modifying the <code>tree_data.environment</code> object to find any existing cards in the environment (with the name \"cards\") and overwriting them with the new deal.</p>"},{"location":"Advanced/custom_objects/","title":"Returning Objects","text":""},{"location":"Advanced/custom_objects/#result","title":"Result","text":"<p>For more detail, see the <code>Result</code> description in the reference.</p> <p>A <code>Result</code> is a class with a <code>to_json()</code> and <code>to_frontend()</code> method which returns the objects defined within the class, and their metadata, to either the decision tree environment and an attached frontend, respectively. By default, any <code>Result</code> objects yielded within a tool will automatically have these objects assigned and sent.</p> <p>I.e. <pre><code># top of file\nfrom elysia.objects import Result\n\n# existing tool code\nyield Result(\n    objects = [...],\n    metadata = {...},\n    payload_type = \"&lt;your_type_here&gt;\",\n    name = \"&lt;name_to_go_in_environment&gt;\",\n    mapping = {...}\n)\n# continued tool code\n</code></pre></p>"},{"location":"Advanced/custom_objects/#parameters","title":"Parameters","text":"<p>Objects</p> <p>The <code>Result</code> class stores <code>objects</code>, which are a list of dictionaries containing anything that should be added to the environment or sent to the frontend. These can be stored however you like, but an Elysia-aware frontend expects the objects to have a certain format - the fields of the dictionaries need to be specific to the type of object being sent.</p> <p>For example, an Elysia frontend knows what the payload of a 'document' object should be, and there are fields such as <code>'title'</code>, <code>'content'</code> and <code>'author'</code> which it expects. But the objects returned from a retrieval might not have the fields line up exactly like this - maybe it has fields called <code>'document_header'</code>, <code>'text_content'</code> and <code>'writer'</code> instead.</p> <p>Metadata</p> <p>Results also can have metadata attached to them, which is a single dictionary that contains any information about this particular list of objects that exist across all objects, rather than on an individual level. For example, if we have retrieved some documents using a search query, the metadata can contain what that search query was and what collection was searched, whereas <code>objects</code> are the objects themselves.</p> <p>Payload Type</p> <p>The <code>payload_type</code> parameter is used to tell the frontend what to expect. Within Elysia, there are some predefined types (see here) that the built-in frontend is aware of. However, you can specify your own payload types if you are building a different frontend that is aware of different payload types.</p> <p>Mapping</p> <p>Within the <code>Result</code> there is also a <code>mapping</code> field which is a dictionary which maps from these fields to the fields contained within the objects themselves. For example, if we had an object with fields <code>\"document_header\"</code>, <code>\"text_content\"</code> and <code>\"writer\"</code>, then you may want to specify the <code>mapping</code> as <pre><code>{\n    \"title\": \"document_header\",\n    \"content\": \"text_content\",\n    \"author\": \"writer\n}\n</code></pre> So that on the frontend, when a document is displayed, the correct field values appear in the relevant fields.</p> <p>Name</p> <p>To index within the tree's environment, a <code>name</code> string identifier must be used to identify what type of objects are added to the environment. E.g., in the retrieval setting, this could be the collection name queried.</p>"},{"location":"Advanced/custom_objects/#frontend","title":"Frontend","text":"<p>When the default <code>.to_frontend(user_id, conversation_id, query_id)</code> method is called, it first calls <code>to_json(mapping=True)</code>, which returns a list of all objects that are mapped to their frontend-specific values, and then returns an augmented payload:</p> <pre><code>{\n    \"type\": \"result\",\n    \"user_id\": str,\n    \"conversation_id\": str,\n    \"query_id\": str,\n    \"id\": str,\n    \"payload\": dict = {\n        \"type\": str,\n        \"objects\": list[dict],\n        \"metadata\": dict,\n    },\n}\n</code></pre> <p>The outer level <code>type</code> field will default to <code>\"result\"</code>, by definition of the <code>Result</code> class. The <code>\"payload\"</code> field contains the unique <code>payload_type</code> (created on initialisation of the <code>Result</code>), as well as the objects/metadata within the <code>Result</code> object. Other fields, such as <code>user_id</code> and so forth, are inputs to the function which are automatically assigned when the decision tree processes the results.</p>"},{"location":"Advanced/custom_objects/#llm-message","title":"LLM Message","text":"<p>The <code>Result</code> class also has a <code>llm_message</code> parameter (or <code>.llm_parse()</code> method) which can be used to display custom information to both the decision agent LLM as well as any tools which use the <code>tasks_completed</code> field in <code>tree_data</code>.</p> <p>llm_message:</p> <p>The message can be formatted using placeholders given by:</p> <ul> <li><code>{payload_type}</code>: The payload type of the object created at initialisation</li> <li><code>{name}</code>: The name of the object</li> <li><code>{num_objects}</code>: The number of objects in the <code>Result</code></li> </ul> <p>Additionally, any key in the metadata dictionary can be used.</p> <p>E.g., on initialising the <code>Result</code>, you can pass <code>llm_message = \"Retrieved {num_objects} from {collection_name}\"</code> if you have <code>collection_name</code> in the metadata.</p>"},{"location":"Advanced/custom_objects/#custom-objects","title":"Custom Objects","text":""},{"location":"Advanced/custom_objects/#using-result-directly","title":"Using Result Directly","text":"<p>If you want specific payload types or similar, you can directly use <code>Result</code> and simply change the initialisation parameters for your own use-case. E.g. in the tool call, if we are dealing cards randomly, you can use</p> <p><pre><code>yield Result(\n    objects = [\n        {\"card_title\": \"Jack of Clubs\", \"card_value\": 11},\n        {\"card_title\": \"8 of Diamonds\", \"card_value\": 8}\n    ], \n    metadata = {\"deck_size\": 52},\n    payload_type = \"playing_cards\",\n    name=\"dealt_cards\",\n    llm_message=\"Dealt {num_objects} cards out of a possible {deck_size}.\"\n)\n</code></pre> Here, the <code>llm_message</code> will be input to the <code>tasks_completed</code> field of the <code>tree_data</code>, and when input to any tools using that field, this message will be displayed alongside what prompt was used and the tool called.</p> <p>Also, the frontend payload will use the <code>playing_cards</code> payload type, and the decision tree processing the result will automatically create the correct frontend payload.</p>"},{"location":"Advanced/custom_objects/#defining-a-new-subclass","title":"Defining a New Subclass","text":"<p>You can create your own subclass of the <code>Result</code> class to customise your objects specifically for your use-case. This can be used when you may want some custom rules when the <code>.to_json</code>, <code>.to_frontend</code>, or <code>.llm_parse</code> methods are automatically used.</p> <p>For example, if we just want to </p> <pre><code>class Card(Result):\n    def __init__(\n        self,\n        objects: list[dict],\n        metadata: dict = {},\n        name: str = \"card\",\n        mapping: dict | None = None,\n        llm_message: str | None = None,\n        unmapped_keys: list[str] = [],\n    ):\n        Result.__init__(\n            self,\n            objects=objects,\n            payload_type=\"playing_card\",\n            metadata=metadata,\n            name=name,\n            mapping=mapping,\n            llm_message=llm_message,\n            unmapped_keys=unmapped_keys,\n        )\n\n    def to_json(self, mapping: bool = False) -&gt; list[dict]:\n\n        output_objects = self.objects\n        for card in output_objects:\n            suit = \"\u2665\ufe0f\u2666\ufe0f\u2663\ufe0f\u2660\ufe0f\"[hash(str(card)) % 4] if \"card_title\" in card else \"\ud83c\udccf\"\n            card[\"suit_emoji\"] = suit\n            card[\"is_lucky\"] = card.get(\"card_value\", 0) &gt; 10\n\n        # Apply mapping if requested\n        if mapping and self.mapping:\n            output_objects = self.do_mapping(output_objects)\n\n        return output_objects\n\n    def llm_parse(self):\n        out = f\"\"\"\n        The first object in the hand was {self.objects[0]}.\n        There were {len(self.objects)} cards in the hand in total.\n        \"\"\"\n        if \"deck_size\" in self.metadata:\n            out += f\"There were a possible {self.metadata['deck_size']} cards to be dealt\"\n        return out\n</code></pre> <p>Here, the <code>to_json</code> method was overwritten to add a bit of flavour to the objects, which didn't exist in the original objects retrieved. The <code>llm_parse</code> method was overwritten so it could use information from the objects themselves, which was not available using the generic placeholders.</p>"},{"location":"Advanced/environment/","title":"Environment","text":"<p>The environment is a persistent object across all actions, tools and decisions performed within the Elysia decision tree. It can be used to store global information, such as retrieved objects or information that needs to be seen across all tools and actions.</p>"},{"location":"Advanced/environment/#overview","title":"Overview","text":"<p>The 'Environment' variable contains all objects returned from any tools called by the Elysia decision tree. In essence, it is a dictionary which is keyed by two variables:</p> <ul> <li><code>tool_name</code> (str): the name of the tool used to add this field to the environment</li> <li><code>name</code> (str): a subkey of <code>tool_name</code>, a unique <code>name</code> associated to the returns from that tool. E.g. a collection name from a retrieval.</li> </ul> <p>And when these items are accessed, it is a list of dictionaries, where each dictionary contains two subfields:</p> <ul> <li><code>objects</code> (list[dict])</li> <li><code>metadata</code> (dict)</li> </ul> <p>where each item in <code>objects</code> is a list of objects retrieved during the call of that tool. Each set of objects has its own corresponding metadata. </p> <p>For example, if Elysia calls the 'Query' tool, then the <code>tool_name</code> is <code>\"query\"</code> and the <code>name</code> is the name of the collection queried. Each list of objects has metadata associated with the query used to retrieve the data. So each list of objects has unique metadata.</p> Environment Example  Below is an example of what the environment looks like, after the tools `query` and `aggregate` have been called within this tree session. <pre><code>{\n    \"query\": {\n        \"message_result\": [\n            {\n                \"objects\": [\n                    {\"message_id\": 1, \"message_content\": \"Hi this is an example message about frogs!\"},\n                    {\"message_id\": 2, \"message_content\": \"Hi this is also an example message about reindeer!\"},\n                ], \n                \"metadata\": {\n                    \"collection_name\": \"example_email_messages_collection\",\n                    \"query_search_term\": \"animals\"\n                }\n            },\n        ]\n    },\n    \"aggregate\": {\n        \"pet_food_result\": [\n            {\n                \"objects\": [\n                    {\n                        \"average_price\": 45.99, \n                        \"product_count\": 150, \n                    }\n                ],\n                \"metadata\": {\n                    \"collection_name\": \"pet_food\",\n                    \"group_by\": {\"field\": \"animal\", \"value\": \"frog\"} \n                }\n            }\n        ]\n    }\n}\n</code></pre> This is just an example and not exactly how the structure within Elysia's inbuilt query and aggregate tools behave (they have much more information and would be harder to follow).  Note the levels of indexing the environment.  - The outer most level is the tool name that yielded the result (`\"query\"` and `\"aggregate\"`). - The next level is a `name` parameter associated with the `Result` that was yielded (`\"message_result\"` for query and `\"pet_food_result\"` for aggregate). - After the `name` key, there is a list of dictionaries. This list corresponds to a different result that was yielded within the same tool/name combination. - Each element of the list underneath `name` contains an `objects` and `metadata`, where the metadata is shared amongst all objects in this element."},{"location":"Advanced/environment/#interacting-with-the-environment","title":"Interacting with the Environment","text":"<p>For a full breakdown of all the methods, see the Environment reference page.</p>"},{"location":"Advanced/environment/#automatic-assignment","title":"Automatic Assignment","text":"<p>When yielding a <code>Result</code> object from a Tool, the result's <code>to_json()</code> method will return a list of dictionaries which automatically gets created or appended to the objects field in <code>environment[tool_name][name]</code>. The metadata are added at the same point.</p> <p>This calls the <code>.add()</code> method on the environment using the <code>Result</code> object.</p> Environment Example (cont. pt. 1)  From the `aggregate` tool, we can yield and initialise a `Result` back to the decision tree, where it is processed by the tree logic:  <pre><code>yield Result(\n    name=\"pet_food_result\",\n    objects = [\n        {\n            \"average_price\": 12.52, \n            \"product_count\": 33,\n        }\n    ],\n    metadata = {\n        \"collection_name\": \"pet_food\",\n        \"group_by\": {\"field\": \"animal\", \"value\": \"reindeer\"} \n    }\n)\n</code></pre>  And the updated environment looks like:  <pre><code>{\n    \"query\": {\n        \"message_result\": [...]\n    },\n    \"aggregate\": {\n        \"pet_food_result\": [\n            {\n                \"objects\": [\n                    {\n                        \"average_price\": 45.99, \n                        \"product_count\": 150, \n                    }\n                ],\n                \"metadata\": {\n                    \"collection_name\": \"pet_food\",\n                    \"group_by\": {\"field\": \"animal\", \"value\": \"frog\"} \n                }\n            },\n            {\n                \"objects\": [\n                    {\n                        \"average_price\": 12.52, \n                        \"product_count\": 33,\n                    }\n                ],\n                \"metadata\": {\n                    \"collection_name\": \"pet_food\",\n                    \"group_by\": {\"field\": \"animal\", \"value\": \"reindeer\"} \n                }\n            }\n        ]\n    }\n}\n</code></pre> Notice how a new entry was not added to either the first or second level of the environment dictionary, but was instead appended to the existing entries under `aggregate -&gt; pet_food_result`"},{"location":"Advanced/environment/#add-and-add_objects","title":"<code>.add()</code> and <code>.add_objects()</code>","text":"<p>See the reference page.</p> <p>When calling a tool, you can specifically add a <code>Result</code> object to the environment via  <pre><code>environment.add(tool_name, Result)\n</code></pre> The corresponding <code>to_json()</code> method in the <code>Result</code> is used to obtain the objects which get added.</p> <p>You can also have more control over which objects get added specifically by using <pre><code>environment.add_objects(tool_name, name, objects, metadata)\n</code></pre> where <code>objects</code> is a list of dictionaries, <code>metadata</code> is a dictionary and <code>tool_name</code> and <code>name</code> are string identifiers.</p> Environment Example (cont. pt. 2) If we were to do <pre><code>frog_result = Result(\n    objects = [\n        {\n            \"animal\": \"frog\",\n            \"description\": \"Green and slimy\"\n        }\n    ],\n    name=\"animal_description\"\n)\nenvironment.add(tool_name=\"descriptor\", result=frog_result)\n</code></pre> Then the environment would be updated to  <pre><code>{\n    \"query\": {\n        \"message_result\": [...]\n    },\n    \"aggregate\": {\n        \"pet_food_result\": [...]\n    }\n    \"descriptor\": {\n        \"animal_description\": [\n            {\n                \"objects\": [\n                    {\n                        \"animal\": \"frog\",\n                        \"description\": \"Green and slimy\"\n                    }\n                ],\n                \"metadata\": {}\n            }\n        ]\n    }\n}\n</code></pre> Even though we never interfaced with a tool called `descriptor`."},{"location":"Advanced/environment/#replace","title":"<code>.replace()</code>","text":"<p>See the reference page.</p> <p>Change an item in the environment with another item  <pre><code>environment.replace(tool_name, name, objects, metadata, index)\n</code></pre> either replace the entire list of items (objects + metadatas) or a single item at a particular index. <code>index</code> will only replace a particular item at that location, or if <code>None</code> (default) will replace the entire list.</p> Environment Example (cont. pt. 3) If we were to change the results from the `\"descriptor\"` to something else, <pre><code>environment.replace(\n    tool_name=\"descriptor\", \n    name=\"animal_description\",\n    objects = [{\"animal\": \"reindeer\", \"description\": \"Has a red nose\"}]\n)\n</code></pre> Then the environment would be updated to  <pre><code>{\n    \"query\": {\n        \"message_result\": [...]\n    },\n    \"aggregate\": {\n        \"pet_food_result\": [...]\n    }\n    \"descriptor\": {\n        \"animal_description\": [\n            {\n                \"objects\": [\n                    {\n                        \"animal\": \"reindeer\",\n                        \"description\": \"Has a red nose\"\n                    }\n                ],\n                \"metadata\": {}\n            }\n        ]\n    }\n}\n</code></pre>"},{"location":"Advanced/environment/#find","title":"<code>.find()</code>","text":"<p>See the reference page.</p> <p>You can use <pre><code>environment.find(tool_name, name, index)\n</code></pre> Which is an easy way to retrieve objects from the environment associated with the <code>tool_name</code> and <code>name</code> string identifiers. <code>index</code> is a parameter which finds the corresponding location of an item for these identifiers. Defaults to <code>None</code>, in which case it returns a list of all items.</p> <p>This is essentially just an alias to <code>environment.environment[tool_name][name][index]</code>.</p>"},{"location":"Advanced/environment/#remove","title":"<code>.remove()</code>","text":"<p>See the reference page.</p> <p>Items (objects + metadata) in the environment can be removed via <pre><code>environment.remove(tool_name, name, index)\n</code></pre> which uses the <code>tool_name</code> and <code>name</code> string identifiers to find the corresponding item. The <code>index</code> parameter will remove the objects and metadata associated only with that position in the list. E.g., if <code>index=-1</code>, then the most recent entry in the list will be deleted. This defaults to <code>None</code>, in which case the entire set of objects for <code>tool_name</code> and <code>name</code> are removed. You can, of course, check the length of items beforehand via <code>len(environment.find(tool_name, name))</code> and use that to define the index. Will raise an <code>IndexError</code> if that index does not exist.</p>"},{"location":"Advanced/environment/#the-hidden-environment","title":"The Hidden Environment","text":"<p>Within the environment there is also a dictionary, <code>environment.hidden_environment</code>, designed to be used as a store of data that is not shown to the LLM. You can save any type of object within this dictionary as it does not need to be converted to string to converted to LLM formatting.</p> <p>For example, this could be used to save raw retrieval objects that are not converted to their simple object properties, so you can still access the metadata output from the retrieval method that you otherwise wouldn't save inside the object metadata.</p>"},{"location":"Advanced/environment/#some-quick-usecases","title":"Some Quick Usecases","text":"<ul> <li>You may want to create a tool that only runs when the environment is non empty, so the <code>run_if_true</code> method of the tool (see here for details) returns <code>not tree_data.environment.is_empty()</code>.</li> <li>Your tool may not want to return any objects to the frontend, so instead of returning specific <code>Result</code> objects, you could modify the environment via <code>.add_objects()</code>, <code>.replace()</code> and <code>.remove()</code>. This stores 'private' variables that are not seen by the user unless they can manually inspect the environment.</li> </ul>"},{"location":"Advanced/technical_overview/","title":"Technical Overview","text":"<p>Let's break down the Elysia decision tree, how exactly it runs and how objects persist over multiple iterations. </p> <p>We will consider a 'standard' Elysia set up as an example, where we have access to two tools: 'Query' and 'Aggregate', which both interact with custom data. There are two additional tools: 'Summarize' and 'Text Response', which both provide text outputs (with slightly different specifications).</p> <p></p>"},{"location":"Advanced/technical_overview/#decision-agent","title":"Decision Agent","text":"<p>The decision agent (which is run from the <code>base_model</code>) is responsible for choosing the tools to call/nodes for each decision step. The decision tree structure consists of 'branches', which are subcategories for tools, used to separate out different tools if there are many of them, and tools, which are actions to perform. Tools should add information to the Elysia environment. The environment is used within the decision agent as well as any tools so the process is aware of any retrieved or collected data.</p> <p>The inputs to the decision tree are:</p> <ul> <li>The tree data (see below).</li> <li>Tool descriptions.</li> <li>Instruction for the branch (e.g. how to make the choice between the currently available tools).</li> <li>Metadata on the tree, including how many loops through the tree has been made, as well as future tools that exist within a branch.</li> </ul> <p>The decision agent assigns the following outputs:</p> <ul> <li>Tool to use.</li> <li>Inputs to the tool if they exist.</li> <li>Whether to end the tree after calling this tool (although this is conditional on the tool also allowing the process to end after its call).</li> <li>A message update to the user.</li> <li>Whether the task is impossible given all other information.</li> </ul>"},{"location":"Advanced/technical_overview/#tree-data","title":"Tree Data","text":"<p>The tree data is a subset of the most important data in the Elysia decision tree. This includes the most pertinent information, such as the user prompt and the conversation history, as well as the Atlas, an alias to the style, agent description and end goal that the agent must adhere to, and the environment, a collection of all data retrieved or collected by Elysia during tool evaluations. A history of completed tasks and custom formatted text from the tools is also included. Any errors (that were manually caught and yielded) during tool evaluations are also included into the tree data, so that the decision agent or subsequent runs of the tools can be aware of previous failures.</p> <p>The tree data is included in the decision agent and can be also included in any LLM calls within tools. The tree data is essentially the way that tools 'interact' with Elysia, by including information of the state of the tree and updating this state information.</p> <p>To see a full breakdown of the tree data, see the description for the <code>TreeData</code> class. </p>"},{"location":"Examples/","title":"Index","text":"<ol> <li>Querying a Weaviate database - create an example collection in Weaviate and use Elysia with its core functionality to retrieve data.</li> <li>Basic Linear Regression - creating a custom Elysia tool to perform a basic least squares regression on items retrieved from the <code>query</code> tool.</li> </ol> <p>More examples coming soon!</p>"},{"location":"Examples/data_analysis/","title":"Basic Linear Regression","text":"<p>Let's create a tool which performs a least squares regression on numeric data retrieved from a Weaviate collection. For this example, we will use the default branch initialisation for the decision tree (<code>\"one_branch\"</code>), which includes tools for querying and retrieving data from a Weaviate collection. We are going to add a <code>BasicLinearRegression</code> tool that extracts data from the environment and solves the least squares problem to obtain coefficients for the regression.</p>"},{"location":"Examples/data_analysis/#initial-setup","title":"Initial Setup","text":"<p>Let's follow the basic guideline for creating a tool, and create the skeleton of the tool below.</p> <pre><code>from elysia import Error, Tool, Result\nimport numpy as np\nimport matplotlib.pyplot as plt\n\nclass BasicLinearRegression(Tool):\n\n    def __init__(self, logger, **kwargs):\n        pass\n\n    async def __call__(\n        self,\n        tree_data,\n        inputs,\n        base_lm,\n        complex_lm,\n        client_manager,\n        **kwargs,\n    ):\n        pass\n\n    async def is_tool_available(self, tree_data, base_lm, complex_lm, client_manager):\n        pass\n</code></pre> <p>The general outline for this tool is going to be as follows:</p> <ul> <li>No LLM calls within the tool, the decision agent is going to be deciding inputs for the regression.</li> <li>The call of the tool is going to transform the environment into matrices to be used for the analysis.</li> <li>The tool is going to add to the environment the labelled coefficients from the regression.</li> <li>The <code>is_tool_available</code> function is going to return <code>True</code> when there is data retrieved from the <code>query</code> tool in the environment.</li> </ul>"},{"location":"Examples/data_analysis/#tool-initialisation","title":"Tool Initialisation","text":"<p>Let's set the initialisation parameters to provide a comprehensive tool description and input descriptions.</p> <pre><code>    def __init__(self, logger, **kwargs):\n        super().__init__(\n            name=\"basic_linear_regression_tool\",\n            description=\"\"\"\n            Use this tool to perform linear regression on objects in the environment with numeric data types.\n            \"\"\",\n            status=\"Running linear regression...\",\n            inputs={\n                \"environment_key\": {\n                    \"description\": (\n   \"A single key (string) of the `environment` dictionary that will be used in the analysis. \"\n                        \"Choose the most relevant key for the analysis according to the user prompt. \"\n                        \"All objects under that key will be used to create the dataframe. \"\n                    ),\n                    \"required\": True,\n                    \"type\": str,\n                    \"default\": None,\n                },\n                \"x_variable_fields\": {\n                    \"description\": (\n                        \"The independent variables for the regression. \"\n                        \"Choose one or more fields within the `objects` underneath the specific `environment_key`. \"\n                    ),\n                    \"required\": True,\n                    \"type\": list[str],\n                    \"default\": None,\n                },\n                \"y_variable_field\": {\n                    \"description\": (\n                        \"The dependent variable for the regression. \"\n                        \"Choose one single field within the `objects` underneath the specific `environment_key`. \"\n                    ),\n                    \"required\": True,\n                    \"type\": str,\n                    \"default\": None,\n                },\n            },\n            end=False,\n        )\n</code></pre>"},{"location":"Examples/data_analysis/#tool-call","title":"Tool Call","text":"<p>The tool call is the <code>__call__</code> method - this will be called when the tool is selected by the LLM. So this is where the actual tool execution takes place. We need to do several things here:</p> <ol> <li>Convert the environment (within the <code>tree_data</code>) to matrices</li> <li>Perform least squares regression on these matrices</li> <li>Yield relevant objects to the decision tree, so the information goes back to the tree</li> </ol> <p>Let's first start with setting the tool up and collecting the inputs: <pre><code>    async def __call__(\n        self,\n        tree_data,\n        inputs,\n        base_lm,\n        complex_lm,\n        client_manager,\n        **kwargs,\n    ):\n        environment = tree_data.environment.environment\n        environment_key = inputs[\"environment_key\"]\n        x_variable_field = inputs[\"x_variable_field\"]\n        y_variable_field = inputs[\"y_variable_field\"]\n</code></pre></p> <p>Now we have separated the relevant inputs and items we need, let's now proceed with converting the environment (within the <code>tree_data</code>) to matrices:</p> <p><pre><code>        # initialise empty matrices to store all objects\n        X = np.empty((0, 2))\n        y = np.empty((0, 1))\n\n        # iterate over all items in the environment\n        for inner_key in environment[environment_key]:\n\n            # convert all objects under this key to a matrix\n            inner_X = np.array(\n                [\n                    [obj[x_variable_field]]\n                    for environment_list in environment[environment_key][inner_key]\n                    for obj in environment_list[\"objects\"]\n                ]\n            )\n            inner_X = np.hstack([np.ones((inner_X.shape[0], 1)), inner_X])\n            X = np.vstack([X, inner_X])\n\n            # convert all objects under this key to a matrix\n            inner_y = np.array(\n                [\n                    [obj[y_variable_field]]\n                    for environment_list in environment[environment_key][inner_key]\n                    for obj in environment_list[\"objects\"]\n                ]\n            )\n            y = np.vstack([y, inner_y])\n</code></pre> This may look a bit complicated, but its quite straightforward. Since the <code>environment</code> is keyed via two variables: the tool used which added items to the environment and then a sub-key of names within that tool, we require looping over the <code>inner_key</code> within the outer <code>environment_key</code> which was decided by the LLM.</p> <p>We use NumPy to create the matrices, which are initialised to the correct dimension (the independent variable should have matrix \\(X\\) which is \\(n \\times 2\\), since there is only one independent variable and a intercept column, and the dependent variable, \\(y\\), should be \\(n \\times 1\\)). </p> <p>Now we need to perform least squares regression on these matrices to obtain the regression coefficients.</p> <pre><code>        # calculate the beta hat values via least squares\n        beta_hat = np.linalg.inv(X.T @ X + 1e-10 * np.eye(X.shape[1])) @ X.T @ y\n        beta_hat_dict = {\n            \"intercept\": beta_hat[0],\n            \"slope\": beta_hat[1],\n        }\n</code></pre> <p>We follow the least squares solution using linear algebra to get these coefficients: $$     \\hat{\\beta} = (X^\\top X + \\lambda I_n)^{-1} X^\\top y $$ where \\(\\lambda\\) is small (e.g. <code>1e-10</code>). The first value in \\(\\hat{\\beta}\\) will correspond to the intercept and the second value will correspond to the independent variable and its correlation with the dependent variable (the slope). We can plot these values with <code>matplotlib</code>, just for explanatory purposes:</p> <pre><code>        # plot the data\n        pred_y = X @ beta_hat   \n        fig, ax = plt.subplots()\n        ax.scatter(X[:, 1], y)\n        ax.plot(X[:, 1], pred_y, color=\"red\")\n        ax.set_title(\n            f\"Linear regression between {x_variable_field} and {y_variable_field}\"\n        )\n        ax.set_xlabel(x_variable_field)\n        ax.set_ylabel(y_variable_field)\n        fig.show()\n</code></pre> <p>This will plot the independent variable against the dependent one, include the line of best fit, and then show the plot whenever the tool is successfully run.</p> <p>Now we need to give information back to the decision tree about the results of this analysis, so it can be used to continue the conversation and make further decisions. All tools should <code>yield</code> objects, and we use the <code>Result</code> class which automatically will assign objects to the tree's environment.</p> <pre><code>        yield Result(\n            objects=[\n                beta_hat_dict,\n            ],\n            metadata={\n                \"x_variable_field\": x_variable_field,\n                \"y_variable_field\": y_variable_field,\n            },\n            llm_message=(\n                \"Completed linear regression analysis where: \"\n                \"    x variable: {x_variable_field} \"\n                \"    y variable: {y_variable_field} \"\n            ),\n        )\n</code></pre> <p>There is only one object needed to be returned, the coefficient values. The decision agent will use this information to continue the decision tree by reading the objects. We also include what variable corresponds to where by including the <code>x_variable_field</code> and <code>y_variable_field</code> in the metadata, and include an <code>llm_message</code> to custom display that the regression was completed. </p> <pre><code>    async def __call__(\n        self,\n        tree_data,\n        inputs,\n        base_lm,\n        complex_lm,\n        client_manager,\n        **kwargs,\n    ):\n        environment = tree_data.environment.environment\n        environment_key = inputs[\"environment_key\"]\n        x_variable_field = inputs[\"x_variable_field\"]\n        y_variable_field = inputs[\"y_variable_field\"]\n\n        # initialise empty matrices to store all objects\n        X = np.empty((0, 2))\n        y = np.empty((0, 1))\n\n        # iterate over all items in the environment\n        for inner_key in environment[environment_key]:\n\n            # convert all objects under this key to a matrix\n            inner_X = np.array(\n                [\n                    [obj[x_variable_field]]\n                    for environment_list in environment[environment_key][inner_key]\n                    for obj in environment_list[\"objects\"]\n                ]\n            )\n            inner_X = np.hstack([np.ones((inner_X.shape[0], 1)), inner_X])\n            X = np.vstack([X, inner_X])\n\n            # convert all objects under this key to a matrix\n            inner_y = np.array(\n                [\n                    [obj[y_variable_field]]\n                    for environment_list in environment[environment_key][inner_key]\n                    for obj in environment_list[\"objects\"]\n                ]\n            )\n            y = np.vstack([y, inner_y])\n\n        # calculate the beta hat values via least squares\n        beta_hat = np.linalg.inv(X.T @ X + 1e-10 * np.eye(X.shape[1])) @ X.T @ y\n        beta_hat_dict = {\n            \"intercept\": beta_hat[0],\n            \"slope\": beta_hat[1],\n        }\n        pred_y = X @ beta_hat\n\n        # plot the data\n        fig, ax = plt.subplots()\n        ax.scatter(X[:, 1], y)\n        ax.plot(X[:, 1], pred_y, color=\"red\")\n        ax.set_title(\n            f\"Linear regression between {x_variable_field} and {y_variable_field}\"\n        )\n        ax.set_xlabel(x_variable_field)\n        ax.set_ylabel(y_variable_field)\n        fig.show()\n\n        # yield the result to the decision tree\n        yield Result(\n            objects=[\n                beta_hat_dict,\n            ],\n            metadata={\n                \"x_variable_field\": x_variable_field,\n                \"y_variable_field\": y_variable_field,\n            },\n            llm_message=(\n                \"Completed linear regression analysis where: \"\n                \"    x variable: {x_variable_field} \"\n                \"    y variable: {y_variable_field} \"\n            ),\n        )\n</code></pre>"},{"location":"Examples/data_analysis/#controlling-when-the-tool-is-available","title":"Controlling when the tool is available","text":"<p>We can also set the <code>is_tool_available</code> method to only return <code>True</code> when something relevant is in the environment. In this case, when information has been returned from the <code>query</code> tool.</p> <pre><code>    async def is_tool_available(self, tree_data, base_lm, complex_lm, client_manager):\n        \"\"\"\n        Available when the 'query' task has been completed and it has added data to the environment.\n        \"\"\"\n        return (\n            \"query\" in tree_data.environment.environment\n            and len(tree_data.environment.environment[\"query\"]) &gt; 0\n        )\n</code></pre> <p>We have also provided a brief description of when the tool will become available, which will be passed to the decision agent any time the tool is unavailable, so that it knows what tasks it needs to accomplish before being able to run this tool. In this case, this should inform the LM that to perform linear regression, it needs to get the data first.</p>"},{"location":"Examples/data_analysis/#putting-it-all-together","title":"Putting it all together","text":"<p>Here is the full tool construction, and let's also wrap the call in a <code>try</code>/<code>except</code> block to catch any errors (using the <code>Error</code> class for self-healing errors).</p> <pre><code>class BasicLinearRegression(Tool):\n\n    def __init__(self, logger, **kwargs):\n        super().__init__(\n            name=\"basic_linear_regression_tool\",\n            description=\"\"\"\n            Use this tool to perform linear regression between two numeric variables in the environment.\n            \"\"\",\n            status=\"Running linear regression...\",\n            inputs={\n                \"environment_key\": {\n                    \"description\": (\n                        \"A single key (string) of the `environment` dictionary that will be used in the analysis. \"\n                        \"Choose the most relevant key for the analysis according to the user prompt. \"\n                        \"All objects under that key will be used to create the dataframe. \"\n                    ),\n                    \"required\": True,\n                    \"type\": str,\n                    \"default\": None,\n                },\n                \"x_variable_field\": {\n                    \"description\": (\n                        \"The independent variable for the regression. \"\n                        \"Choose one field title within the `objects` underneath the specific `environment_key`. \"\n                    ),\n                    \"required\": True,\n                    \"type\": str,\n                    \"default\": None,\n                },\n                \"y_variable_field\": {\n                    \"description\": (\n                        \"The dependent variable for the regression. \"\n                        \"Choose one single field within the `objects` underneath the specific `environment_key`. \"\n                    ),\n                    \"required\": True,\n                    \"type\": str,\n                    \"default\": None,\n                },\n            },\n            end=False,\n        )\n\n    async def __call__(\n        self,\n        tree_data,\n        inputs,\n        base_lm,\n        complex_lm,\n        client_manager,\n        **kwargs,\n    ):\n        environment = tree_data.environment.environment\n        environment_key = inputs[\"environment_key\"]\n        x_variable_field = inputs[\"x_variable_field\"]\n        y_variable_field = inputs[\"y_variable_field\"]\n\n        try:\n\n            # initialise empty matrices to store all objects\n            X = np.empty((0, 2))\n            y = np.empty((0, 1))\n\n            # iterate over all items in the environment\n            for inner_key in environment[environment_key]:\n\n                # convert all objects under this key to a matrix\n                inner_X = np.array(\n                    [\n                        [obj[x_variable_field]]\n                        for environment_list in environment[environment_key][inner_key]\n                        for obj in environment_list[\"objects\"]\n                    ]\n                )\n                inner_X = np.hstack([np.ones((inner_X.shape[0], 1)), inner_X])\n                X = np.vstack([X, inner_X])\n\n                # convert all objects under this key to a matrix\n                inner_y = np.array(\n                    [\n                        [obj[y_variable_field]]\n                        for environment_list in environment[environment_key][inner_key]\n                        for obj in environment_list[\"objects\"]\n                    ]\n                )\n                y = np.vstack([y, inner_y])\n\n            # calculate the beta hat values via least squares\n            beta_hat = np.linalg.inv(X.T @ X + 1e-10 * np.eye(X.shape[1])) @ X.T @ y\n            beta_hat_dict = {\n                \"intercept\": beta_hat[0],\n                \"slope\": beta_hat[1],\n            }\n            pred_y = X @ beta_hat\n\n            # plot the data\n            fig, ax = plt.subplots()\n            ax.scatter(X[:, 1], y)\n            ax.plot(X[:, 1], pred_y, color=\"red\")\n            ax.set_title(\n                f\"Linear regression between {x_variable_field} and {y_variable_field}\"\n            )\n            ax.set_xlabel(x_variable_field)\n            ax.set_ylabel(y_variable_field)\n            fig.show()\n\n            # yield the result to the decision tree\n            yield Result(\n                objects=[\n                    beta_hat_dict,\n                ],\n                metadata={\n                    \"x_variable_field\": x_variable_field,\n                    \"y_variable_field\": y_variable_field,\n                },\n                llm_message=(\n                    \"Completed linear regression analysis where: \"\n                    \"    x variable: {x_variable_field} \"\n                    \"    y variable: {y_variable_field} \"\n                ),\n            )\n        except Exception as e:\n            yield Error(str(e))\n\n    async def is_tool_available(self, tree_data, base_lm, complex_lm, client_manager):\n        \"\"\"\n        Available when the 'query' task has been completed and it has added data to the environment.\n        \"\"\"\n        return (\n            \"query\" in tree_data.environment.environment\n            and len(tree_data.environment.environment[\"query\"]) &gt; 0\n        )\n</code></pre>"},{"location":"Examples/data_analysis/#experimenting","title":"Experimenting","text":"<p>Let's initialise a tree, add the tool and test it runs correctly. In this example, a Weaviate collection called <code>Ecommerce</code> will be used. The <code>Ecommerce</code> collection has many redundant fields (for this example), but we want to evaluate whether the <code>price</code> variable correlates with the review <code>rating</code>.</p> <p><pre><code>from elysia import Tree\ntree = Tree()\ntree.add_tool(BasicLinearRegression)\nresponse, objects = tree(\n    \"Perform linear regression on the relationship between the price of a product and the review rating it has\",\n    collection_names = [\"Ecommerce\"]\n)\n</code></pre> And some relevant output from the run: <pre><code>INFO     Tasks completed (iteration 1):\n            - query (Avg. 3.90 seconds)\n            - summarise_items (Avg. 0.00 seconds)\nINFO     Tasks completed (iteration 2):\n            - basic_linear_regression_tool (Avg. 0.01 seconds)\nINFO     Tasks completed (iteration 3):\n            - cited_summarize (Avg. 4.59 seconds)\n</code></pre></p> <p><pre><code>print(response)\n</code></pre> <code>To begin, I'm querying the \"Ecommerce\" collection to retrieve the product price and review rating data needed for the linear regression. I am now retrieving all product prices and review ratings from the \"Ecommerce\" collection to prepare for the linear regression analysis. I am now performing a linear regression analysis on the retrieved data, using product price as the independent variable and review rating as the dependent variable. I have completed the linear regression analysis, revealing an intercept of approximately 4.61 and a slope of approximately 0.00044, indicating a very slight positive relationship between product price and review rating. The linear regression analysis performed on product price and review rating reveals a very slight positive relationship between the two variables. The intercept of the regression model is approximately 4.61, and the slope is approximately 0.00044. This indicates that as the product price increases, the review rating tends to increase, but only by a very small margin.</code></p> <p></p>"},{"location":"Examples/email/","title":"Sending an Automated Email","text":"<p>This example will go through a</p>"},{"location":"Examples/fantasy_adventure/","title":"Example: Creating a Fantasy Adventure Game","text":"<p>Coming soon.</p>"},{"location":"Examples/query_weaviate/","title":"Querying a Weaviate Database","text":"<p>This example will walk through using Elysia to:</p> <ul> <li>Setting up your API keys with Elysia for using models</li> <li>Setting up your Weaviate collections for usage with Elysia</li> <li>Query or aggregate your Weaviate collections</li> <li>How the decision tree works</li> </ul>"},{"location":"Examples/query_weaviate/#before-you-begin","title":"Before You Begin","text":"<p>Before setting up your environment and connecting to Weaviate, make sure you have the necessary API keys and access credentials for both your language models and your Weaviate instance. This will ensure a smooth setup process in the following steps.</p> <ol> <li>You should have a Weaviate cloud cluster - see Step 1.1 in the Weaviate quickstart guide.</li> <li>You need to find your REST endpoint URL and Admin API key for your cluster - see Step 1.3 in the Weaviate quickstart guide</li> <li>You additionally need API keys for any LLMs you want to use. We recommend OpenRouter to gain access to a range of models.</li> </ol>"},{"location":"Examples/query_weaviate/#setting-up","title":"Setting up","text":"<p>Let's use the basic elysia <code>configure</code> to both set up your models and connect to your Weaviate cluster.</p> <p><pre><code>from elysia import configure\nconfigure(\n    wcd_url = \"...\", # replace with your Weaviate REST endpoint URL\n    wcd_api_key = \"...\" # replace with your Weaviate cluster API key,\n    base_model = \"gemini-2.0.flash-001\",\n    base_provider = \"gemini\",\n    complex_model = \"gemini-2.5.flash-001\",\n    complex_provider = \"gemini\",\n    gemini_api_key = \"...\" # replace with your GEMINI_API_KEY from Google AI studio\n)\n</code></pre> Alternatively, you can use different models, such as <code>gpt-4.1-mini</code>, <code>gpt-4.1</code>, with <code>base_provider=\"openai\"</code> and <code>complex_provider=\"openai\"</code>, as well as an <code>openai_api_key</code>. Or any model/provider combination that you wish, see the full LiteLLM docs for all API keys and models/providers.</p>"},{"location":"Examples/query_weaviate/#optional-add-some-data-to-your-weaviate-cluster","title":"Optional: Add some data to your Weaviate cluster","text":"<p>We're going to create some basic data and an example collection for this demo. This is based on this example in the Weaviate docs.</p> <p>If you want to skip this step and use data from your own collection, simply replace all instances of the collection name \"JeopardyQuestion\" with your true collection name in later steps.</p> <ol> <li> <p>Download the example dataset.     <pre><code>import requests, json\nurl = \"https://raw.githubusercontent.com/weaviate/weaviate-examples/main/jeopardy_small_dataset/jeopardy_tiny.json\"\nresp = requests.get(url)\ndata = json.loads(resp.text)\n</code></pre>     This dataset contains questions, answers and categories from Jeopardy questions. E.g.     <pre><code>{\n    \"Category\": \"SCIENCE\",\n    \"Question\": \"This organ removes excess glucose from the blood &amp; stores it as glycogen\",\n    \"Answer\": \"Liver\"\n}\n</code></pre></p> </li> <li> <p>Import the data into Weaviate     <pre><code>from elysia.util.client import ClientManager\n\nclient_manager = ClientManager()\n\nwith client_manager.connect_to_client() as client:\n\n    if client.collections.exists(\"JeopardyQuestion\"):\n        client.collections.delete(\"JeopardyQuestion\")\n\n    client.collections.create(\n        \"JeopardyQuestion\"\n    )\n\n    jeopardy = client.collections.get(\"JeopardyQuestion\")\n    response = jeopardy.data.insert_many(data)\n\n    if response.has_errors:\n        print(response.errors)\n    else:\n        print(\"Insert complete.\")\n</code></pre>     This will by default use the settings inherited from the earlier <code>configure</code> function, so the Weaviate REST endpoint URL and API key set up previously.</p> </li> </ol>"},{"location":"Examples/query_weaviate/#preprocessing-with-elysia","title":"Preprocessing with Elysia","text":"<p>Now that you are fully set up with models and Weaviate integrations, you can move onto preprocessing your collection for use with Elysia. This is as simple as: <pre><code>from elysia import preprocess\npreprocess(\"JeopardyQuestion\")\n</code></pre></p> View the Preprocessed Data  To view the preprocessing that has been completed, you can run the `view_preprocessed_collection` function on your collection:  <pre><code>from elysia import view_preprocessed_collection\nview_preprocessed_collection(\"JeopardyQuestion\")\n</code></pre> <pre><code>{\n    \"mappings\": {\n        \"document\": {\"content\": \"question\", \"category\": \"category\", \"title\": \"\", \"author\": \"\", \"date\": \"\"},\n        \"table\": {\"category\": \"category\", \"question\": \"question\", \"answer\": \"answer\"}\n    },\n    \"prompts\": [\n        \"What are some questions about DNA?\",\n        \"What questions are in the SCIENCE category?\",\n        \"What questions are in the ANIMALS category?\",\n        \"What are some questions about mammals?\",\n        \"What are some questions about snakes?\",\n        \"What are the answers related to science?\",\n        \"What are the answers related to animals?\",\n        \"What questions involve the atmosphere?\",\n        \"What questions involve metals?\",\n        \"What questions involve organs?\"\n    ],\n    \"fields\": [\n        {\n            \"range\": [1.0, 4.0],\n            \"type\": \"text\",\n            \"groups\": [\n                {\"count\": 1, \"value\": \"DNA\"},\n                {\"count\": 1, \"value\": \"the atmosphere\"},\n                {\"count\": 1, \"value\": \"wire\"},\n                {\"count\": 1, \"value\": \"Elephant\"},\n                {\"count\": 1, \"value\": \"Antelope\"},\n                {\"count\": 1, \"value\": \"species\"},\n                {\"count\": 1, \"value\": \"Liver\"},\n                {\"count\": 1, \"value\": \"Sound barrier\"},\n                {\"count\": 1, \"value\": \"the diamondback rattler\"},\n                {\"count\": 1, \"value\": \"the nose or snout\"}\n            ],\n            \"mean\": 1.7,\n            \"date_range\": None,\n            \"name\": \"answer\",\n            \"date_median\": None,\n            \"description\": \"The correct response to the question posed in the 'question' field. This is a string \ncontaining the answer.\"\n        },\n        {\n            \"range\": [1.0, 1.0],\n            \"type\": \"text\",\n            \"groups\": [{\"count\": 6, \"value\": \"SCIENCE\"}, {\"count\": 4, \"value\": \"ANIMALS\"}],\n            \"mean\": 1.0,\n            \"date_range\": None,\n            \"name\": \"category\",\n            \"date_median\": None,\n            \"description\": \"The subject area or topic to which the question and answer belong. Examples include \n'SCIENCE' and 'ANIMALS'.\"\n        },\n        {\n            \"range\": [10.0, 22.0],\n            \"type\": \"text\",\n            \"groups\": [\n                {\n                    \"count\": 1,\n                    \"value\": \"A metal that is 'ductile' can be pulled into this while cold &amp; under pressure\"\n                },\n                {\n                    \"count\": 1,\n                    \"value\": \"The gavial looks very much like a crocodile except for this bodily feature\"\n                },\n                {\n                    \"count\": 1,\n                    \"value\": \"In 1953 Watson &amp; Crick built a model of the molecular structure of this, the \ngene-carrying substance\"\n                },\n                {\n                    \"count\": 1,\n                    \"value\": \"Weighing around a ton, the eland is the largest species of this animal in Africa\"\n                },\n                {\n                    \"count\": 1,\n                    \"value\": \"2000 news: the Gunnison sage grouse isn't just another northern sage grouse, but a \nnew one of this classification\"\n                },\n                {\"count\": 1, \"value\": \"It's the only living mammal in the order Proboseidea\"},\n                {\"count\": 1, \"value\": \"This organ removes excess glucose from the blood &amp; stores it as glycogen\"},\n                {\n                    \"count\": 1,\n                    \"value\": \"In 70-degree air, a plane traveling at about 1,130 feet per second breaks it\"\n                },\n                {\"count\": 1, \"value\": \"Heaviest of all poisonous snakes is this North American rattlesnake\"},\n                {\"count\": 1, \"value\": \"Changes in the tropospheric layer of this are what gives us weather\"}\n            ],\n            \"mean\": 15.0,\n            \"date_range\": None,\n            \"name\": \"question\",\n            \"date_median\": None,\n            \"description\": \"The question or prompt for which the 'answer' field provides the correct response. This\nis a string containing the question.\"\n        }\n    ],\n    \"summary\": \"This dataset contains questions and answers across various categories, primarily focusing on \nscience and animals. Each entry includes a question, its corresponding answer, and the category to which the \nquestion belongs. The dataset provides a diverse set of trivia-like information suitable for quizzes or educational\npurposes. The sample represents the entire dataset. The 'question' field is related to the 'answer' field, as the \n'answer' provides the correct response to the 'question'. The 'category' field classifies the 'question' and \n'answer' pair into a specific subject area. The category helps to group questions of similar topics together. The \ndata is structured as a list of JSON objects. Each object contains three fields: 'answer', 'category', and \n'question'. No irregularities found. \",\n    \"vectorizer\": None,\n    \"name\": \"JeopardyQuestion\",\n    \"named_vectors\": [\n        {\n            \"source_properties\": None,\n            \"enabled\": True,\n            \"name\": \"default\",\n            \"model\": \"Snowflake/snowflake-arctic-embed-l-v2.0\",\n            \"description\": \"\",\n            \"vectorizer\": \"TEXT2VEC_WEAVIATE\"\n        }\n    ],\n    \"index_properties\": {\"isTimestampIndexed\": False, \"isNullIndexed\": False, \"isLengthIndexed\": False},\n    \"length\": 10.0\n}\n</code></pre>"},{"location":"Examples/query_weaviate/#creating-the-decision-tree","title":"Creating the Decision Tree","text":"<p>Now that the models and Weaviate integrations are set up (with <code>configure</code>), the default parameters to run the decision tree will also work automatically. </p> <p>Let's first create the class and inspect some of the properties. <pre><code>from elysia import Tree\ntree = Tree()\n</code></pre></p> Inspecting the Decision Tree Structure To look at what tools are currently on the tree, we can inspect use the `tree.view()` method:  <pre><code>print(tree.view())\n</code></pre> <pre><code>\ud83d\udcc1 Base (base)\n  \u251c\u2500\u2500 \ud83d\udd27 Cited summarize (cited_summarize)\n      \ud83d\udcac Summarize retrieved information for the user when all relevant data has\n         been gathered. Provides a text response, and may end the conversation, but\n         unlike text_response tool, can be used mid-conversation. Avoid for general\n         questions where text_response is available. Summarisation text is directly\n         displayed to the user. Most of the time, you can choose end_actions to be\n         True to end the conversation with a summary. This is a good way to end the\n         conversation.\n\n\n  \u251c\u2500\u2500 \ud83d\udd27 Text response (text_response)\n      \ud83d\udcac End the conversation. This should be used when the user has finished their\n         query, or you have nothing more to do except reply. You should use this to\n         answer conversational questions not related to other tools. But do not use\n         this as a source of information. All information should be from the\n         environment if answering a complex question or an explanation. If there is\n         an error and you could not complete a task, use this tool to suggest a\n         brief reason why. If, for example, there is a missing API key, then the\n         user needs to add it to the settings (which you should inform them of). Or\n         you cannot connect to weaviate, then the user needs to input their API\n         keys in the settings. If there are no collections available, the user\n         needs to analyze this in the 'data' tab. If there are other problems, and\n         it looks like the user can fix it, then provide a suggestion.\n\n\n  \u251c\u2500\u2500 \ud83d\udd27 Aggregate (aggregate)\n      \ud83d\udcac Query the knowledge base specifically for aggregation queries. Performs\n         calculations (counting, averaging, summing, etc.) and provides summary\n         statistics on data. It can group data by properties and apply filters\n         directly, without needing a prior query. Aggregation queries can be\n         filtered. This can be applied directly on any collections in the schema.\n         Use this tool when you need counts, sums, averages, or other summary\n         statistics on properties in the collections. 'aggregate' should be\n         considered the first choice for tasks involving counting, summing,\n         averaging, or other statistical operations, even when filtering is\n         required.\n\n\n  \u251c\u2500\u2500 \ud83d\udd27 Base.query (base.query)\n      \ud83d\udcac Retrieves and displays specific data entries from the collections. Then,\n         query with semantic search, keyword search, or a combination of both.\n         Queries can be filtered, sorted, and more. Retrieving and displaying\n         specific data entries rather than performing calculations or summaries. Do\n         not use 'query' as a preliminary filtering step when 'aggregate' can\n         achieve the same result more efficiently (if 'aggregate' is available).\n\n    \u2514\u2500\u2500 \ud83d\udd27 Query postprocessing (query_postprocessing)\n        \ud83d\udcac If the user has requested itemised summaries for retrieved objects, this\n           tool summarises each object on an individual basis.\n\n\n  \u2514\u2500\u2500 \ud83d\udd27 Visualise (visualise)\n      \ud83d\udcac Visualise data in a chart from the environment. You can only visualise\n         data that is in the environment. If there is nothing relevant in the\n         environment, do not choose this tool.\n</code></pre>  These are the default tools available in a regular initialisation of the Elysia Tree, as well as their tool descriptions. To change the default tools available on a tree, you can initialise the tree with a different `branch_initialisation`, e.g.  <pre><code>tree = Tree(branch_initialisation=\"empty\")\n</code></pre> will create a tree with no tools, and you can add custom tools via `tree.add_tool()`."},{"location":"Examples/query_weaviate/#running-the-decision-tree","title":"Running the Decision Tree","text":"<p>To run the tool-running pipeline of the Elysia decision tree, you can simply call the class, i.e.</p> <pre><code>response, objects = tree(\n    \"Find a single question about Science\",\n    collection_names = [\"JeopardyQuestion\"]\n)\n</code></pre> Real time updates The default behaviour is that Elysia will print updates on what it is doing. In this example, this is <pre><code>\u256d\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500 User prompt \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u256e\n\u2502                                      \u2502\n\u2502 Find a single question about Science \u2502\n\u2502                                      \u2502\n\u2570\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u256f\n\u256d\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500 Assistant response \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u256e\n\u2502                                                                              \u2502\n\u2502 I will now search for a science question in the JeopardyQuestion collection. \u2502\n\u2502                                                                              \u2502\n\u2570\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u256f\n\u256d\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500 Current Decision \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u256e\n\u2502                                                                                                                 \u2502\n\u2502 Node: base                                                                                                      \u2502\n\u2502 Decision: query                                                                                                 \u2502\n\u2502 Reasoning: The user is asking for a question about science.                                                     \u2502\n\u2502 The `JeopardyQuestion` collection contains questions and answers, and the category field indicates whether the  \u2502\n\u2502 question is about science.                                                                                      \u2502\n\u2502 Therefore, I should query the `JeopardyQuestion` collection and filter for questions where the category is      \u2502\n\u2502 science.                                                                                                        \u2502\n\u2502 I should use the `query` tool to retrieve the questions.                                                        \u2502\n\u2502                                                                                                                 \u2502\n\u2502                                                                                                                 \u2502\n\u2570\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u256f\n\u256d\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500 Assistant response \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u256e\n\u2502                                                                                                                 \u2502\n\u2502 I am now retrieving a single science question from the JeopardyQuestion collection by filtering for the         \u2502\n\u2502 'SCIENCE' category.                                                                                             \u2502\n\u2502                                                                                                                 \u2502\n\u2570\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u256f\n\u256d\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500 JeopardyQuestion (Weaviate Query) \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u256e\n\u2502                                                         \u2502\n\u2502 collection.query.fetch_objects(                         \u2502\n\u2502     filters=Filter.all_of([                             \u2502\n\u2502         Filter.by_property('category').equal('SCIENCE') \u2502\n\u2502     ]),                                                 \u2502\n\u2502     limit=1                                             \u2502\n\u2502 )                                                       \u2502\n\u2502                                                         \u2502\n\u2570\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u256f\n\u256d\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500 Current Decision \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u256e\n\u2502                                                                                                 \u2502\n\u2502 Node: base.query                                                                                \u2502\n\u2502 Decision: query_postprocessing                                                                  \u2502\n\u2502 Reasoning: Only one option available: query_postprocessing (and no function inputs are needed). \u2502\n\u2502                                                                                                 \u2502\n\u2502                                                                                                 \u2502\n\u2570\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u256f\n\u256d\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500 Current Decision \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u256e\n\u2502                                                                                                                 \u2502\n\u2502 Node: base                                                                                                      \u2502\n\u2502 Decision: text_response                                                                                         \u2502\n\u2502 Reasoning: I have already retrieved a science question from the JeopardyQuestion collection in the previous     \u2502\n\u2502 turn. The question is: \"This organ removes excess glucose from the blood &amp; stores it as glycogen\". The answer   \u2502\n\u2502 is \"Liver\". I should now respond to the user with this question.                                                \u2502\n\u2502                                                                                                                 \u2502\n\u2502                                                                                                                 \u2502\n\u2570\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u256f\n\u256d\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500 Assistant response \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u256e\n\u2502                                                                                                                \u2502\n\u2502 Here's a science question for you: \"This organ removes excess glucose from the blood &amp; stores it as glycogen?\" \u2502\n\u2502                                                                                                                \u2502\n\u2570\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u256f\n</code></pre> <p>This will run through the decision tree, where the decision agent will choose tools based on what tools are available, what branch the decision agent is currently on, and context.</p> <p>The <code>response</code> will be a concatenation of all responses that the model output (at each decision step and during any other response outputs): <pre><code>print(response)\n</code></pre> <pre><code>'I will now search for a science question in the JeopardyQuestion collection. I am now retrieving a single science question from the JeopardyQuestion collection by filtering for the \\'SCIENCE\\' category. Here\\'s a science question for you: \"This organ removes excess glucose from the blood &amp; stores it as glycogen?\"'\n</code></pre></p> <p>The <code>objects</code> will be a list of objects that were added to the environment during that tree run: <pre><code>print(objects)\n</code></pre> <pre><code>[\n    [\n        {\n            'category': 'SCIENCE',\n            'question': 'This organ removes excess glucose from the blood &amp; stores it as glycogen',\n            'answer': 'Liver',\n            'uuid': 'b28ca48a-9a8d-417c-9ed1-e487132740ed',\n            'collection_name': 'JeopardyQuestion',\n            'chunk_spans': [],\n            '_REF_ID': 'query_JeopardyQuestion_0_0'\n        }\n    ]\n]\n</code></pre></p> <p>In this case, the model searched Weaviate using a <code>fetch_objects</code> search (no hybrid or semantic search), and used a <code>limit=1</code>, so only returned one object. The decision agent recognised that the query tool was called successfully, added a single object to the environment, and then finally recognised that the task was completed and therefore finalised the process with a <code>text_response</code>, informing the user of what the question was.</p> <p>Note that the query tool was able to correctly use the filter <code>Filter.by_property('category').equal('SCIENCE')</code>, as the preprocessing step identified the unique groups for the property <code>'category'</code>, which was handed down to the query tool.</p>"},{"location":"Examples/query_weaviate/#continuing-the-conversation","title":"Continuing the Conversation","text":"<p>By calling the same <code>Tree</code> class a second time, the conversation history is automatically included in the context of the decision tree. So if you were to ask: <pre><code>tree(\"What about animals?\")\n</code></pre></p> Real time updates <pre><code>\u256d\u2500\u2500\u2500\u2500 User prompt \u2500\u2500\u2500\u2500\u256e\n\u2502                     \u2502\n\u2502 What about animals? \u2502\n\u2502                     \u2502\n\u2570\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u256f\n\u256d\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500 Assistant response \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u256e\n\u2502                                                                                    \u2502\n\u2502 I will now search for a question about animals in the JeopardyQuestion collection. \u2502\n\u2502                                                                                    \u2502\n\u2570\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u256f\n\u256d\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500 Current Decision \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u256e\n\u2502                                                                                                                 \u2502\n\u2502 Node: base                                                                                                      \u2502\n\u2502 Decision: query                                                                                                 \u2502\n\u2502 Reasoning: The user is now asking about animals, following a previous question about science.                   \u2502\n\u2502 The `JeopardyQuestion` collection contains questions and answers, and the category field indicates whether the  \u2502\n\u2502 question is about animals.                                                                                      \u2502\n\u2502 Therefore, I should query the `JeopardyQuestion` collection and filter for questions where the category is      \u2502\n\u2502 animals.                                                                                                        \u2502\n\u2502 I should use the `query` tool to retrieve the questions.                                                        \u2502\n\u2502                                                                                                                 \u2502\n\u2502                                                                                                                 \u2502\n\u2570\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u256f\n\u256d\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500 Assistant response \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u256e\n\u2502                                                                                                                 \u2502\n\u2502 I am now retrieving a single question about animals from the JeopardyQuestion collection by filtering for the   \u2502\n\u2502 'ANIMALS' category.                                                                                             \u2502\n\u2502                                                                                                                 \u2502\n\u2570\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u256f\n\u256d\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500 JeopardyQuestion (Weaviate Query) \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u256e\n\u2502                                                         \u2502\n\u2502 collection.query.fetch_objects(                         \u2502\n\u2502     filters=Filter.all_of([                             \u2502\n\u2502         Filter.by_property('category').equal('ANIMALS') \u2502\n\u2502     ]),                                                 \u2502\n\u2502     limit=1                                             \u2502\n\u2502 )                                                       \u2502\n\u2502                                                         \u2502\n\u2570\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u256f\n\u256d\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500 Current Decision \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u256e\n\u2502                                                                                                 \u2502\n\u2502 Node: base.query                                                                                \u2502\n\u2502 Decision: query_postprocessing                                                                  \u2502\n\u2502 Reasoning: Only one option available: query_postprocessing (and no function inputs are needed). \u2502\n\u2502                                                                                                 \u2502\n\u2502                                                                                                 \u2502\n\u2570\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u256f\n\u256d\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500 Current Decision \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u256e\n\u2502                                                                                                                 \u2502\n\u2502 Node: base                                                                                                      \u2502\n\u2502 Decision: text_response                                                                                         \u2502\n\u2502 Reasoning: I have already retrieved a question about animals from the JeopardyQuestion collection in the        \u2502\n\u2502 previous turn. The question is: \"It's the only living mammal in the order Proboseidea\". The answer is           \u2502\n\u2502 \"Elephant\". I should now respond to the user with this question.                                                \u2502\n\u2502                                                                                                                 \u2502\n\u2502                                                                                                                 \u2502\n\u2570\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u256f\n\u256d\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500 Assistant response \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u256e\n\u2502                                                                                             \u2502\n\u2502 Here is an animal question for you: \"It's the only living mammal in the order Proboseidea?\" \u2502\n\u2502                                                                                             \u2502\n\u2570\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u256f\n</code></pre> <p>Then the decision agent is aware that the context of the first question, i.e. \"retrieve a single question\", and uses that to frame its responses and queries for the second question, changing the filter from <code>\"SCIENCE\"</code> to <code>\"ANIMALS\"</code>. The conversation history can be viewed by running:</p> <p><pre><code>print(tree.conversation_history)\n</code></pre> <pre><code>[\n    {'role': 'user', 'content': 'Find a single question about Science'},\n    {\n        'role': 'assistant',\n        'content': 'I will now search for a science question in the JeopardyQuestion collection. I am now \nretrieving a single science question from the JeopardyQuestion collection by filtering for the \\'SCIENCE\\' \ncategory. Here\\'s a science question for you: \"This organ removes excess glucose from the blood &amp; stores it as \nglycogen?\"'\n    },\n    {'role': 'user', 'content': 'What about animals?'},\n    {\n        'role': 'assistant',\n        'content': 'I will now search for a question about animals in the JeopardyQuestion collection. I am now \nretrieving a single question about animals from the JeopardyQuestion collection by filtering for the \\'ANIMALS\\' \ncategory. Here\\'s a question about animals for you: \"It\\'s the only living mammal in the order Proboseidea?\"'\n    }\n]\n</code></pre></p>"},{"location":"Examples/sentiment_analysis/","title":"Example: Sentiment Analysis on Retrieved Data","text":"<p>Coming soon.</p>"},{"location":"Reference/Client/","title":"WeaviateClient","text":""},{"location":"Reference/Client/#elysia.util.client.ClientManager","title":"<code>ClientManager</code>","text":"<p>Handles the creation and management of the Weaviate client. Handles cases where the client can be used in more than one thread or async operation at a time, via threading and asyncio locks. Also can use methods for restarting client if its been inactive.</p> Source code in <code>elysia/util/client.py</code> <pre><code>class ClientManager:\n    \"\"\"\n    Handles the creation and management of the Weaviate client.\n    Handles cases where the client can be used in more than one thread or async operation at a time,\n    via threading and asyncio locks.\n    Also can use methods for restarting client if its been inactive.\n    \"\"\"\n\n    def __init__(\n        self,\n        wcd_url: str | None = None,\n        wcd_api_key: str | None = None,\n        client_timeout: datetime.timedelta | int | None = None,\n        logger: Logger | None = None,\n        settings: Settings | None = None,\n        **kwargs,\n    ) -&gt; None:\n        \"\"\"\n        Args:\n            wcd_url (str): the url of the Weaviate cluster. Defaults to global settings config.\n            wcd_api_key (str): the api key for the Weaviate cluster. Defaults to global settings config.\n            client_timeout (datetime.timedelta | int | None): how long (in minutes) means the client should be restarted. Defaults to 3 minutes.\n            logger (Logger | None): a logger object for logging messages. Defaults to None.\n            settings (Settings | None): a settings object for the client manager. Defaults to environment settings.\n            **kwargs (Any): any other api keys for third party services (formatted as e.g. OPENAI_APIKEY).\n\n        Example:\n        ```python\n        client_manager = ClientManager(\n            wcd_url=\"https://my-weaviate-cluster...\",\n            wcd_api_key=\"my-api-key...\",\n            OPENAI_APIKEY=\"my-openai-api-key...\",\n            HUGGINGFACE_APIKEY=\"my-huggingface-api-key...\",\n        )\n        ```\n        \"\"\"\n\n        self.logger = logger\n\n        if client_timeout is None:\n            self.client_timeout = datetime.timedelta(\n                minutes=int(os.getenv(\"CLIENT_TIMEOUT\", 3))\n            )\n        elif isinstance(client_timeout, int):\n            self.client_timeout = datetime.timedelta(minutes=client_timeout)\n        else:\n            self.client_timeout = client_timeout\n\n        if settings is None:\n            self.settings = environment_settings\n        else:\n            self.settings = settings\n\n        # Set the weaviate cluster url and api key\n        if wcd_url is None:\n            self.wcd_url = self.settings.WCD_URL\n        else:\n            self.wcd_url = wcd_url\n\n        if wcd_api_key is None:\n            self.wcd_api_key = self.settings.WCD_API_KEY\n        else:\n            self.wcd_api_key = wcd_api_key\n\n        # Set the api keys for non weaviate cluster (third parties)\n        self.headers = {}\n        for api_key in self.settings.API_KEYS:\n            if api_key.lower() in [a.lower() for a in api_key_map.keys()]:\n                self.headers[api_key_map[api_key.upper()]] = self.settings.API_KEYS[\n                    api_key\n                ]\n\n        # From kwargs\n        for kwarg in kwargs:\n            if kwarg.lower() in [a.lower() for a in api_key_map.keys()]:\n                self.headers[api_key_map[kwarg.upper()]] = kwargs[kwarg]\n\n        # Create locks for client events\n        self.async_lock = asyncio.Lock()\n        self.sync_lock = threading.Lock()\n\n        # In use counter tracks when the client is in use and by how many operations. 0 = can restart\n        self.async_in_use_counter = 0\n        self.sync_in_use_counter = 0\n        self.async_restart_event = asyncio.Event()\n        self.sync_restart_event = threading.Event()\n\n        self.last_used_sync_client = datetime.datetime.now()\n        self.last_used_async_client = datetime.datetime.now()\n\n        self.async_client = None\n        self.async_init_completed = False\n        self.is_client = self.wcd_url != \"\" and self.wcd_api_key != \"\"\n\n        if self.logger:\n            if self.wcd_api_key == \"\" and self.wcd_url == \"\":\n                self.logger.warning(\n                    \"WCD_URL and WCD_API_KEY are not set. \"\n                    \"All Weaviate functionality will be disabled.\"\n                )\n            elif self.wcd_url == \"\":\n                self.logger.warning(\n                    \"WCD_URL is not set. \"\n                    \"All Weaviate functionality will be disabled.\"\n                )\n            elif self.wcd_api_key == \"\":\n                self.logger.warning(\n                    \"WCD_API_KEY is not set. \"\n                    \"All Weaviate functionality will be disabled.\"\n                )\n            else:\n                self.logger.debug(\n                    \"Weaviate client initialised. \"\n                    \"All Weaviate functionality will be enabled.\"\n                )\n\n        if not self.is_client:\n            return\n\n        # Start sync client\n        self.client = self.get_client()\n        self.sync_restart_event.set()\n\n    async def reset_keys(\n        self,\n        wcd_url: str | None = None,\n        wcd_api_key: str | None = None,\n        api_keys: dict[str, str] = {},\n    ) -&gt; None:\n        \"\"\"\n        Set the API keys, WCD_URL and WCD_API_KEY from the settings object.\n\n        Args:\n            wcd_url (str): the url of the Weaviate cluster.\n            wcd_api_key (str): the api key for the Weaviate cluster.\n            api_keys (dict): a dictionary of api keys for third party services.\n        \"\"\"\n        self.wcd_url = wcd_url\n        self.wcd_api_key = wcd_api_key\n\n        self.headers = {}\n\n        for api_key in api_keys:\n            if api_key.lower() in [a.lower() for a in api_key_map.keys()]:\n                self.headers[api_key_map[api_key.upper()]] = api_keys[api_key]\n\n        self.is_client = self.wcd_url != \"\" and self.wcd_api_key != \"\"\n        if self.is_client:\n            await self.restart_client(force=True)\n            await self.restart_async_client(force=True)\n            await self.start_clients()\n\n    async def start_clients(self) -&gt; None:\n        \"\"\"\n        Start the async and sync clients if they are not already running.\n        \"\"\"\n\n        if not self.is_client:\n            raise ValueError(\n                \"Weaviate is not available. Please set the WCD_URL and WCD_API_KEY in the settings.\"\n            )\n\n        if self.async_client is None:\n            self.async_client = await self.get_async_client()\n            self.async_restart_event.set()\n\n        if not self.async_client.is_connected():\n            await self.async_client.connect()\n\n        self.async_init_completed = True\n\n        if not self.client.is_connected():\n            self.client.connect()\n\n    def update_last_user_request(self) -&gt; None:\n        self.last_user_request = datetime.datetime.now()\n\n    def update_last_used_sync_client(self) -&gt; None:\n        self.last_used_sync_client = datetime.datetime.now()\n\n    def update_last_used_async_client(self) -&gt; None:\n        self.last_used_async_client = datetime.datetime.now()\n\n    def get_client(self) -&gt; WeaviateClient:\n        if self.wcd_url is None or self.wcd_api_key is None:\n            raise ValueError(\"WCD_URL and WCD_API_KEY must be set\")\n\n        return weaviate.connect_to_weaviate_cloud(\n            cluster_url=self.wcd_url,\n            auth_credentials=Auth.api_key(self.wcd_api_key),\n            headers=self.headers,\n            skip_init_checks=True,\n        )\n\n    async def get_async_client(self) -&gt; WeaviateAsyncClient:\n        if self.wcd_url is None or self.wcd_api_key is None:\n            raise ValueError(\"WCD_URL and WCD_API_KEY must be set\")\n\n        return weaviate.use_async_with_weaviate_cloud(\n            cluster_url=self.wcd_url,\n            auth_credentials=Auth.api_key(self.wcd_api_key),\n            headers=self.headers,\n            skip_init_checks=True,\n        )\n\n    @contextmanager\n    def connect_to_client(self) -&gt; Generator[WeaviateClient, Any, None]:\n        \"\"\"\n        A context manager to connect to the _sync_ client.\n\n        E.g.\n\n        ```python\n        with client_manager.connect_to_client():\n            # do stuff with the weaviate client\n            ...\n        ```\n        \"\"\"\n        if not self.is_client:\n            raise ValueError(\n                \"Weaviate is not available. Please set the WCD_URL and WCD_API_KEY in the settings.\"\n            )\n\n        self.sync_restart_event.wait()\n        with self.sync_lock:\n            self.sync_in_use_counter += 1\n\n        if not self.client.is_connected():\n            self.client.connect()\n\n        connection = _ClientConnection(self, self.client)\n        with connection:\n            yield connection.client\n\n    @asynccontextmanager\n    async def connect_to_async_client(\n        self,\n    ) -&gt; AsyncGenerator[WeaviateAsyncClient, Any]:\n        \"\"\"\n        A context manager to connect to the _async_ client.\n\n        E.g.\n        ```python\n        async with client_manager.connect_to_async_client():\n            # do stuff with the async weaviate client\n            ...\n        ```\n        \"\"\"\n        if not self.is_client:\n            raise ValueError(\n                \"Weaviate is not available. Please set the WCD_URL and WCD_API_KEY in the settings.\"\n            )\n\n        if not self.async_init_completed:\n            await self.start_clients()\n\n        await self.async_restart_event.wait()\n        async with self.async_lock:\n            self.async_in_use_counter += 1\n\n        if self.async_client is None:\n            raise ValueError(\"Async client not initialised\")\n\n        if not self.async_client.is_connected():\n            await self.async_client.connect()\n\n        connection = _AsyncClientConnection(self, self.async_client)\n        async with connection:\n            yield connection.client\n\n    async def restart_async_client(self, force=False) -&gt; None:\n        \"\"\"\n        Restart the async client if it has not been used in the last client_timeout minutes (set in init).\n        \"\"\"\n        if self.client_timeout == datetime.timedelta(minutes=0) and not force:\n            return\n\n        # First check if the client has been used in the last X minutes\n        if (\n            datetime.datetime.now() - self.last_used_async_client &gt; self.client_timeout\n            or force\n        ):\n            # Acquire lock before modifying shared state to prevent race conditions\n            try:\n                async with self.async_lock:\n                    # Clear the event WHILE holding the lock to prevent new connections from starting\n                    # This ensures no new connections can proceed until we're done\n                    self.async_restart_event.clear()\n\n                    # Record current counter value before waiting\n                    last_recorded_counter = self.async_in_use_counter\n\n                    # Set reasonable timeout values\n                    time_spent = 0\n                    max_wait_time = 10  # seconds\n                    check_interval = 0.1  # seconds\n\n                    # Only wait if there are active connections\n                    if last_recorded_counter &gt; 0:\n                        # Wait for existing connections to complete\n                        while self.async_in_use_counter &gt; 0:\n                            # Release lock during sleep to prevent deadlock\n                            self.async_lock.release()\n\n                            # Only timeout after 10 seconds if nothing is happening\n                            # if the counter is changing, then things are happening and we should wait\n                            if self.async_in_use_counter != last_recorded_counter:\n                                last_recorded_counter = self.async_in_use_counter\n                                time_spent = 0\n\n                            try:\n                                await asyncio.sleep(check_interval)\n                                time_spent += check_interval\n                                if time_spent &gt; max_wait_time:\n                                    if self.logger:\n                                        self.logger.error(\n                                            f\"Async client restart timed out after {max_wait_time} seconds. \"\n                                        )\n                                    break\n                            finally:\n                                # Re-acquire lock after sleep\n                                await self.async_lock.acquire()\n\n                    # Handle timeout case - must reset state regardless of timeout\n                    if self.async_in_use_counter &gt; 0:\n                        if self.logger:\n                            self.logger.error(\n                                \"Force resetting async client state due to timeout\"\n                            )\n                        self.async_in_use_counter = 0\n\n                    # Whether we timed out or not, we need to restart the client\n                    try:\n                        # Only close if client exists and is connected\n                        if (\n                            hasattr(self, \"async_client\")\n                            and self.async_client is not None\n                        ):\n                            await self.async_client.close()\n                        await asyncio.sleep(0.1)\n                        # Create a new client instance\n                        self.async_client = await self.get_async_client()\n                    except Exception as e:\n                        if self.logger:\n                            self.logger.error(\n                                f\"Error during async client restart: {str(e)}\"\n                            )\n                        # Create a new client anyway to ensure we have a valid client\n                        self.async_client = await self.get_async_client()\n                    finally:\n                        # CRITICAL: Always set the event to prevent deadlocks\n                        # This ensures waiting connections can proceed\n                        self.async_restart_event.set()\n\n            except Exception as e:\n                if self.logger:\n                    self.logger.error(\n                        f\"Unexpected error in async client restart: {str(e)}\"\n                    )\n                # Ensure the event is set in all error cases\n                self.async_restart_event.set()\n                # Attempt to create a new client\n                self.async_client = await self.get_async_client()\n\n    async def restart_client(self, force=False) -&gt; None:\n        \"\"\"\n        Restart the sync client if it has not been used in the last client_timeout minutes (set in init).\n        \"\"\"\n        if self.client_timeout == datetime.timedelta(minutes=0) and not force:\n            return\n\n        # First check if the client has been used in the last X minutes\n        if (\n            datetime.datetime.now() - self.last_used_sync_client &gt; self.client_timeout\n            or force\n        ):\n            # Use both locks to prevent any race conditions between sync and async operations\n            try:\n                # Acquire sync lock first\n                with self.sync_lock:\n                    # Clear event while holding the lock to prevent race conditions\n                    self.sync_restart_event.clear()\n\n                    # Record current counter value\n                    last_recorded_counter = self.sync_in_use_counter\n\n                    # Set reasonable timeout values\n                    time_spent = 0\n                    max_wait_time = 10  # seconds\n                    check_interval = 0.1  # seconds\n\n                    # Only wait if there are active connections\n                    if last_recorded_counter &gt; 0:\n                        # Wait for existing connections to complete\n                        while self.sync_in_use_counter &gt; 0:\n                            # Must release lock during async sleep to prevent deadlock\n                            self.sync_lock.release()\n\n                            # Only timeout after 10 seconds if nothing is happening\n                            # if the counter is changing, then things are happening and we should wait\n                            if self.sync_in_use_counter != last_recorded_counter:\n                                last_recorded_counter = self.sync_in_use_counter\n                                time_spent = 0\n\n                            try:\n                                await asyncio.sleep(check_interval)\n                                time_spent += check_interval\n                                if time_spent &gt; max_wait_time:\n                                    if self.logger:\n                                        self.logger.error(\n                                            f\"Sync client restart timed out after {max_wait_time}s. \"\n                                            f\"Initial counter: {last_recorded_counter}, Current: {self.sync_in_use_counter}\"\n                                        )\n                                    break\n                            finally:\n                                # Re-acquire lock\n                                self.sync_lock.acquire()\n\n                    # Handle timeout case - must reset state regardless of timeout\n                    if self.sync_in_use_counter &gt; 0:\n                        if self.logger:\n                            self.logger.error(\n                                \"Force resetting sync client state due to timeout\"\n                            )\n                        self.sync_in_use_counter = 0\n\n                    # Whether we timed out or not, we need to restart the client\n                    try:\n                        # Only close if client exists and is connected\n                        if hasattr(self, \"client\") and self.client is not None:\n                            self.client.close()\n                        await asyncio.sleep(0.1)\n                        # Create a new client instance\n                        self.client = self.get_client()\n                    except Exception as e:\n                        if self.logger:\n                            self.logger.error(\n                                f\"Error during sync client restart: {str(e)}\"\n                            )\n                        # Create a new client anyway\n                        self.client = self.get_client()\n                    finally:\n                        # CRITICAL: Always set the event to prevent deadlocks\n                        self.sync_restart_event.set()\n\n            except Exception as e:\n                if self.logger:\n                    self.logger.error(\n                        f\"Unexpected error in sync client restart: {str(e)}\"\n                    )\n                # Ensure the event is set in all error cases\n                self.sync_restart_event.set()\n                # Attempt to create a new client\n                self.client = self.get_client()\n\n    async def close_clients(self) -&gt; None:\n        \"\"\"\n        Close both the async and sync clients.\n        Should not be called inside a Tool or other function inside the decision tree.\n        \"\"\"\n        if hasattr(self, \"async_client\") and self.async_client is not None:\n            await self.async_client.close()\n        if hasattr(self, \"client\") and self.client is not None:\n            self.client.close()\n</code></pre>"},{"location":"Reference/Client/#elysia.util.client.ClientManager.__init__","title":"<code>__init__(wcd_url=None, wcd_api_key=None, client_timeout=None, logger=None, settings=None, **kwargs)</code>","text":"<p>Parameters:</p> Name Type Description Default <code>wcd_url</code> <code>str</code> <p>the url of the Weaviate cluster. Defaults to global settings config.</p> <code>None</code> <code>wcd_api_key</code> <code>str</code> <p>the api key for the Weaviate cluster. Defaults to global settings config.</p> <code>None</code> <code>client_timeout</code> <code>timedelta | int | None</code> <p>how long (in minutes) means the client should be restarted. Defaults to 3 minutes.</p> <code>None</code> <code>logger</code> <code>Logger | None</code> <p>a logger object for logging messages. Defaults to None.</p> <code>None</code> <code>settings</code> <code>Settings | None</code> <p>a settings object for the client manager. Defaults to environment settings.</p> <code>None</code> <code>**kwargs</code> <code>Any</code> <p>any other api keys for third party services (formatted as e.g. OPENAI_APIKEY).</p> <code>{}</code> <p>Example: <pre><code>client_manager = ClientManager(\n    wcd_url=\"https://my-weaviate-cluster...\",\n    wcd_api_key=\"my-api-key...\",\n    OPENAI_APIKEY=\"my-openai-api-key...\",\n    HUGGINGFACE_APIKEY=\"my-huggingface-api-key...\",\n)\n</code></pre></p> Source code in <code>elysia/util/client.py</code> <pre><code>def __init__(\n    self,\n    wcd_url: str | None = None,\n    wcd_api_key: str | None = None,\n    client_timeout: datetime.timedelta | int | None = None,\n    logger: Logger | None = None,\n    settings: Settings | None = None,\n    **kwargs,\n) -&gt; None:\n    \"\"\"\n    Args:\n        wcd_url (str): the url of the Weaviate cluster. Defaults to global settings config.\n        wcd_api_key (str): the api key for the Weaviate cluster. Defaults to global settings config.\n        client_timeout (datetime.timedelta | int | None): how long (in minutes) means the client should be restarted. Defaults to 3 minutes.\n        logger (Logger | None): a logger object for logging messages. Defaults to None.\n        settings (Settings | None): a settings object for the client manager. Defaults to environment settings.\n        **kwargs (Any): any other api keys for third party services (formatted as e.g. OPENAI_APIKEY).\n\n    Example:\n    ```python\n    client_manager = ClientManager(\n        wcd_url=\"https://my-weaviate-cluster...\",\n        wcd_api_key=\"my-api-key...\",\n        OPENAI_APIKEY=\"my-openai-api-key...\",\n        HUGGINGFACE_APIKEY=\"my-huggingface-api-key...\",\n    )\n    ```\n    \"\"\"\n\n    self.logger = logger\n\n    if client_timeout is None:\n        self.client_timeout = datetime.timedelta(\n            minutes=int(os.getenv(\"CLIENT_TIMEOUT\", 3))\n        )\n    elif isinstance(client_timeout, int):\n        self.client_timeout = datetime.timedelta(minutes=client_timeout)\n    else:\n        self.client_timeout = client_timeout\n\n    if settings is None:\n        self.settings = environment_settings\n    else:\n        self.settings = settings\n\n    # Set the weaviate cluster url and api key\n    if wcd_url is None:\n        self.wcd_url = self.settings.WCD_URL\n    else:\n        self.wcd_url = wcd_url\n\n    if wcd_api_key is None:\n        self.wcd_api_key = self.settings.WCD_API_KEY\n    else:\n        self.wcd_api_key = wcd_api_key\n\n    # Set the api keys for non weaviate cluster (third parties)\n    self.headers = {}\n    for api_key in self.settings.API_KEYS:\n        if api_key.lower() in [a.lower() for a in api_key_map.keys()]:\n            self.headers[api_key_map[api_key.upper()]] = self.settings.API_KEYS[\n                api_key\n            ]\n\n    # From kwargs\n    for kwarg in kwargs:\n        if kwarg.lower() in [a.lower() for a in api_key_map.keys()]:\n            self.headers[api_key_map[kwarg.upper()]] = kwargs[kwarg]\n\n    # Create locks for client events\n    self.async_lock = asyncio.Lock()\n    self.sync_lock = threading.Lock()\n\n    # In use counter tracks when the client is in use and by how many operations. 0 = can restart\n    self.async_in_use_counter = 0\n    self.sync_in_use_counter = 0\n    self.async_restart_event = asyncio.Event()\n    self.sync_restart_event = threading.Event()\n\n    self.last_used_sync_client = datetime.datetime.now()\n    self.last_used_async_client = datetime.datetime.now()\n\n    self.async_client = None\n    self.async_init_completed = False\n    self.is_client = self.wcd_url != \"\" and self.wcd_api_key != \"\"\n\n    if self.logger:\n        if self.wcd_api_key == \"\" and self.wcd_url == \"\":\n            self.logger.warning(\n                \"WCD_URL and WCD_API_KEY are not set. \"\n                \"All Weaviate functionality will be disabled.\"\n            )\n        elif self.wcd_url == \"\":\n            self.logger.warning(\n                \"WCD_URL is not set. \"\n                \"All Weaviate functionality will be disabled.\"\n            )\n        elif self.wcd_api_key == \"\":\n            self.logger.warning(\n                \"WCD_API_KEY is not set. \"\n                \"All Weaviate functionality will be disabled.\"\n            )\n        else:\n            self.logger.debug(\n                \"Weaviate client initialised. \"\n                \"All Weaviate functionality will be enabled.\"\n            )\n\n    if not self.is_client:\n        return\n\n    # Start sync client\n    self.client = self.get_client()\n    self.sync_restart_event.set()\n</code></pre>"},{"location":"Reference/Client/#elysia.util.client.ClientManager.close_clients","title":"<code>close_clients()</code>  <code>async</code>","text":"<p>Close both the async and sync clients. Should not be called inside a Tool or other function inside the decision tree.</p> Source code in <code>elysia/util/client.py</code> <pre><code>async def close_clients(self) -&gt; None:\n    \"\"\"\n    Close both the async and sync clients.\n    Should not be called inside a Tool or other function inside the decision tree.\n    \"\"\"\n    if hasattr(self, \"async_client\") and self.async_client is not None:\n        await self.async_client.close()\n    if hasattr(self, \"client\") and self.client is not None:\n        self.client.close()\n</code></pre>"},{"location":"Reference/Client/#elysia.util.client.ClientManager.connect_to_async_client","title":"<code>connect_to_async_client()</code>  <code>async</code>","text":"<p>A context manager to connect to the async client.</p> <p>E.g. <pre><code>async with client_manager.connect_to_async_client():\n    # do stuff with the async weaviate client\n    ...\n</code></pre></p> Source code in <code>elysia/util/client.py</code> <pre><code>@asynccontextmanager\nasync def connect_to_async_client(\n    self,\n) -&gt; AsyncGenerator[WeaviateAsyncClient, Any]:\n    \"\"\"\n    A context manager to connect to the _async_ client.\n\n    E.g.\n    ```python\n    async with client_manager.connect_to_async_client():\n        # do stuff with the async weaviate client\n        ...\n    ```\n    \"\"\"\n    if not self.is_client:\n        raise ValueError(\n            \"Weaviate is not available. Please set the WCD_URL and WCD_API_KEY in the settings.\"\n        )\n\n    if not self.async_init_completed:\n        await self.start_clients()\n\n    await self.async_restart_event.wait()\n    async with self.async_lock:\n        self.async_in_use_counter += 1\n\n    if self.async_client is None:\n        raise ValueError(\"Async client not initialised\")\n\n    if not self.async_client.is_connected():\n        await self.async_client.connect()\n\n    connection = _AsyncClientConnection(self, self.async_client)\n    async with connection:\n        yield connection.client\n</code></pre>"},{"location":"Reference/Client/#elysia.util.client.ClientManager.connect_to_client","title":"<code>connect_to_client()</code>","text":"<p>A context manager to connect to the sync client.</p> <p>E.g.</p> <pre><code>with client_manager.connect_to_client():\n    # do stuff with the weaviate client\n    ...\n</code></pre> Source code in <code>elysia/util/client.py</code> <pre><code>@contextmanager\ndef connect_to_client(self) -&gt; Generator[WeaviateClient, Any, None]:\n    \"\"\"\n    A context manager to connect to the _sync_ client.\n\n    E.g.\n\n    ```python\n    with client_manager.connect_to_client():\n        # do stuff with the weaviate client\n        ...\n    ```\n    \"\"\"\n    if not self.is_client:\n        raise ValueError(\n            \"Weaviate is not available. Please set the WCD_URL and WCD_API_KEY in the settings.\"\n        )\n\n    self.sync_restart_event.wait()\n    with self.sync_lock:\n        self.sync_in_use_counter += 1\n\n    if not self.client.is_connected():\n        self.client.connect()\n\n    connection = _ClientConnection(self, self.client)\n    with connection:\n        yield connection.client\n</code></pre>"},{"location":"Reference/Client/#elysia.util.client.ClientManager.reset_keys","title":"<code>reset_keys(wcd_url=None, wcd_api_key=None, api_keys={})</code>  <code>async</code>","text":"<p>Set the API keys, WCD_URL and WCD_API_KEY from the settings object.</p> <p>Parameters:</p> Name Type Description Default <code>wcd_url</code> <code>str</code> <p>the url of the Weaviate cluster.</p> <code>None</code> <code>wcd_api_key</code> <code>str</code> <p>the api key for the Weaviate cluster.</p> <code>None</code> <code>api_keys</code> <code>dict</code> <p>a dictionary of api keys for third party services.</p> <code>{}</code> Source code in <code>elysia/util/client.py</code> <pre><code>async def reset_keys(\n    self,\n    wcd_url: str | None = None,\n    wcd_api_key: str | None = None,\n    api_keys: dict[str, str] = {},\n) -&gt; None:\n    \"\"\"\n    Set the API keys, WCD_URL and WCD_API_KEY from the settings object.\n\n    Args:\n        wcd_url (str): the url of the Weaviate cluster.\n        wcd_api_key (str): the api key for the Weaviate cluster.\n        api_keys (dict): a dictionary of api keys for third party services.\n    \"\"\"\n    self.wcd_url = wcd_url\n    self.wcd_api_key = wcd_api_key\n\n    self.headers = {}\n\n    for api_key in api_keys:\n        if api_key.lower() in [a.lower() for a in api_key_map.keys()]:\n            self.headers[api_key_map[api_key.upper()]] = api_keys[api_key]\n\n    self.is_client = self.wcd_url != \"\" and self.wcd_api_key != \"\"\n    if self.is_client:\n        await self.restart_client(force=True)\n        await self.restart_async_client(force=True)\n        await self.start_clients()\n</code></pre>"},{"location":"Reference/Client/#elysia.util.client.ClientManager.restart_async_client","title":"<code>restart_async_client(force=False)</code>  <code>async</code>","text":"<p>Restart the async client if it has not been used in the last client_timeout minutes (set in init).</p> Source code in <code>elysia/util/client.py</code> <pre><code>async def restart_async_client(self, force=False) -&gt; None:\n    \"\"\"\n    Restart the async client if it has not been used in the last client_timeout minutes (set in init).\n    \"\"\"\n    if self.client_timeout == datetime.timedelta(minutes=0) and not force:\n        return\n\n    # First check if the client has been used in the last X minutes\n    if (\n        datetime.datetime.now() - self.last_used_async_client &gt; self.client_timeout\n        or force\n    ):\n        # Acquire lock before modifying shared state to prevent race conditions\n        try:\n            async with self.async_lock:\n                # Clear the event WHILE holding the lock to prevent new connections from starting\n                # This ensures no new connections can proceed until we're done\n                self.async_restart_event.clear()\n\n                # Record current counter value before waiting\n                last_recorded_counter = self.async_in_use_counter\n\n                # Set reasonable timeout values\n                time_spent = 0\n                max_wait_time = 10  # seconds\n                check_interval = 0.1  # seconds\n\n                # Only wait if there are active connections\n                if last_recorded_counter &gt; 0:\n                    # Wait for existing connections to complete\n                    while self.async_in_use_counter &gt; 0:\n                        # Release lock during sleep to prevent deadlock\n                        self.async_lock.release()\n\n                        # Only timeout after 10 seconds if nothing is happening\n                        # if the counter is changing, then things are happening and we should wait\n                        if self.async_in_use_counter != last_recorded_counter:\n                            last_recorded_counter = self.async_in_use_counter\n                            time_spent = 0\n\n                        try:\n                            await asyncio.sleep(check_interval)\n                            time_spent += check_interval\n                            if time_spent &gt; max_wait_time:\n                                if self.logger:\n                                    self.logger.error(\n                                        f\"Async client restart timed out after {max_wait_time} seconds. \"\n                                    )\n                                break\n                        finally:\n                            # Re-acquire lock after sleep\n                            await self.async_lock.acquire()\n\n                # Handle timeout case - must reset state regardless of timeout\n                if self.async_in_use_counter &gt; 0:\n                    if self.logger:\n                        self.logger.error(\n                            \"Force resetting async client state due to timeout\"\n                        )\n                    self.async_in_use_counter = 0\n\n                # Whether we timed out or not, we need to restart the client\n                try:\n                    # Only close if client exists and is connected\n                    if (\n                        hasattr(self, \"async_client\")\n                        and self.async_client is not None\n                    ):\n                        await self.async_client.close()\n                    await asyncio.sleep(0.1)\n                    # Create a new client instance\n                    self.async_client = await self.get_async_client()\n                except Exception as e:\n                    if self.logger:\n                        self.logger.error(\n                            f\"Error during async client restart: {str(e)}\"\n                        )\n                    # Create a new client anyway to ensure we have a valid client\n                    self.async_client = await self.get_async_client()\n                finally:\n                    # CRITICAL: Always set the event to prevent deadlocks\n                    # This ensures waiting connections can proceed\n                    self.async_restart_event.set()\n\n        except Exception as e:\n            if self.logger:\n                self.logger.error(\n                    f\"Unexpected error in async client restart: {str(e)}\"\n                )\n            # Ensure the event is set in all error cases\n            self.async_restart_event.set()\n            # Attempt to create a new client\n            self.async_client = await self.get_async_client()\n</code></pre>"},{"location":"Reference/Client/#elysia.util.client.ClientManager.restart_client","title":"<code>restart_client(force=False)</code>  <code>async</code>","text":"<p>Restart the sync client if it has not been used in the last client_timeout minutes (set in init).</p> Source code in <code>elysia/util/client.py</code> <pre><code>async def restart_client(self, force=False) -&gt; None:\n    \"\"\"\n    Restart the sync client if it has not been used in the last client_timeout minutes (set in init).\n    \"\"\"\n    if self.client_timeout == datetime.timedelta(minutes=0) and not force:\n        return\n\n    # First check if the client has been used in the last X minutes\n    if (\n        datetime.datetime.now() - self.last_used_sync_client &gt; self.client_timeout\n        or force\n    ):\n        # Use both locks to prevent any race conditions between sync and async operations\n        try:\n            # Acquire sync lock first\n            with self.sync_lock:\n                # Clear event while holding the lock to prevent race conditions\n                self.sync_restart_event.clear()\n\n                # Record current counter value\n                last_recorded_counter = self.sync_in_use_counter\n\n                # Set reasonable timeout values\n                time_spent = 0\n                max_wait_time = 10  # seconds\n                check_interval = 0.1  # seconds\n\n                # Only wait if there are active connections\n                if last_recorded_counter &gt; 0:\n                    # Wait for existing connections to complete\n                    while self.sync_in_use_counter &gt; 0:\n                        # Must release lock during async sleep to prevent deadlock\n                        self.sync_lock.release()\n\n                        # Only timeout after 10 seconds if nothing is happening\n                        # if the counter is changing, then things are happening and we should wait\n                        if self.sync_in_use_counter != last_recorded_counter:\n                            last_recorded_counter = self.sync_in_use_counter\n                            time_spent = 0\n\n                        try:\n                            await asyncio.sleep(check_interval)\n                            time_spent += check_interval\n                            if time_spent &gt; max_wait_time:\n                                if self.logger:\n                                    self.logger.error(\n                                        f\"Sync client restart timed out after {max_wait_time}s. \"\n                                        f\"Initial counter: {last_recorded_counter}, Current: {self.sync_in_use_counter}\"\n                                    )\n                                break\n                        finally:\n                            # Re-acquire lock\n                            self.sync_lock.acquire()\n\n                # Handle timeout case - must reset state regardless of timeout\n                if self.sync_in_use_counter &gt; 0:\n                    if self.logger:\n                        self.logger.error(\n                            \"Force resetting sync client state due to timeout\"\n                        )\n                    self.sync_in_use_counter = 0\n\n                # Whether we timed out or not, we need to restart the client\n                try:\n                    # Only close if client exists and is connected\n                    if hasattr(self, \"client\") and self.client is not None:\n                        self.client.close()\n                    await asyncio.sleep(0.1)\n                    # Create a new client instance\n                    self.client = self.get_client()\n                except Exception as e:\n                    if self.logger:\n                        self.logger.error(\n                            f\"Error during sync client restart: {str(e)}\"\n                        )\n                    # Create a new client anyway\n                    self.client = self.get_client()\n                finally:\n                    # CRITICAL: Always set the event to prevent deadlocks\n                    self.sync_restart_event.set()\n\n        except Exception as e:\n            if self.logger:\n                self.logger.error(\n                    f\"Unexpected error in sync client restart: {str(e)}\"\n                )\n            # Ensure the event is set in all error cases\n            self.sync_restart_event.set()\n            # Attempt to create a new client\n            self.client = self.get_client()\n</code></pre>"},{"location":"Reference/Client/#elysia.util.client.ClientManager.start_clients","title":"<code>start_clients()</code>  <code>async</code>","text":"<p>Start the async and sync clients if they are not already running.</p> Source code in <code>elysia/util/client.py</code> <pre><code>async def start_clients(self) -&gt; None:\n    \"\"\"\n    Start the async and sync clients if they are not already running.\n    \"\"\"\n\n    if not self.is_client:\n        raise ValueError(\n            \"Weaviate is not available. Please set the WCD_URL and WCD_API_KEY in the settings.\"\n        )\n\n    if self.async_client is None:\n        self.async_client = await self.get_async_client()\n        self.async_restart_event.set()\n\n    if not self.async_client.is_connected():\n        await self.async_client.connect()\n\n    self.async_init_completed = True\n\n    if not self.client.is_connected():\n        self.client.connect()\n</code></pre>"},{"location":"Reference/Managers/","title":"Managers","text":""},{"location":"Reference/Managers/#elysia.api.services.user.UserManager","title":"<code>UserManager</code>","text":"<p>The UserManager is designed to manage, for each user:</p> <ul> <li>TreeManager</li> <li>ClientManager</li> <li>FrontendConfig</li> </ul> <p>It contains methods for creating and updating these objects across a range of users, stored in a dictionary. It can be used as a dependency injection container for FastAPI. The user manager/tree manager is decoupled from the core of the Elysia package functionality. It is designed to be used to manage separate Elysia instances, set of trees (via tree managers), configs, etc.</p> Source code in <code>elysia/api/services/user.py</code> <pre><code>class UserManager:\n    \"\"\"\n    The UserManager is designed to manage, for each user:\n\n    - TreeManager\n    - ClientManager\n    - FrontendConfig\n\n    It contains methods for creating and updating these objects across a range of users, stored in a dictionary.\n    It can be used as a dependency injection container for FastAPI.\n    The user manager/tree manager is decoupled from the core of the Elysia package functionality.\n    It is designed to be used to manage separate Elysia instances, set of trees (via tree managers), configs, etc.\n    \"\"\"\n\n    def __init__(\n        self,\n        user_timeout: datetime.timedelta | int | None = None,\n    ):\n        \"\"\"\n        Args:\n            user_timeout (datetime.timedelta | int | None): Optional.\n                The length of time a user can be idle before being timed out.\n                Defaults to 20 minutes or the value of the USER_TIMEOUT environment variable.\n                If an integer is provided, it is interpreted as the number of minutes.\n        \"\"\"\n        if user_timeout is None:\n            self.user_timeout = datetime.timedelta(\n                minutes=int(os.environ.get(\"USER_TIMEOUT\", 20))\n            )\n        elif isinstance(user_timeout, int):\n            self.user_timeout = datetime.timedelta(minutes=user_timeout)\n        else:\n            self.user_timeout = user_timeout\n\n        self.manager_id = random.randint(0, 1000000)\n        self.date_of_reset = None\n        self.users = {}\n\n    def user_exists(self, user_id: str):\n        return user_id in self.users\n\n    async def update_config(\n        self,\n        user_id: str,\n        conversation_id: str | None = None,\n        config_id: str | None = None,\n        config_name: str | None = None,\n        settings: dict[str, Any] | None = None,\n        style: str | None = None,\n        agent_description: str | None = None,\n        end_goal: str | None = None,\n        branch_initialisation: str | None = None,\n    ):\n        local_user = await self.get_user_local(user_id)\n        local_user[\"tree_manager\"].update_config(\n            conversation_id,\n            config_id,\n            config_name,\n            settings,\n            style,\n            agent_description,\n            end_goal,\n            branch_initialisation,\n        )\n\n        await local_user[\"client_manager\"].reset_keys(\n            wcd_url=local_user[\"tree_manager\"].settings.WCD_URL,\n            wcd_api_key=local_user[\"tree_manager\"].settings.WCD_API_KEY,\n            api_keys=local_user[\"tree_manager\"].settings.API_KEYS,\n        )\n\n    async def update_frontend_config(\n        self,\n        user_id: str,\n        config: dict[str, Any],\n    ):\n        local_user = await self.get_user_local(user_id)\n        frontend_config: FrontendConfig = local_user[\"frontend_config\"]\n        await frontend_config.configure(**config)\n\n    async def add_user_local(\n        self,\n        user_id: str,\n        config: Config | None = None,\n    ):\n        \"\"\"\n        Add a user to the UserManager.\n\n        Args:\n            user_id (str): Required. The unique identifier for the user.\n            config (Config): Required. The config for the user.\n        \"\"\"\n\n        # add user if it doesn't exist\n        if user_id not in self.users:\n            self.users[user_id] = {}\n\n            fe_config = await load_frontend_config_from_file(user_id, logger)\n\n            self.users[user_id][\"frontend_config\"] = fe_config\n\n            self.users[user_id][\"tree_manager\"] = TreeManager(\n                user_id=user_id,\n                config=config,\n                tree_timeout=fe_config.config[\"tree_timeout\"],\n            )\n\n            # client manager starts with env variables, when config is updated, api keys are updated\n            self.users[user_id][\"client_manager\"] = ClientManager(\n                logger=logger,\n                client_timeout=fe_config.config[\"client_timeout\"],\n                settings=self.users[user_id][\"tree_manager\"].config.settings,\n            )\n\n    async def get_user_local(self, user_id: str):\n        \"\"\"\n        Return a local user object.\n        Will raise a ValueError if the user is not found.\n\n        Args:\n            user_id (str): Required. The unique identifier for the user.\n\n        Returns:\n            (dict): A local user object, containing a TreeManager (\"tree_manager\"),\n                Frontend Config (\"frontend_config\") and ClientManager (\"client_manager\").\n        \"\"\"\n\n        if user_id not in self.users:\n            raise ValueError(\n                f\"User {user_id} not found. Please initialise a user first (by calling `add_user_local`).\"\n            )\n\n        # update last request (adds last_request to user)\n        await self.update_user_last_request(user_id)\n\n        return self.users[user_id]\n\n    async def get_tree(self, user_id: str, conversation_id: str):\n        \"\"\"\n        Get a tree for a user.\n        Will raise a ValueError if the user is not found, or the tree is not found.\n\n        Args:\n            user_id (str): Required. The unique identifier for the user.\n            conversation_id (str): Required. The unique identifier for the conversation.\n\n        Returns:\n            (Tree): The tree.\n        \"\"\"\n        local_user = await self.get_user_local(user_id)\n        return local_user[\"tree_manager\"].get_tree(conversation_id)\n\n    async def check_all_trees_timeout(self):\n        \"\"\"\n        Check all trees in all TreeManagers across all users and remove any that have not been active in the last tree_timeout.\n        \"\"\"\n        for user_id in self.users:\n            self.users[user_id][\"tree_manager\"].check_all_trees_timeout()\n\n    def check_user_timeout(self, user_id: str):\n        \"\"\"\n        Check if a user has been idle for the last user_timeout.\n\n        Args:\n            user_id (str): The user ID which contains the user.\n\n        Returns:\n            (bool): True if the user has been idle for the last user_timeout, False otherwise.\n        \"\"\"\n        # if user not found, return True\n        if user_id not in self.users:\n            return True\n\n        # Remove any trees that have not been active in the last user_timeout\n        # if (\n        #     \"last_request\" in self.users[user_id]\n        #     and datetime.datetime.now() - self.users[user_id][\"last_request\"]\n        #     &gt; self.user_timeout\n        # ):\n        #     return True\n\n        return False\n\n    async def check_all_users_timeout(self):\n        \"\"\"\n        Check all users in the UserManager and remove any that have not been active in the last user_timeout.\n        \"\"\"\n        if self.user_timeout == datetime.timedelta(minutes=0):\n            return\n\n        for user_id in self.users:\n            if self.check_user_timeout(user_id):\n                del self.users[user_id]\n\n    async def check_restart_clients(self):\n        \"\"\"\n        Check all clients in all ClientManagers across all users and run the restart_client() method (for sync and async clients).\n        The restart_client() methods will check if the client has been inactive for the last client_timeout minutes (set in init).\n        \"\"\"\n        for user_id in self.users:\n            if (\n                \"client_manager\" in self.users[user_id]\n                and self.users[user_id][\"client_manager\"].is_client\n            ):\n                await self.users[user_id][\"client_manager\"].restart_client()\n                await self.users[user_id][\"client_manager\"].restart_async_client()\n\n    async def close_all_clients(self):\n        \"\"\"\n        Close all clients in all ClientManagers across all users.\n        \"\"\"\n        for user_id in self.users:\n            if \"client_manager\" in self.users[user_id]:\n                await self.users[user_id][\"client_manager\"].close_clients()\n\n    async def initialise_tree(\n        self,\n        user_id: str,\n        conversation_id: str,\n        low_memory: bool = False,\n    ):\n        \"\"\"\n        Initialises a tree for a user for an existing user at user_id.\n        Requires a user to already exist in the UserManager, via `add_user_local`.\n        This is a wrapper for the TreeManager.add_tree() method.\n\n        Args:\n            user_id (str): Required. The unique identifier for the user.\n            conversation_id (str): Required. The unique identifier for a new conversation within the tree manager.\n            low_memory (bool): Optional. Whether to use low memory mode for the tree.\n                Controls the LM history being saved in the tree, and some other variables.\n                Defaults to False.\n        \"\"\"\n        # self.add_user_local(user_id)\n        local_user = await self.get_user_local(user_id)\n        tree_manager: TreeManager = local_user[\"tree_manager\"]\n        if not tree_manager.tree_exists(conversation_id):\n            tree_manager.add_tree(\n                conversation_id,\n                low_memory,\n            )\n        return tree_manager.get_tree(conversation_id)\n\n    async def save_tree(\n        self,\n        user_id: str,\n        conversation_id: str,\n        wcd_url: str | None = None,\n        wcd_api_key: str | None = None,\n    ):\n        \"\"\"\n        Save a tree to a Weaviate instance (set in the frontend config).\n        This is a wrapper for the TreeManager.save_tree_weaviate() method.\n\n        Args:\n            user_id (str): Required. The unique identifier for the user stored in the UserManager.\n            conversation_id (str): Required. The unique identifier for the conversation for the user.\n        \"\"\"\n\n        local_user = await self.get_user_local(user_id)\n        tree_manager: TreeManager = local_user[\"tree_manager\"]\n\n        if wcd_url is None or wcd_api_key is None:\n            save_location_client_manager = local_user[\n                \"frontend_config\"\n            ].save_location_client_manager\n        else:\n            save_location_client_manager = ClientManager(\n                logger=logger,\n                wcd_url=wcd_url,\n                wcd_api_key=wcd_api_key,\n            )\n\n        await tree_manager.save_tree_weaviate(\n            conversation_id, save_location_client_manager\n        )\n\n    async def check_tree_exists_weaviate(\n        self,\n        user_id: str,\n        conversation_id: str,\n        wcd_url: str | None = None,\n        wcd_api_key: str | None = None,\n    ):\n        \"\"\"\n        Check if a tree exists in a Weaviate instance (set in the frontend config).\n\n        Args:\n            user_id (str): Required. The unique identifier for the user stored in the UserManager.\n            conversation_id (str): Required. The unique identifier for the conversation for the user.\n            wcd_url (str | None): Required. The URL of the Weaviate Cloud Database instance used to save the tree.\n                Defaults to the value of the `wcd_url` setting in the frontend config.\n            wcd_api_key (str | None): Required. The API key for the Weaviate Cloud Database instance used to save the tree.\n                Defaults to the value of the `wcd_api_key` setting in the frontend config.\n\n        Returns:\n            (bool): True if the tree exists in the Weaviate instance, False otherwise.\n        \"\"\"\n\n        local_user = await self.get_user_local(user_id)\n        tree_manager: TreeManager = local_user[\"tree_manager\"]\n\n        if wcd_url is None or wcd_api_key is None:\n            save_location_client_manager = local_user[\n                \"frontend_config\"\n            ].save_location_client_manager\n        else:\n            save_location_client_manager = ClientManager(\n                logger=logger,\n                wcd_url=wcd_url,\n                wcd_api_key=wcd_api_key,\n            )\n\n        return await tree_manager.check_tree_exists_weaviate(\n            conversation_id, save_location_client_manager\n        )\n\n    async def load_tree(\n        self,\n        user_id: str,\n        conversation_id: str,\n        wcd_url: str | None = None,\n        wcd_api_key: str | None = None,\n    ):\n        \"\"\"\n        Load a tree from a Weaviate instance (set in the frontend config).\n        This is a wrapper for the TreeManager.load_tree_weaviate() method.\n\n        Args:\n            user_id (str): Required. The unique identifier for the user stored in the UserManager.\n            conversation_id (str): Required. The unique identifier for the conversation for the user.\n            wcd_url (str | None): Required. The URL of the Weaviate Cloud Database instance used to save the tree.\n                Defaults to the value of the `wcd_url` setting in the frontend config.\n            wcd_api_key (str | None): Required. The API key for the Weaviate Cloud Database instance used to save the tree.\n                Defaults to the value of the `wcd_api_key` setting in the frontend config.\n\n        Returns:\n            (list[dict]): A list of dictionaries, each containing a frontend payload that was used to generate the tree.\n                The list is ordered by the time the payload was originally sent to the frontend (at the time it was saved).\n        \"\"\"\n\n        local_user = await self.get_user_local(user_id)\n        tree_manager: TreeManager = local_user[\"tree_manager\"]\n\n        if wcd_url is None or wcd_api_key is None:\n            save_location_client_manager = local_user[\n                \"frontend_config\"\n            ].save_location_client_manager\n        else:\n            save_location_client_manager = ClientManager(\n                logger=logger,\n                wcd_url=wcd_url,\n                wcd_api_key=wcd_api_key,\n            )\n\n        return await tree_manager.load_tree_weaviate(\n            conversation_id, save_location_client_manager\n        )\n\n    async def delete_tree(\n        self,\n        user_id: str,\n        conversation_id: str,\n        wcd_url: str | None = None,\n        wcd_api_key: str | None = None,\n    ):\n        \"\"\"\n        Delete a saved tree from a Weaviate instance (set in the frontend config).\n        Also delete the tree from the local tree manager.\n        This is a wrapper for the TreeManager.delete_tree_weaviate() method and the TreeManager.delete_tree_local() method.\n\n        Args:\n            user_id (str): Required. The unique identifier for the user stored in the UserManager.\n            conversation_id (str): Required. The unique identifier for the conversation for the user.\n            wcd_url (str | None): Required. The URL of the Weaviate Cloud Database instance used to save the tree.\n                Defaults to the value of the `wcd_url` setting in the frontend config.\n            wcd_api_key (str | None): Required. The API key for the Weaviate Cloud Database instance used to save the tree.\n                Defaults to the value of the `wcd_api_key` setting in the frontend config.\n        \"\"\"\n\n        local_user = await self.get_user_local(user_id)\n        tree_manager: TreeManager = local_user[\"tree_manager\"]\n\n        if wcd_url is None or wcd_api_key is None:\n            save_location_client_manager = local_user[\n                \"frontend_config\"\n            ].save_location_client_manager\n        else:\n            save_location_client_manager = ClientManager(\n                logger=logger,\n                wcd_url=wcd_url,\n                wcd_api_key=wcd_api_key,\n            )\n\n        await tree_manager.delete_tree_weaviate(\n            conversation_id, save_location_client_manager\n        )\n        tree_manager.delete_tree_local(conversation_id)\n\n    async def get_saved_trees(\n        self,\n        user_id: str,\n        wcd_url: str | None = None,\n        wcd_api_key: str | None = None,\n    ):\n        \"\"\"\n        Get all saved trees from a Weaviate instance (set in the frontend config).\n\n        Args:\n            user_id (str): Required. The unique identifier for the user stored in the UserManager.\n            wcd_url (str | None): Required. The URL of the Weaviate Cloud Database instance used to save the tree.\n                Defaults to the value of the `wcd_url` setting in the frontend config.\n            wcd_api_key (str | None): Required. The API key for the Weaviate Cloud Database instance used to save the tree.\n                Defaults to the value of the `wcd_api_key` setting in the frontend config.\n\n        Returns:\n            (dict): A dictionary whose keys are the conversation IDs and whose values are dictionaries containing the title and last update time of the tree.\n                E.g.\n                ```\n                {\n                    \"12345678-XXX-YYYY-ZZZZ\": {\n                        \"title\": \"Query Request\",\n                        \"last_update_time\": \"2025-06-07T10:06:47.376000Z\"\n                    }\n                }\n                ```\n        \"\"\"\n        local_user = await self.get_user_local(user_id)\n\n        if wcd_url is None or wcd_api_key is None:\n            save_location_client_manager = local_user[\n                \"frontend_config\"\n            ].save_location_client_manager\n        else:\n            save_location_client_manager = ClientManager(\n                logger=logger,\n                wcd_url=wcd_url,\n                wcd_api_key=wcd_api_key,\n            )\n\n        return await get_saved_trees_weaviate(\n            \"ELYSIA_TREES__\", save_location_client_manager, user_id\n        )\n\n    async def update_user_last_request(self, user_id: str):\n        self.users[user_id][\"last_request\"] = datetime.datetime.now()\n\n    def check_tree_timeout(self, user_id: str, conversation_id: str):\n        if user_id not in self.users:\n            return True\n        elif conversation_id not in self.users[user_id][\"tree_manager\"].trees:\n            return True\n        return False\n\n    async def process_tree(\n        self,\n        query: str,\n        user_id: str,\n        conversation_id: str,\n        query_id: str,\n        training_route: str = \"\",\n        collection_names: list[str] = [],\n        save_trees_to_weaviate: bool | None = None,\n        wcd_url: str | None = None,\n        wcd_api_key: str | None = None,\n    ):\n        \"\"\"\n        Wrapper for the TreeManager.process_tree() method.\n        Which itself is a wrapper for the Tree.async_run() method.\n        This is an async generator which yields results from the tree.async_run() method.\n        Automatically sends error payloads if the user or tree has been timed out.\n\n        Args:\n            query (str): Required. The user input/prompt to process in the decision tree.\n            user_id (str): Required. The unique identifier for the user.\n            conversation_id (str): Required. The conversation ID which contains the tree.\n                This should be the same conversation ID as the one used to initialise the tree (see `initialise_tree`).\n            query_id (str): Required. A unique identifier for the query.\n            training_route (str): Optional. The training route, a string of the form \"tool1/tool2/tool1\" etc.\n                See the `tree.async_run()` method for more details.\n            collection_names (list[str]): Optional. A list of collection names to use in the query.\n                If not supplied, all collections will be used.\n            save_trees_to_weaviate (bool | None): Optional. Whether to save the trees to a Weaviate instance,\n                after the process_tree() method has finished.\n                Defaults to the value of the `save_trees_to_weaviate` setting in the frontend config.\n            wcd_url (str | None): Required. The URL of the Weaviate Cloud Database instance used to save the tree.\n                Defaults to the value of the `wcd_url` setting in the frontend config.\n            wcd_api_key (str | None): Required. The API key for the Weaviate Cloud Database instance used to save the tree.\n                Defaults to the value of the `wcd_api_key` setting in the frontend config.\n        \"\"\"\n\n        if self.check_user_timeout(user_id):\n            user_timeout_error = UserTimeoutError()\n            error_payload = await user_timeout_error.to_frontend(\n                user_id, conversation_id, query_id\n            )\n            yield error_payload\n            return\n\n        if self.check_tree_timeout(user_id, conversation_id):\n            if await self.check_tree_exists_weaviate(user_id, conversation_id):\n                await self.load_tree(user_id, conversation_id)\n            else:\n                tree_timeout_error = TreeTimeoutError()\n                error_payload = await tree_timeout_error.to_frontend(\n                    user_id, conversation_id, query_id\n                )\n                yield error_payload\n                return\n\n        local_user = await self.get_user_local(user_id)\n        await self.update_user_last_request(user_id)\n\n        tree_manager: TreeManager = local_user[\"tree_manager\"]\n\n        async for yielded_result in tree_manager.process_tree(\n            query,\n            conversation_id,\n            query_id,\n            training_route,\n            collection_names,\n            local_user[\"client_manager\"],\n        ):\n            yield yielded_result\n            await self.update_user_last_request(user_id)\n\n        if save_trees_to_weaviate is None:\n            frontend_config: FrontendConfig = local_user[\"frontend_config\"]\n            save_trees_to_weaviate = frontend_config.config[\"save_trees_to_weaviate\"]\n\n        if save_trees_to_weaviate:\n            await self.save_tree(user_id, conversation_id, wcd_url, wcd_api_key)\n</code></pre>"},{"location":"Reference/Managers/#elysia.api.services.user.UserManager.__init__","title":"<code>__init__(user_timeout=None)</code>","text":"<p>Parameters:</p> Name Type Description Default <code>user_timeout</code> <code>timedelta | int | None</code> <p>Optional. The length of time a user can be idle before being timed out. Defaults to 20 minutes or the value of the USER_TIMEOUT environment variable. If an integer is provided, it is interpreted as the number of minutes.</p> <code>None</code> Source code in <code>elysia/api/services/user.py</code> <pre><code>def __init__(\n    self,\n    user_timeout: datetime.timedelta | int | None = None,\n):\n    \"\"\"\n    Args:\n        user_timeout (datetime.timedelta | int | None): Optional.\n            The length of time a user can be idle before being timed out.\n            Defaults to 20 minutes or the value of the USER_TIMEOUT environment variable.\n            If an integer is provided, it is interpreted as the number of minutes.\n    \"\"\"\n    if user_timeout is None:\n        self.user_timeout = datetime.timedelta(\n            minutes=int(os.environ.get(\"USER_TIMEOUT\", 20))\n        )\n    elif isinstance(user_timeout, int):\n        self.user_timeout = datetime.timedelta(minutes=user_timeout)\n    else:\n        self.user_timeout = user_timeout\n\n    self.manager_id = random.randint(0, 1000000)\n    self.date_of_reset = None\n    self.users = {}\n</code></pre>"},{"location":"Reference/Managers/#elysia.api.services.user.UserManager.add_user_local","title":"<code>add_user_local(user_id, config=None)</code>  <code>async</code>","text":"<p>Add a user to the UserManager.</p> <p>Parameters:</p> Name Type Description Default <code>user_id</code> <code>str</code> <p>Required. The unique identifier for the user.</p> required <code>config</code> <code>Config</code> <p>Required. The config for the user.</p> <code>None</code> Source code in <code>elysia/api/services/user.py</code> <pre><code>async def add_user_local(\n    self,\n    user_id: str,\n    config: Config | None = None,\n):\n    \"\"\"\n    Add a user to the UserManager.\n\n    Args:\n        user_id (str): Required. The unique identifier for the user.\n        config (Config): Required. The config for the user.\n    \"\"\"\n\n    # add user if it doesn't exist\n    if user_id not in self.users:\n        self.users[user_id] = {}\n\n        fe_config = await load_frontend_config_from_file(user_id, logger)\n\n        self.users[user_id][\"frontend_config\"] = fe_config\n\n        self.users[user_id][\"tree_manager\"] = TreeManager(\n            user_id=user_id,\n            config=config,\n            tree_timeout=fe_config.config[\"tree_timeout\"],\n        )\n\n        # client manager starts with env variables, when config is updated, api keys are updated\n        self.users[user_id][\"client_manager\"] = ClientManager(\n            logger=logger,\n            client_timeout=fe_config.config[\"client_timeout\"],\n            settings=self.users[user_id][\"tree_manager\"].config.settings,\n        )\n</code></pre>"},{"location":"Reference/Managers/#elysia.api.services.user.UserManager.check_all_trees_timeout","title":"<code>check_all_trees_timeout()</code>  <code>async</code>","text":"<p>Check all trees in all TreeManagers across all users and remove any that have not been active in the last tree_timeout.</p> Source code in <code>elysia/api/services/user.py</code> <pre><code>async def check_all_trees_timeout(self):\n    \"\"\"\n    Check all trees in all TreeManagers across all users and remove any that have not been active in the last tree_timeout.\n    \"\"\"\n    for user_id in self.users:\n        self.users[user_id][\"tree_manager\"].check_all_trees_timeout()\n</code></pre>"},{"location":"Reference/Managers/#elysia.api.services.user.UserManager.check_all_users_timeout","title":"<code>check_all_users_timeout()</code>  <code>async</code>","text":"<p>Check all users in the UserManager and remove any that have not been active in the last user_timeout.</p> Source code in <code>elysia/api/services/user.py</code> <pre><code>async def check_all_users_timeout(self):\n    \"\"\"\n    Check all users in the UserManager and remove any that have not been active in the last user_timeout.\n    \"\"\"\n    if self.user_timeout == datetime.timedelta(minutes=0):\n        return\n\n    for user_id in self.users:\n        if self.check_user_timeout(user_id):\n            del self.users[user_id]\n</code></pre>"},{"location":"Reference/Managers/#elysia.api.services.user.UserManager.check_restart_clients","title":"<code>check_restart_clients()</code>  <code>async</code>","text":"<p>Check all clients in all ClientManagers across all users and run the restart_client() method (for sync and async clients). The restart_client() methods will check if the client has been inactive for the last client_timeout minutes (set in init).</p> Source code in <code>elysia/api/services/user.py</code> <pre><code>async def check_restart_clients(self):\n    \"\"\"\n    Check all clients in all ClientManagers across all users and run the restart_client() method (for sync and async clients).\n    The restart_client() methods will check if the client has been inactive for the last client_timeout minutes (set in init).\n    \"\"\"\n    for user_id in self.users:\n        if (\n            \"client_manager\" in self.users[user_id]\n            and self.users[user_id][\"client_manager\"].is_client\n        ):\n            await self.users[user_id][\"client_manager\"].restart_client()\n            await self.users[user_id][\"client_manager\"].restart_async_client()\n</code></pre>"},{"location":"Reference/Managers/#elysia.api.services.user.UserManager.check_tree_exists_weaviate","title":"<code>check_tree_exists_weaviate(user_id, conversation_id, wcd_url=None, wcd_api_key=None)</code>  <code>async</code>","text":"<p>Check if a tree exists in a Weaviate instance (set in the frontend config).</p> <p>Parameters:</p> Name Type Description Default <code>user_id</code> <code>str</code> <p>Required. The unique identifier for the user stored in the UserManager.</p> required <code>conversation_id</code> <code>str</code> <p>Required. The unique identifier for the conversation for the user.</p> required <code>wcd_url</code> <code>str | None</code> <p>Required. The URL of the Weaviate Cloud Database instance used to save the tree. Defaults to the value of the <code>wcd_url</code> setting in the frontend config.</p> <code>None</code> <code>wcd_api_key</code> <code>str | None</code> <p>Required. The API key for the Weaviate Cloud Database instance used to save the tree. Defaults to the value of the <code>wcd_api_key</code> setting in the frontend config.</p> <code>None</code> <p>Returns:</p> Type Description <code>bool</code> <p>True if the tree exists in the Weaviate instance, False otherwise.</p> Source code in <code>elysia/api/services/user.py</code> <pre><code>async def check_tree_exists_weaviate(\n    self,\n    user_id: str,\n    conversation_id: str,\n    wcd_url: str | None = None,\n    wcd_api_key: str | None = None,\n):\n    \"\"\"\n    Check if a tree exists in a Weaviate instance (set in the frontend config).\n\n    Args:\n        user_id (str): Required. The unique identifier for the user stored in the UserManager.\n        conversation_id (str): Required. The unique identifier for the conversation for the user.\n        wcd_url (str | None): Required. The URL of the Weaviate Cloud Database instance used to save the tree.\n            Defaults to the value of the `wcd_url` setting in the frontend config.\n        wcd_api_key (str | None): Required. The API key for the Weaviate Cloud Database instance used to save the tree.\n            Defaults to the value of the `wcd_api_key` setting in the frontend config.\n\n    Returns:\n        (bool): True if the tree exists in the Weaviate instance, False otherwise.\n    \"\"\"\n\n    local_user = await self.get_user_local(user_id)\n    tree_manager: TreeManager = local_user[\"tree_manager\"]\n\n    if wcd_url is None or wcd_api_key is None:\n        save_location_client_manager = local_user[\n            \"frontend_config\"\n        ].save_location_client_manager\n    else:\n        save_location_client_manager = ClientManager(\n            logger=logger,\n            wcd_url=wcd_url,\n            wcd_api_key=wcd_api_key,\n        )\n\n    return await tree_manager.check_tree_exists_weaviate(\n        conversation_id, save_location_client_manager\n    )\n</code></pre>"},{"location":"Reference/Managers/#elysia.api.services.user.UserManager.check_user_timeout","title":"<code>check_user_timeout(user_id)</code>","text":"<p>Check if a user has been idle for the last user_timeout.</p> <p>Parameters:</p> Name Type Description Default <code>user_id</code> <code>str</code> <p>The user ID which contains the user.</p> required <p>Returns:</p> Type Description <code>bool</code> <p>True if the user has been idle for the last user_timeout, False otherwise.</p> Source code in <code>elysia/api/services/user.py</code> <pre><code>def check_user_timeout(self, user_id: str):\n    \"\"\"\n    Check if a user has been idle for the last user_timeout.\n\n    Args:\n        user_id (str): The user ID which contains the user.\n\n    Returns:\n        (bool): True if the user has been idle for the last user_timeout, False otherwise.\n    \"\"\"\n    # if user not found, return True\n    if user_id not in self.users:\n        return True\n\n    # Remove any trees that have not been active in the last user_timeout\n    # if (\n    #     \"last_request\" in self.users[user_id]\n    #     and datetime.datetime.now() - self.users[user_id][\"last_request\"]\n    #     &gt; self.user_timeout\n    # ):\n    #     return True\n\n    return False\n</code></pre>"},{"location":"Reference/Managers/#elysia.api.services.user.UserManager.close_all_clients","title":"<code>close_all_clients()</code>  <code>async</code>","text":"<p>Close all clients in all ClientManagers across all users.</p> Source code in <code>elysia/api/services/user.py</code> <pre><code>async def close_all_clients(self):\n    \"\"\"\n    Close all clients in all ClientManagers across all users.\n    \"\"\"\n    for user_id in self.users:\n        if \"client_manager\" in self.users[user_id]:\n            await self.users[user_id][\"client_manager\"].close_clients()\n</code></pre>"},{"location":"Reference/Managers/#elysia.api.services.user.UserManager.delete_tree","title":"<code>delete_tree(user_id, conversation_id, wcd_url=None, wcd_api_key=None)</code>  <code>async</code>","text":"<p>Delete a saved tree from a Weaviate instance (set in the frontend config). Also delete the tree from the local tree manager. This is a wrapper for the TreeManager.delete_tree_weaviate() method and the TreeManager.delete_tree_local() method.</p> <p>Parameters:</p> Name Type Description Default <code>user_id</code> <code>str</code> <p>Required. The unique identifier for the user stored in the UserManager.</p> required <code>conversation_id</code> <code>str</code> <p>Required. The unique identifier for the conversation for the user.</p> required <code>wcd_url</code> <code>str | None</code> <p>Required. The URL of the Weaviate Cloud Database instance used to save the tree. Defaults to the value of the <code>wcd_url</code> setting in the frontend config.</p> <code>None</code> <code>wcd_api_key</code> <code>str | None</code> <p>Required. The API key for the Weaviate Cloud Database instance used to save the tree. Defaults to the value of the <code>wcd_api_key</code> setting in the frontend config.</p> <code>None</code> Source code in <code>elysia/api/services/user.py</code> <pre><code>async def delete_tree(\n    self,\n    user_id: str,\n    conversation_id: str,\n    wcd_url: str | None = None,\n    wcd_api_key: str | None = None,\n):\n    \"\"\"\n    Delete a saved tree from a Weaviate instance (set in the frontend config).\n    Also delete the tree from the local tree manager.\n    This is a wrapper for the TreeManager.delete_tree_weaviate() method and the TreeManager.delete_tree_local() method.\n\n    Args:\n        user_id (str): Required. The unique identifier for the user stored in the UserManager.\n        conversation_id (str): Required. The unique identifier for the conversation for the user.\n        wcd_url (str | None): Required. The URL of the Weaviate Cloud Database instance used to save the tree.\n            Defaults to the value of the `wcd_url` setting in the frontend config.\n        wcd_api_key (str | None): Required. The API key for the Weaviate Cloud Database instance used to save the tree.\n            Defaults to the value of the `wcd_api_key` setting in the frontend config.\n    \"\"\"\n\n    local_user = await self.get_user_local(user_id)\n    tree_manager: TreeManager = local_user[\"tree_manager\"]\n\n    if wcd_url is None or wcd_api_key is None:\n        save_location_client_manager = local_user[\n            \"frontend_config\"\n        ].save_location_client_manager\n    else:\n        save_location_client_manager = ClientManager(\n            logger=logger,\n            wcd_url=wcd_url,\n            wcd_api_key=wcd_api_key,\n        )\n\n    await tree_manager.delete_tree_weaviate(\n        conversation_id, save_location_client_manager\n    )\n    tree_manager.delete_tree_local(conversation_id)\n</code></pre>"},{"location":"Reference/Managers/#elysia.api.services.user.UserManager.get_saved_trees","title":"<code>get_saved_trees(user_id, wcd_url=None, wcd_api_key=None)</code>  <code>async</code>","text":"<p>Get all saved trees from a Weaviate instance (set in the frontend config).</p> <p>Parameters:</p> Name Type Description Default <code>user_id</code> <code>str</code> <p>Required. The unique identifier for the user stored in the UserManager.</p> required <code>wcd_url</code> <code>str | None</code> <p>Required. The URL of the Weaviate Cloud Database instance used to save the tree. Defaults to the value of the <code>wcd_url</code> setting in the frontend config.</p> <code>None</code> <code>wcd_api_key</code> <code>str | None</code> <p>Required. The API key for the Weaviate Cloud Database instance used to save the tree. Defaults to the value of the <code>wcd_api_key</code> setting in the frontend config.</p> <code>None</code> <p>Returns:</p> Type Description <code>dict</code> <p>A dictionary whose keys are the conversation IDs and whose values are dictionaries containing the title and last update time of the tree. E.g. <pre><code>{\n    \"12345678-XXX-YYYY-ZZZZ\": {\n        \"title\": \"Query Request\",\n        \"last_update_time\": \"2025-06-07T10:06:47.376000Z\"\n    }\n}\n</code></pre></p> Source code in <code>elysia/api/services/user.py</code> <pre><code>async def get_saved_trees(\n    self,\n    user_id: str,\n    wcd_url: str | None = None,\n    wcd_api_key: str | None = None,\n):\n    \"\"\"\n    Get all saved trees from a Weaviate instance (set in the frontend config).\n\n    Args:\n        user_id (str): Required. The unique identifier for the user stored in the UserManager.\n        wcd_url (str | None): Required. The URL of the Weaviate Cloud Database instance used to save the tree.\n            Defaults to the value of the `wcd_url` setting in the frontend config.\n        wcd_api_key (str | None): Required. The API key for the Weaviate Cloud Database instance used to save the tree.\n            Defaults to the value of the `wcd_api_key` setting in the frontend config.\n\n    Returns:\n        (dict): A dictionary whose keys are the conversation IDs and whose values are dictionaries containing the title and last update time of the tree.\n            E.g.\n            ```\n            {\n                \"12345678-XXX-YYYY-ZZZZ\": {\n                    \"title\": \"Query Request\",\n                    \"last_update_time\": \"2025-06-07T10:06:47.376000Z\"\n                }\n            }\n            ```\n    \"\"\"\n    local_user = await self.get_user_local(user_id)\n\n    if wcd_url is None or wcd_api_key is None:\n        save_location_client_manager = local_user[\n            \"frontend_config\"\n        ].save_location_client_manager\n    else:\n        save_location_client_manager = ClientManager(\n            logger=logger,\n            wcd_url=wcd_url,\n            wcd_api_key=wcd_api_key,\n        )\n\n    return await get_saved_trees_weaviate(\n        \"ELYSIA_TREES__\", save_location_client_manager, user_id\n    )\n</code></pre>"},{"location":"Reference/Managers/#elysia.api.services.user.UserManager.get_tree","title":"<code>get_tree(user_id, conversation_id)</code>  <code>async</code>","text":"<p>Get a tree for a user. Will raise a ValueError if the user is not found, or the tree is not found.</p> <p>Parameters:</p> Name Type Description Default <code>user_id</code> <code>str</code> <p>Required. The unique identifier for the user.</p> required <code>conversation_id</code> <code>str</code> <p>Required. The unique identifier for the conversation.</p> required <p>Returns:</p> Type Description <code>Tree</code> <p>The tree.</p> Source code in <code>elysia/api/services/user.py</code> <pre><code>async def get_tree(self, user_id: str, conversation_id: str):\n    \"\"\"\n    Get a tree for a user.\n    Will raise a ValueError if the user is not found, or the tree is not found.\n\n    Args:\n        user_id (str): Required. The unique identifier for the user.\n        conversation_id (str): Required. The unique identifier for the conversation.\n\n    Returns:\n        (Tree): The tree.\n    \"\"\"\n    local_user = await self.get_user_local(user_id)\n    return local_user[\"tree_manager\"].get_tree(conversation_id)\n</code></pre>"},{"location":"Reference/Managers/#elysia.api.services.user.UserManager.get_user_local","title":"<code>get_user_local(user_id)</code>  <code>async</code>","text":"<p>Return a local user object. Will raise a ValueError if the user is not found.</p> <p>Parameters:</p> Name Type Description Default <code>user_id</code> <code>str</code> <p>Required. The unique identifier for the user.</p> required <p>Returns:</p> Type Description <code>dict</code> <p>A local user object, containing a TreeManager (\"tree_manager\"), Frontend Config (\"frontend_config\") and ClientManager (\"client_manager\").</p> Source code in <code>elysia/api/services/user.py</code> <pre><code>async def get_user_local(self, user_id: str):\n    \"\"\"\n    Return a local user object.\n    Will raise a ValueError if the user is not found.\n\n    Args:\n        user_id (str): Required. The unique identifier for the user.\n\n    Returns:\n        (dict): A local user object, containing a TreeManager (\"tree_manager\"),\n            Frontend Config (\"frontend_config\") and ClientManager (\"client_manager\").\n    \"\"\"\n\n    if user_id not in self.users:\n        raise ValueError(\n            f\"User {user_id} not found. Please initialise a user first (by calling `add_user_local`).\"\n        )\n\n    # update last request (adds last_request to user)\n    await self.update_user_last_request(user_id)\n\n    return self.users[user_id]\n</code></pre>"},{"location":"Reference/Managers/#elysia.api.services.user.UserManager.initialise_tree","title":"<code>initialise_tree(user_id, conversation_id, low_memory=False)</code>  <code>async</code>","text":"<p>Initialises a tree for a user for an existing user at user_id. Requires a user to already exist in the UserManager, via <code>add_user_local</code>. This is a wrapper for the TreeManager.add_tree() method.</p> <p>Parameters:</p> Name Type Description Default <code>user_id</code> <code>str</code> <p>Required. The unique identifier for the user.</p> required <code>conversation_id</code> <code>str</code> <p>Required. The unique identifier for a new conversation within the tree manager.</p> required <code>low_memory</code> <code>bool</code> <p>Optional. Whether to use low memory mode for the tree. Controls the LM history being saved in the tree, and some other variables. Defaults to False.</p> <code>False</code> Source code in <code>elysia/api/services/user.py</code> <pre><code>async def initialise_tree(\n    self,\n    user_id: str,\n    conversation_id: str,\n    low_memory: bool = False,\n):\n    \"\"\"\n    Initialises a tree for a user for an existing user at user_id.\n    Requires a user to already exist in the UserManager, via `add_user_local`.\n    This is a wrapper for the TreeManager.add_tree() method.\n\n    Args:\n        user_id (str): Required. The unique identifier for the user.\n        conversation_id (str): Required. The unique identifier for a new conversation within the tree manager.\n        low_memory (bool): Optional. Whether to use low memory mode for the tree.\n            Controls the LM history being saved in the tree, and some other variables.\n            Defaults to False.\n    \"\"\"\n    # self.add_user_local(user_id)\n    local_user = await self.get_user_local(user_id)\n    tree_manager: TreeManager = local_user[\"tree_manager\"]\n    if not tree_manager.tree_exists(conversation_id):\n        tree_manager.add_tree(\n            conversation_id,\n            low_memory,\n        )\n    return tree_manager.get_tree(conversation_id)\n</code></pre>"},{"location":"Reference/Managers/#elysia.api.services.user.UserManager.load_tree","title":"<code>load_tree(user_id, conversation_id, wcd_url=None, wcd_api_key=None)</code>  <code>async</code>","text":"<p>Load a tree from a Weaviate instance (set in the frontend config). This is a wrapper for the TreeManager.load_tree_weaviate() method.</p> <p>Parameters:</p> Name Type Description Default <code>user_id</code> <code>str</code> <p>Required. The unique identifier for the user stored in the UserManager.</p> required <code>conversation_id</code> <code>str</code> <p>Required. The unique identifier for the conversation for the user.</p> required <code>wcd_url</code> <code>str | None</code> <p>Required. The URL of the Weaviate Cloud Database instance used to save the tree. Defaults to the value of the <code>wcd_url</code> setting in the frontend config.</p> <code>None</code> <code>wcd_api_key</code> <code>str | None</code> <p>Required. The API key for the Weaviate Cloud Database instance used to save the tree. Defaults to the value of the <code>wcd_api_key</code> setting in the frontend config.</p> <code>None</code> <p>Returns:</p> Type Description <code>list[dict]</code> <p>A list of dictionaries, each containing a frontend payload that was used to generate the tree. The list is ordered by the time the payload was originally sent to the frontend (at the time it was saved).</p> Source code in <code>elysia/api/services/user.py</code> <pre><code>async def load_tree(\n    self,\n    user_id: str,\n    conversation_id: str,\n    wcd_url: str | None = None,\n    wcd_api_key: str | None = None,\n):\n    \"\"\"\n    Load a tree from a Weaviate instance (set in the frontend config).\n    This is a wrapper for the TreeManager.load_tree_weaviate() method.\n\n    Args:\n        user_id (str): Required. The unique identifier for the user stored in the UserManager.\n        conversation_id (str): Required. The unique identifier for the conversation for the user.\n        wcd_url (str | None): Required. The URL of the Weaviate Cloud Database instance used to save the tree.\n            Defaults to the value of the `wcd_url` setting in the frontend config.\n        wcd_api_key (str | None): Required. The API key for the Weaviate Cloud Database instance used to save the tree.\n            Defaults to the value of the `wcd_api_key` setting in the frontend config.\n\n    Returns:\n        (list[dict]): A list of dictionaries, each containing a frontend payload that was used to generate the tree.\n            The list is ordered by the time the payload was originally sent to the frontend (at the time it was saved).\n    \"\"\"\n\n    local_user = await self.get_user_local(user_id)\n    tree_manager: TreeManager = local_user[\"tree_manager\"]\n\n    if wcd_url is None or wcd_api_key is None:\n        save_location_client_manager = local_user[\n            \"frontend_config\"\n        ].save_location_client_manager\n    else:\n        save_location_client_manager = ClientManager(\n            logger=logger,\n            wcd_url=wcd_url,\n            wcd_api_key=wcd_api_key,\n        )\n\n    return await tree_manager.load_tree_weaviate(\n        conversation_id, save_location_client_manager\n    )\n</code></pre>"},{"location":"Reference/Managers/#elysia.api.services.user.UserManager.process_tree","title":"<code>process_tree(query, user_id, conversation_id, query_id, training_route='', collection_names=[], save_trees_to_weaviate=None, wcd_url=None, wcd_api_key=None)</code>  <code>async</code>","text":"<p>Wrapper for the TreeManager.process_tree() method. Which itself is a wrapper for the Tree.async_run() method. This is an async generator which yields results from the tree.async_run() method. Automatically sends error payloads if the user or tree has been timed out.</p> <p>Parameters:</p> Name Type Description Default <code>query</code> <code>str</code> <p>Required. The user input/prompt to process in the decision tree.</p> required <code>user_id</code> <code>str</code> <p>Required. The unique identifier for the user.</p> required <code>conversation_id</code> <code>str</code> <p>Required. The conversation ID which contains the tree. This should be the same conversation ID as the one used to initialise the tree (see <code>initialise_tree</code>).</p> required <code>query_id</code> <code>str</code> <p>Required. A unique identifier for the query.</p> required <code>training_route</code> <code>str</code> <p>Optional. The training route, a string of the form \"tool1/tool2/tool1\" etc. See the <code>tree.async_run()</code> method for more details.</p> <code>''</code> <code>collection_names</code> <code>list[str]</code> <p>Optional. A list of collection names to use in the query. If not supplied, all collections will be used.</p> <code>[]</code> <code>save_trees_to_weaviate</code> <code>bool | None</code> <p>Optional. Whether to save the trees to a Weaviate instance, after the process_tree() method has finished. Defaults to the value of the <code>save_trees_to_weaviate</code> setting in the frontend config.</p> <code>None</code> <code>wcd_url</code> <code>str | None</code> <p>Required. The URL of the Weaviate Cloud Database instance used to save the tree. Defaults to the value of the <code>wcd_url</code> setting in the frontend config.</p> <code>None</code> <code>wcd_api_key</code> <code>str | None</code> <p>Required. The API key for the Weaviate Cloud Database instance used to save the tree. Defaults to the value of the <code>wcd_api_key</code> setting in the frontend config.</p> <code>None</code> Source code in <code>elysia/api/services/user.py</code> <pre><code>async def process_tree(\n    self,\n    query: str,\n    user_id: str,\n    conversation_id: str,\n    query_id: str,\n    training_route: str = \"\",\n    collection_names: list[str] = [],\n    save_trees_to_weaviate: bool | None = None,\n    wcd_url: str | None = None,\n    wcd_api_key: str | None = None,\n):\n    \"\"\"\n    Wrapper for the TreeManager.process_tree() method.\n    Which itself is a wrapper for the Tree.async_run() method.\n    This is an async generator which yields results from the tree.async_run() method.\n    Automatically sends error payloads if the user or tree has been timed out.\n\n    Args:\n        query (str): Required. The user input/prompt to process in the decision tree.\n        user_id (str): Required. The unique identifier for the user.\n        conversation_id (str): Required. The conversation ID which contains the tree.\n            This should be the same conversation ID as the one used to initialise the tree (see `initialise_tree`).\n        query_id (str): Required. A unique identifier for the query.\n        training_route (str): Optional. The training route, a string of the form \"tool1/tool2/tool1\" etc.\n            See the `tree.async_run()` method for more details.\n        collection_names (list[str]): Optional. A list of collection names to use in the query.\n            If not supplied, all collections will be used.\n        save_trees_to_weaviate (bool | None): Optional. Whether to save the trees to a Weaviate instance,\n            after the process_tree() method has finished.\n            Defaults to the value of the `save_trees_to_weaviate` setting in the frontend config.\n        wcd_url (str | None): Required. The URL of the Weaviate Cloud Database instance used to save the tree.\n            Defaults to the value of the `wcd_url` setting in the frontend config.\n        wcd_api_key (str | None): Required. The API key for the Weaviate Cloud Database instance used to save the tree.\n            Defaults to the value of the `wcd_api_key` setting in the frontend config.\n    \"\"\"\n\n    if self.check_user_timeout(user_id):\n        user_timeout_error = UserTimeoutError()\n        error_payload = await user_timeout_error.to_frontend(\n            user_id, conversation_id, query_id\n        )\n        yield error_payload\n        return\n\n    if self.check_tree_timeout(user_id, conversation_id):\n        if await self.check_tree_exists_weaviate(user_id, conversation_id):\n            await self.load_tree(user_id, conversation_id)\n        else:\n            tree_timeout_error = TreeTimeoutError()\n            error_payload = await tree_timeout_error.to_frontend(\n                user_id, conversation_id, query_id\n            )\n            yield error_payload\n            return\n\n    local_user = await self.get_user_local(user_id)\n    await self.update_user_last_request(user_id)\n\n    tree_manager: TreeManager = local_user[\"tree_manager\"]\n\n    async for yielded_result in tree_manager.process_tree(\n        query,\n        conversation_id,\n        query_id,\n        training_route,\n        collection_names,\n        local_user[\"client_manager\"],\n    ):\n        yield yielded_result\n        await self.update_user_last_request(user_id)\n\n    if save_trees_to_weaviate is None:\n        frontend_config: FrontendConfig = local_user[\"frontend_config\"]\n        save_trees_to_weaviate = frontend_config.config[\"save_trees_to_weaviate\"]\n\n    if save_trees_to_weaviate:\n        await self.save_tree(user_id, conversation_id, wcd_url, wcd_api_key)\n</code></pre>"},{"location":"Reference/Managers/#elysia.api.services.user.UserManager.save_tree","title":"<code>save_tree(user_id, conversation_id, wcd_url=None, wcd_api_key=None)</code>  <code>async</code>","text":"<p>Save a tree to a Weaviate instance (set in the frontend config). This is a wrapper for the TreeManager.save_tree_weaviate() method.</p> <p>Parameters:</p> Name Type Description Default <code>user_id</code> <code>str</code> <p>Required. The unique identifier for the user stored in the UserManager.</p> required <code>conversation_id</code> <code>str</code> <p>Required. The unique identifier for the conversation for the user.</p> required Source code in <code>elysia/api/services/user.py</code> <pre><code>async def save_tree(\n    self,\n    user_id: str,\n    conversation_id: str,\n    wcd_url: str | None = None,\n    wcd_api_key: str | None = None,\n):\n    \"\"\"\n    Save a tree to a Weaviate instance (set in the frontend config).\n    This is a wrapper for the TreeManager.save_tree_weaviate() method.\n\n    Args:\n        user_id (str): Required. The unique identifier for the user stored in the UserManager.\n        conversation_id (str): Required. The unique identifier for the conversation for the user.\n    \"\"\"\n\n    local_user = await self.get_user_local(user_id)\n    tree_manager: TreeManager = local_user[\"tree_manager\"]\n\n    if wcd_url is None or wcd_api_key is None:\n        save_location_client_manager = local_user[\n            \"frontend_config\"\n        ].save_location_client_manager\n    else:\n        save_location_client_manager = ClientManager(\n            logger=logger,\n            wcd_url=wcd_url,\n            wcd_api_key=wcd_api_key,\n        )\n\n    await tree_manager.save_tree_weaviate(\n        conversation_id, save_location_client_manager\n    )\n</code></pre>"},{"location":"Reference/Managers/#elysia.api.services.tree.TreeManager","title":"<code>TreeManager</code>","text":"<p>Manages trees (different conversations) for a single user. Designed to be used with the Elysia API, or a manager for multiple Elysia decision trees.</p> <p>You can initialise the TreeManager with particular config options. Or, upon adding a tree, you can set a specific style, description and end goal for that tree.</p> <p>Each tree has separate elements: the tree itself, the last request time, and the asyncio event.</p> Source code in <code>elysia/api/services/tree.py</code> <pre><code>class TreeManager:\n    \"\"\"\n    Manages trees (different conversations) for a single user.\n    Designed to be used with the Elysia API, or a manager for multiple Elysia decision trees.\n\n    You can initialise the TreeManager with particular config options.\n    Or, upon adding a tree, you can set a specific style, description and end goal for that tree.\n\n    Each tree has separate elements: the tree itself, the last request time, and the asyncio event.\n    \"\"\"\n\n    def __init__(\n        self,\n        user_id: str,\n        config: Config | None = None,\n        tree_timeout: datetime.timedelta | int | None = None,\n    ):\n        \"\"\"\n        Args:\n            user_id (str): Required. A unique identifier for the user being managed within this TreeManager.\n            config (Config | None): Optional. A config for all trees managed by this TreeManager.\n                Defaults to a new config with default settings.\n                If `settings` is not provided, it will be set to the default settings (smart_setup).\n            tree_timeout (datetime.timedelta | int | None): Optional. A timeout for all trees managed by this TreeManager.\n                Defaults to the value of the `TREE_TIMEOUT` environment variable.\n                If an integer is passed, it will be interpreted as minutes.\n                If set to 0, trees will not be automatically removed.\n        \"\"\"\n        self.trees = {}\n        self.user_id = user_id\n\n        if tree_timeout is None:\n            self.tree_timeout = datetime.timedelta(\n                minutes=int(os.environ.get(\"TREE_TIMEOUT\", 10))\n            )\n        elif isinstance(tree_timeout, int):\n            self.tree_timeout = datetime.timedelta(minutes=tree_timeout)\n        else:\n            self.tree_timeout = tree_timeout\n\n        if config is None:\n            self.config = Config()\n        else:\n            self.config = config\n\n        self.settings = self.config.settings\n\n    def update_config(\n        self,\n        conversation_id: str | None = None,\n        config_id: str | None = None,\n        config_name: str | None = None,\n        settings: dict[str, Any] | None = None,\n        style: str | None = None,\n        agent_description: str | None = None,\n        end_goal: str | None = None,\n        branch_initialisation: BranchInitType | None = None,\n    ):\n        if config_id is not None:\n            self.config.id = config_id\n\n        if config_name is not None:\n            self.config.name = config_name\n\n        if settings is not None:\n            self.configure(conversation_id=conversation_id, replace=True, **settings)\n\n        if style is not None:\n            self.change_style(style, conversation_id)\n\n        if agent_description is not None:\n            self.change_agent_description(agent_description, conversation_id)\n\n        if end_goal is not None:\n            self.change_end_goal(end_goal, conversation_id)\n\n        if branch_initialisation is not None:\n            self.change_branch_initialisation(branch_initialisation, conversation_id)\n\n    def add_tree(\n        self,\n        conversation_id: str,\n        low_memory: bool = False,\n    ):\n        \"\"\"\n        Add a tree to the TreeManager.\n        The decision tree can be initialised with specific config options, such as style, agent description and end goal.\n        As well as a Settings object, which chooses options such as the LLM models, API keys and more.\n\n        Args:\n            conversation_id (str): Required. A unique identifier for the conversation.\n            low_memory (bool): Optional. Whether to use low memory mode for the tree.\n                Controls the LM history being saved in the tree, and some other variables.\n                Defaults to False.\n        \"\"\"\n\n        if not self.tree_exists(conversation_id):\n            self.trees[conversation_id] = {\n                \"tree\": Tree(\n                    conversation_id=conversation_id,\n                    user_id=self.user_id,\n                    settings=self.settings,\n                    style=self.config.style,\n                    agent_description=self.config.agent_description,\n                    end_goal=self.config.end_goal,\n                    branch_initialisation=self.config.branch_initialisation,\n                    low_memory=low_memory,\n                    use_elysia_collections=self.config.use_elysia_collections,\n                ),\n                \"last_request\": datetime.datetime.now(),\n                \"event\": asyncio.Event(),\n            }\n            self.trees[conversation_id][\"event\"].set()\n\n    async def save_tree_weaviate(\n        self, conversation_id: str, client_manager: ClientManager\n    ):\n        \"\"\"\n        Save a tree to Weaviate to collection ELYSIA_TREES__.\n        Creates the collection if it doesn't exist.\n\n        Args:\n            conversation_id (str): The conversation ID which contains the tree.\n            client_manager (ClientManager): The client manager to use for the tree.\n        \"\"\"\n        tree: Tree = self.get_tree(conversation_id)\n        await tree.export_to_weaviate(\"ELYSIA_TREES__\", client_manager)\n\n    async def check_tree_exists_weaviate(\n        self, conversation_id: str, client_manager: ClientManager\n    ):\n        \"\"\"\n        Check if a tree exists in a Weaviate instance.\n        The collection ELYSIA_TREES__ must exist, returns False if it doesn't.\n\n        Args:\n            conversation_id (str): The conversation ID which contains the tree.\n            client_manager (ClientManager): The client manager to use for the tree.\n\n        Returns:\n            (bool): True if the tree exists in the Weaviate instance, False otherwise.\n        \"\"\"\n        async with client_manager.connect_to_async_client() as client:\n            if not await client.collections.exists(\"ELYSIA_TREES__\"):\n                return False\n\n            collection = client.collections.get(\"ELYSIA_TREES__\")\n            uuid = generate_uuid5(conversation_id)\n            return await collection.data.exists(uuid)\n\n    async def load_tree_weaviate(\n        self, conversation_id: str, client_manager: ClientManager\n    ):\n        \"\"\"\n        Load a tree from Weaviate.\n        The conversation ID from the loaded tree is placed into the tree manager\n        (possibly overwriting an existing tree with the same conversation ID).\n        Then the tree itself is not returned - instead the list of frontend payloads\n        that were yielded to the frontend by the tree is returned.\n\n        Args:\n            conversation_id (str): The conversation ID which contains the tree.\n            client_manager (ClientManager): The client manager to use for the tree.\n\n        Returns:\n            (list): A list of dictionaries, each containing a frontend payload that was used to generate the tree.\n                The list is ordered by the time the payload was originally sent to the frontend (at the time it was saved).\n        \"\"\"\n        tree = await Tree.import_from_weaviate(\n            \"ELYSIA_TREES__\", conversation_id, client_manager\n        )\n        if conversation_id not in self.trees:\n            self.trees[conversation_id] = {\n                \"tree\": None,\n                \"event\": asyncio.Event(),\n                \"last_request\": datetime.datetime.now(),\n            }\n        self.trees[conversation_id][\"tree\"] = tree\n        self.trees[conversation_id][\"event\"].set()\n        self.update_tree_last_request(conversation_id)\n        return tree.returner.store\n\n    async def delete_tree_weaviate(\n        self, conversation_id: str, client_manager: ClientManager\n    ):\n        \"\"\"\n        Delete a tree from the stored trees in Weaviate.\n\n        Args:\n            conversation_id (str): The conversation ID of the tree to be deleted.\n            client_manager (ClientManager): The client manager pointing to the Weaviate instance containing the tree.\n        \"\"\"\n        await delete_tree_from_weaviate(\n            conversation_id, \"ELYSIA_TREES__\", client_manager\n        )\n\n    def delete_tree_local(self, conversation_id: str):\n        \"\"\"\n        Delete a tree from the TreeManager.\n\n        Args:\n            conversation_id (str): The conversation ID of the tree to be deleted.\n        \"\"\"\n        if conversation_id in self.trees:\n            del self.trees[conversation_id]\n\n    def tree_exists(self, conversation_id: str):\n        \"\"\"\n        Check if a tree exists in the TreeManager.\n\n        Args:\n            conversation_id (str): The conversation ID which may contain the tree.\n\n        Returns:\n            (bool): True if the tree exists, False otherwise.\n        \"\"\"\n        return conversation_id in self.trees\n\n    def get_tree(self, conversation_id: str):\n        \"\"\"\n        Get a tree from the TreeManager.\n        Will raise a ValueError if the tree is not found.\n\n        Args:\n            conversation_id (str): The conversation ID which contains the tree.\n\n        Returns:\n            (Tree): The tree associated with the conversation ID.\n        \"\"\"\n        if conversation_id not in self.trees:\n            raise ValueError(\n                f\"Tree {conversation_id} not found. Please initialise a tree first (by calling `add_tree`).\"\n            )\n\n        return self.trees[conversation_id][\"tree\"]\n\n    def get_event(self, conversation_id: str):\n        \"\"\"\n        Get the asyncio.Event for a tree in the TreeManager.\n        This is cleared when the tree is processing, and set when the tree is idle.\n        This is used to block the API from sending multiple requests to the tree at once.\n\n        Args:\n            conversation_id (str): The conversation ID which contains the tree.\n\n        Returns:\n            (asyncio.Event): The event for the tree.\n        \"\"\"\n        return self.trees[conversation_id][\"event\"]\n\n    def configure(\n        self, conversation_id: str | None = None, replace: bool = False, **kwargs: Any\n    ):\n        \"\"\"\n        Configure the settings for a tree in the TreeManager.\n\n        Args:\n            conversation_id (str | None): The conversation ID which contains the tree.\n            replace (bool): Whether to override the current settings with the new settings.\n                When this is True, all existing settings are removed, and only the new settings are used.\n                Defaults to False.\n            **kwargs (Any): The keyword arguments to pass to the Settings.configure() method.\n        \"\"\"\n        if conversation_id is None:\n            self.settings.configure(replace=replace, **kwargs)\n            self.config.settings = self.settings\n        else:\n            self.get_tree(conversation_id).settings.configure(replace=replace, **kwargs)\n\n    def change_style(self, style: str, conversation_id: str | None = None):\n        \"\"\"\n        Change the style for a tree in the TreeManager.\n        Or change the global style for all trees (if conversation_id is not supplied).\n        And applies these changes to current trees with default settings.\n\n        Args:\n            style (str): The new style for the tree.\n            conversation_id (str | None): Optional. The conversation ID which contains the tree.\n                If not supplied, the style will be changed on all trees.\n        \"\"\"\n        if conversation_id is None:\n            self.config.style = style\n            for conversation_id in self.trees:\n                if not self.trees[conversation_id][\"tree\"]._config_modified:\n                    self.trees[conversation_id][\"tree\"].change_style(style)\n                    self.trees[conversation_id][\"tree\"]._config_modified = False\n        else:\n            if conversation_id not in self.trees:\n                raise ValueError(f\"Tree {conversation_id} not found\")\n\n            self.trees[conversation_id][\"tree\"].change_style(style)\n\n    def change_agent_description(\n        self, agent_description: str, conversation_id: str | None = None\n    ):\n        \"\"\"\n        Change the agent description for a tree in the TreeManager.\n        Or change the global agent description for all trees (if conversation_id is not supplied).\n        And applies these changes to current trees with default settings.\n\n        Args:\n            agent_description (str): The new agent description for the tree.\n            conversation_id (str | None): Optional. The conversation ID which contains the tree.\n                If not supplied, the agent description will be changed on all trees.\n        \"\"\"\n        if conversation_id is None:\n            self.config.agent_description = agent_description\n            for conversation_id in self.trees:\n                if not self.trees[conversation_id][\"tree\"]._config_modified:\n                    self.trees[conversation_id][\"tree\"].change_agent_description(\n                        agent_description\n                    )\n                    self.trees[conversation_id][\"tree\"]._config_modified = False\n        else:\n            if conversation_id not in self.trees:\n                raise ValueError(f\"Tree {conversation_id} not found\")\n\n            self.trees[conversation_id][\"tree\"].change_agent_description(\n                agent_description\n            )\n\n    def change_end_goal(self, end_goal: str, conversation_id: str | None = None):\n        \"\"\"\n        Change the end goal for a tree in the TreeManager.\n        Or change the global end goal for all trees (if conversation_id is not supplied).\n        And applies these changes to current trees with default settings.\n\n        Args:\n            end_goal (str): The new end goal for the tree.\n            conversation_id (str | None): Optional. The conversation ID which contains the tree.\n                If not supplied, the end goal will be changed on all trees.\n        \"\"\"\n        if conversation_id is None:\n            self.config.end_goal = end_goal\n            for conversation_id in self.trees:\n                if not self.trees[conversation_id][\"tree\"]._config_modified:\n                    self.trees[conversation_id][\"tree\"].change_end_goal(end_goal)\n                    self.trees[conversation_id][\"tree\"]._config_modified = False\n        else:\n            if conversation_id not in self.trees:\n                raise ValueError(f\"Tree {conversation_id} not found\")\n\n            self.trees[conversation_id][\"tree\"].change_end_goal(end_goal)\n\n    def change_branch_initialisation(\n        self, branch_initialisation: BranchInitType, conversation_id: str | None = None\n    ):\n        \"\"\"\n        Change the branch initialisation for a tree in the TreeManager.\n        Or change the global branch initialisation for all trees (if conversation_id is not supplied).\n        And applies these changes to current trees with default settings.\n\n        Args:\n            branch_initialisation (str): The new branch initialisation for the tree.\n            conversation_id (str | None): Optional. The conversation ID which contains the tree.\n                If not supplied, the branch initialisation will be changed on all trees.\n        \"\"\"\n        if conversation_id is None:\n            self.config.branch_initialisation = branch_initialisation\n            for conversation_id in self.trees:\n                if not self.trees[conversation_id][\"tree\"]._config_modified:\n                    self.trees[conversation_id][\"tree\"].set_branch_initialisation(\n                        branch_initialisation\n                    )\n                    self.trees[conversation_id][\"tree\"]._config_modified = False\n        else:\n            if conversation_id not in self.trees:\n                raise ValueError(f\"Tree {conversation_id} not found\")\n\n            self.trees[conversation_id][\"tree\"].set_branch_initialisation(\n                branch_initialisation\n            )\n\n    async def process_tree(\n        self,\n        query: str,\n        conversation_id: str,\n        query_id: str | None = None,\n        training_route: str = \"\",\n        collection_names: list[str] = [],\n        client_manager: ClientManager | None = None,\n    ):\n        \"\"\"\n        Process a tree in the TreeManager.\n        This is an async generator which yields results from the tree.async_run() method.\n\n        Args:\n            query (str): Required. The user input/prompt to process in the decision tree.\n            conversation_id (str): Required. The conversation ID which contains the tree.\n            query_id (str): Optional. A unique identifier for the query.\n                If not supplied, a random UUID will be generated.\n            training_route (str): Optional. The training route, a string of the form \"tool1/tool2/tool1\" etc.\n                See the `tree.async_run()` method for more details.\n            collection_names (list[str]): Optional. A list of collection names to use in the query.\n                If not supplied, all collections will be used.\n            client_manager (ClientManager | None): Optional. A client manager to use for the query.\n                If not supplied, a new ClientManager will be created.\n        \"\"\"\n\n        if query_id is None:\n            query_id = str(uuid.uuid4())\n\n        tree: Tree = self.get_tree(conversation_id)\n        self.update_tree_last_request(conversation_id)\n\n        # wait for the tree to be idle\n        await self.trees[conversation_id][\"event\"].wait()\n\n        # clear the event, set it to working\n        self.trees[conversation_id][\"event\"].clear()\n\n        try:\n            async for yielded_result in tree.async_run(\n                query,\n                collection_names=collection_names,\n                client_manager=client_manager,\n                query_id=query_id,\n                training_route=training_route,\n                close_clients_after_completion=False,\n            ):\n                yield yielded_result\n                self.update_tree_last_request(conversation_id)\n\n        finally:\n            # set the event to idle\n            self.trees[conversation_id][\"event\"].set()\n\n    def check_tree_timeout(self, conversation_id: str):\n        \"\"\"\n        Check if a tree has been idle for the last tree_timeout.\n\n        Args:\n            conversation_id (str): The conversation ID which contains the tree.\n\n        Returns:\n            (bool): True if the tree has been idle for the last tree_timeout, False otherwise.\n        \"\"\"\n        # if tree not found, return True\n        if conversation_id not in self.trees:\n            return True\n\n        # Remove any trees that have not been active in the last TREE_TIMEOUT minutes\n        if (\n            \"last_request\" in self.trees[conversation_id]\n            and datetime.datetime.now() - self.trees[conversation_id][\"last_request\"]\n            &gt; self.tree_timeout\n        ):\n            return True\n\n        return False\n\n    def update_tree_last_request(self, conversation_id: str):\n        self.trees[conversation_id][\"last_request\"] = datetime.datetime.now()\n\n    def check_all_trees_timeout(self):\n        \"\"\"\n        Check all trees in the TreeManager and remove any that have not been active in the last tree_timeout.\n        \"\"\"\n        if self.tree_timeout == datetime.timedelta(minutes=0):\n            return\n\n        convs_to_remove = []\n        for i, conversation_id in enumerate(self.trees):\n            if self.check_tree_timeout(conversation_id):\n                convs_to_remove.append(conversation_id)\n\n        for conversation_id in convs_to_remove:\n            del self.trees[conversation_id]\n</code></pre>"},{"location":"Reference/Managers/#elysia.api.services.tree.TreeManager.__init__","title":"<code>__init__(user_id, config=None, tree_timeout=None)</code>","text":"<p>Parameters:</p> Name Type Description Default <code>user_id</code> <code>str</code> <p>Required. A unique identifier for the user being managed within this TreeManager.</p> required <code>config</code> <code>Config | None</code> <p>Optional. A config for all trees managed by this TreeManager. Defaults to a new config with default settings. If <code>settings</code> is not provided, it will be set to the default settings (smart_setup).</p> <code>None</code> <code>tree_timeout</code> <code>timedelta | int | None</code> <p>Optional. A timeout for all trees managed by this TreeManager. Defaults to the value of the <code>TREE_TIMEOUT</code> environment variable. If an integer is passed, it will be interpreted as minutes. If set to 0, trees will not be automatically removed.</p> <code>None</code> Source code in <code>elysia/api/services/tree.py</code> <pre><code>def __init__(\n    self,\n    user_id: str,\n    config: Config | None = None,\n    tree_timeout: datetime.timedelta | int | None = None,\n):\n    \"\"\"\n    Args:\n        user_id (str): Required. A unique identifier for the user being managed within this TreeManager.\n        config (Config | None): Optional. A config for all trees managed by this TreeManager.\n            Defaults to a new config with default settings.\n            If `settings` is not provided, it will be set to the default settings (smart_setup).\n        tree_timeout (datetime.timedelta | int | None): Optional. A timeout for all trees managed by this TreeManager.\n            Defaults to the value of the `TREE_TIMEOUT` environment variable.\n            If an integer is passed, it will be interpreted as minutes.\n            If set to 0, trees will not be automatically removed.\n    \"\"\"\n    self.trees = {}\n    self.user_id = user_id\n\n    if tree_timeout is None:\n        self.tree_timeout = datetime.timedelta(\n            minutes=int(os.environ.get(\"TREE_TIMEOUT\", 10))\n        )\n    elif isinstance(tree_timeout, int):\n        self.tree_timeout = datetime.timedelta(minutes=tree_timeout)\n    else:\n        self.tree_timeout = tree_timeout\n\n    if config is None:\n        self.config = Config()\n    else:\n        self.config = config\n\n    self.settings = self.config.settings\n</code></pre>"},{"location":"Reference/Managers/#elysia.api.services.tree.TreeManager.add_tree","title":"<code>add_tree(conversation_id, low_memory=False)</code>","text":"<p>Add a tree to the TreeManager. The decision tree can be initialised with specific config options, such as style, agent description and end goal. As well as a Settings object, which chooses options such as the LLM models, API keys and more.</p> <p>Parameters:</p> Name Type Description Default <code>conversation_id</code> <code>str</code> <p>Required. A unique identifier for the conversation.</p> required <code>low_memory</code> <code>bool</code> <p>Optional. Whether to use low memory mode for the tree. Controls the LM history being saved in the tree, and some other variables. Defaults to False.</p> <code>False</code> Source code in <code>elysia/api/services/tree.py</code> <pre><code>def add_tree(\n    self,\n    conversation_id: str,\n    low_memory: bool = False,\n):\n    \"\"\"\n    Add a tree to the TreeManager.\n    The decision tree can be initialised with specific config options, such as style, agent description and end goal.\n    As well as a Settings object, which chooses options such as the LLM models, API keys and more.\n\n    Args:\n        conversation_id (str): Required. A unique identifier for the conversation.\n        low_memory (bool): Optional. Whether to use low memory mode for the tree.\n            Controls the LM history being saved in the tree, and some other variables.\n            Defaults to False.\n    \"\"\"\n\n    if not self.tree_exists(conversation_id):\n        self.trees[conversation_id] = {\n            \"tree\": Tree(\n                conversation_id=conversation_id,\n                user_id=self.user_id,\n                settings=self.settings,\n                style=self.config.style,\n                agent_description=self.config.agent_description,\n                end_goal=self.config.end_goal,\n                branch_initialisation=self.config.branch_initialisation,\n                low_memory=low_memory,\n                use_elysia_collections=self.config.use_elysia_collections,\n            ),\n            \"last_request\": datetime.datetime.now(),\n            \"event\": asyncio.Event(),\n        }\n        self.trees[conversation_id][\"event\"].set()\n</code></pre>"},{"location":"Reference/Managers/#elysia.api.services.tree.TreeManager.change_agent_description","title":"<code>change_agent_description(agent_description, conversation_id=None)</code>","text":"<p>Change the agent description for a tree in the TreeManager. Or change the global agent description for all trees (if conversation_id is not supplied). And applies these changes to current trees with default settings.</p> <p>Parameters:</p> Name Type Description Default <code>agent_description</code> <code>str</code> <p>The new agent description for the tree.</p> required <code>conversation_id</code> <code>str | None</code> <p>Optional. The conversation ID which contains the tree. If not supplied, the agent description will be changed on all trees.</p> <code>None</code> Source code in <code>elysia/api/services/tree.py</code> <pre><code>def change_agent_description(\n    self, agent_description: str, conversation_id: str | None = None\n):\n    \"\"\"\n    Change the agent description for a tree in the TreeManager.\n    Or change the global agent description for all trees (if conversation_id is not supplied).\n    And applies these changes to current trees with default settings.\n\n    Args:\n        agent_description (str): The new agent description for the tree.\n        conversation_id (str | None): Optional. The conversation ID which contains the tree.\n            If not supplied, the agent description will be changed on all trees.\n    \"\"\"\n    if conversation_id is None:\n        self.config.agent_description = agent_description\n        for conversation_id in self.trees:\n            if not self.trees[conversation_id][\"tree\"]._config_modified:\n                self.trees[conversation_id][\"tree\"].change_agent_description(\n                    agent_description\n                )\n                self.trees[conversation_id][\"tree\"]._config_modified = False\n    else:\n        if conversation_id not in self.trees:\n            raise ValueError(f\"Tree {conversation_id} not found\")\n\n        self.trees[conversation_id][\"tree\"].change_agent_description(\n            agent_description\n        )\n</code></pre>"},{"location":"Reference/Managers/#elysia.api.services.tree.TreeManager.change_branch_initialisation","title":"<code>change_branch_initialisation(branch_initialisation, conversation_id=None)</code>","text":"<p>Change the branch initialisation for a tree in the TreeManager. Or change the global branch initialisation for all trees (if conversation_id is not supplied). And applies these changes to current trees with default settings.</p> <p>Parameters:</p> Name Type Description Default <code>branch_initialisation</code> <code>str</code> <p>The new branch initialisation for the tree.</p> required <code>conversation_id</code> <code>str | None</code> <p>Optional. The conversation ID which contains the tree. If not supplied, the branch initialisation will be changed on all trees.</p> <code>None</code> Source code in <code>elysia/api/services/tree.py</code> <pre><code>def change_branch_initialisation(\n    self, branch_initialisation: BranchInitType, conversation_id: str | None = None\n):\n    \"\"\"\n    Change the branch initialisation for a tree in the TreeManager.\n    Or change the global branch initialisation for all trees (if conversation_id is not supplied).\n    And applies these changes to current trees with default settings.\n\n    Args:\n        branch_initialisation (str): The new branch initialisation for the tree.\n        conversation_id (str | None): Optional. The conversation ID which contains the tree.\n            If not supplied, the branch initialisation will be changed on all trees.\n    \"\"\"\n    if conversation_id is None:\n        self.config.branch_initialisation = branch_initialisation\n        for conversation_id in self.trees:\n            if not self.trees[conversation_id][\"tree\"]._config_modified:\n                self.trees[conversation_id][\"tree\"].set_branch_initialisation(\n                    branch_initialisation\n                )\n                self.trees[conversation_id][\"tree\"]._config_modified = False\n    else:\n        if conversation_id not in self.trees:\n            raise ValueError(f\"Tree {conversation_id} not found\")\n\n        self.trees[conversation_id][\"tree\"].set_branch_initialisation(\n            branch_initialisation\n        )\n</code></pre>"},{"location":"Reference/Managers/#elysia.api.services.tree.TreeManager.change_end_goal","title":"<code>change_end_goal(end_goal, conversation_id=None)</code>","text":"<p>Change the end goal for a tree in the TreeManager. Or change the global end goal for all trees (if conversation_id is not supplied). And applies these changes to current trees with default settings.</p> <p>Parameters:</p> Name Type Description Default <code>end_goal</code> <code>str</code> <p>The new end goal for the tree.</p> required <code>conversation_id</code> <code>str | None</code> <p>Optional. The conversation ID which contains the tree. If not supplied, the end goal will be changed on all trees.</p> <code>None</code> Source code in <code>elysia/api/services/tree.py</code> <pre><code>def change_end_goal(self, end_goal: str, conversation_id: str | None = None):\n    \"\"\"\n    Change the end goal for a tree in the TreeManager.\n    Or change the global end goal for all trees (if conversation_id is not supplied).\n    And applies these changes to current trees with default settings.\n\n    Args:\n        end_goal (str): The new end goal for the tree.\n        conversation_id (str | None): Optional. The conversation ID which contains the tree.\n            If not supplied, the end goal will be changed on all trees.\n    \"\"\"\n    if conversation_id is None:\n        self.config.end_goal = end_goal\n        for conversation_id in self.trees:\n            if not self.trees[conversation_id][\"tree\"]._config_modified:\n                self.trees[conversation_id][\"tree\"].change_end_goal(end_goal)\n                self.trees[conversation_id][\"tree\"]._config_modified = False\n    else:\n        if conversation_id not in self.trees:\n            raise ValueError(f\"Tree {conversation_id} not found\")\n\n        self.trees[conversation_id][\"tree\"].change_end_goal(end_goal)\n</code></pre>"},{"location":"Reference/Managers/#elysia.api.services.tree.TreeManager.change_style","title":"<code>change_style(style, conversation_id=None)</code>","text":"<p>Change the style for a tree in the TreeManager. Or change the global style for all trees (if conversation_id is not supplied). And applies these changes to current trees with default settings.</p> <p>Parameters:</p> Name Type Description Default <code>style</code> <code>str</code> <p>The new style for the tree.</p> required <code>conversation_id</code> <code>str | None</code> <p>Optional. The conversation ID which contains the tree. If not supplied, the style will be changed on all trees.</p> <code>None</code> Source code in <code>elysia/api/services/tree.py</code> <pre><code>def change_style(self, style: str, conversation_id: str | None = None):\n    \"\"\"\n    Change the style for a tree in the TreeManager.\n    Or change the global style for all trees (if conversation_id is not supplied).\n    And applies these changes to current trees with default settings.\n\n    Args:\n        style (str): The new style for the tree.\n        conversation_id (str | None): Optional. The conversation ID which contains the tree.\n            If not supplied, the style will be changed on all trees.\n    \"\"\"\n    if conversation_id is None:\n        self.config.style = style\n        for conversation_id in self.trees:\n            if not self.trees[conversation_id][\"tree\"]._config_modified:\n                self.trees[conversation_id][\"tree\"].change_style(style)\n                self.trees[conversation_id][\"tree\"]._config_modified = False\n    else:\n        if conversation_id not in self.trees:\n            raise ValueError(f\"Tree {conversation_id} not found\")\n\n        self.trees[conversation_id][\"tree\"].change_style(style)\n</code></pre>"},{"location":"Reference/Managers/#elysia.api.services.tree.TreeManager.check_all_trees_timeout","title":"<code>check_all_trees_timeout()</code>","text":"<p>Check all trees in the TreeManager and remove any that have not been active in the last tree_timeout.</p> Source code in <code>elysia/api/services/tree.py</code> <pre><code>def check_all_trees_timeout(self):\n    \"\"\"\n    Check all trees in the TreeManager and remove any that have not been active in the last tree_timeout.\n    \"\"\"\n    if self.tree_timeout == datetime.timedelta(minutes=0):\n        return\n\n    convs_to_remove = []\n    for i, conversation_id in enumerate(self.trees):\n        if self.check_tree_timeout(conversation_id):\n            convs_to_remove.append(conversation_id)\n\n    for conversation_id in convs_to_remove:\n        del self.trees[conversation_id]\n</code></pre>"},{"location":"Reference/Managers/#elysia.api.services.tree.TreeManager.check_tree_exists_weaviate","title":"<code>check_tree_exists_weaviate(conversation_id, client_manager)</code>  <code>async</code>","text":"<p>Check if a tree exists in a Weaviate instance. The collection ELYSIA_TREES__ must exist, returns False if it doesn't.</p> <p>Parameters:</p> Name Type Description Default <code>conversation_id</code> <code>str</code> <p>The conversation ID which contains the tree.</p> required <code>client_manager</code> <code>ClientManager</code> <p>The client manager to use for the tree.</p> required <p>Returns:</p> Type Description <code>bool</code> <p>True if the tree exists in the Weaviate instance, False otherwise.</p> Source code in <code>elysia/api/services/tree.py</code> <pre><code>async def check_tree_exists_weaviate(\n    self, conversation_id: str, client_manager: ClientManager\n):\n    \"\"\"\n    Check if a tree exists in a Weaviate instance.\n    The collection ELYSIA_TREES__ must exist, returns False if it doesn't.\n\n    Args:\n        conversation_id (str): The conversation ID which contains the tree.\n        client_manager (ClientManager): The client manager to use for the tree.\n\n    Returns:\n        (bool): True if the tree exists in the Weaviate instance, False otherwise.\n    \"\"\"\n    async with client_manager.connect_to_async_client() as client:\n        if not await client.collections.exists(\"ELYSIA_TREES__\"):\n            return False\n\n        collection = client.collections.get(\"ELYSIA_TREES__\")\n        uuid = generate_uuid5(conversation_id)\n        return await collection.data.exists(uuid)\n</code></pre>"},{"location":"Reference/Managers/#elysia.api.services.tree.TreeManager.check_tree_timeout","title":"<code>check_tree_timeout(conversation_id)</code>","text":"<p>Check if a tree has been idle for the last tree_timeout.</p> <p>Parameters:</p> Name Type Description Default <code>conversation_id</code> <code>str</code> <p>The conversation ID which contains the tree.</p> required <p>Returns:</p> Type Description <code>bool</code> <p>True if the tree has been idle for the last tree_timeout, False otherwise.</p> Source code in <code>elysia/api/services/tree.py</code> <pre><code>def check_tree_timeout(self, conversation_id: str):\n    \"\"\"\n    Check if a tree has been idle for the last tree_timeout.\n\n    Args:\n        conversation_id (str): The conversation ID which contains the tree.\n\n    Returns:\n        (bool): True if the tree has been idle for the last tree_timeout, False otherwise.\n    \"\"\"\n    # if tree not found, return True\n    if conversation_id not in self.trees:\n        return True\n\n    # Remove any trees that have not been active in the last TREE_TIMEOUT minutes\n    if (\n        \"last_request\" in self.trees[conversation_id]\n        and datetime.datetime.now() - self.trees[conversation_id][\"last_request\"]\n        &gt; self.tree_timeout\n    ):\n        return True\n\n    return False\n</code></pre>"},{"location":"Reference/Managers/#elysia.api.services.tree.TreeManager.configure","title":"<code>configure(conversation_id=None, replace=False, **kwargs)</code>","text":"<p>Configure the settings for a tree in the TreeManager.</p> <p>Parameters:</p> Name Type Description Default <code>conversation_id</code> <code>str | None</code> <p>The conversation ID which contains the tree.</p> <code>None</code> <code>replace</code> <code>bool</code> <p>Whether to override the current settings with the new settings. When this is True, all existing settings are removed, and only the new settings are used. Defaults to False.</p> <code>False</code> <code>**kwargs</code> <code>Any</code> <p>The keyword arguments to pass to the Settings.configure() method.</p> <code>{}</code> Source code in <code>elysia/api/services/tree.py</code> <pre><code>def configure(\n    self, conversation_id: str | None = None, replace: bool = False, **kwargs: Any\n):\n    \"\"\"\n    Configure the settings for a tree in the TreeManager.\n\n    Args:\n        conversation_id (str | None): The conversation ID which contains the tree.\n        replace (bool): Whether to override the current settings with the new settings.\n            When this is True, all existing settings are removed, and only the new settings are used.\n            Defaults to False.\n        **kwargs (Any): The keyword arguments to pass to the Settings.configure() method.\n    \"\"\"\n    if conversation_id is None:\n        self.settings.configure(replace=replace, **kwargs)\n        self.config.settings = self.settings\n    else:\n        self.get_tree(conversation_id).settings.configure(replace=replace, **kwargs)\n</code></pre>"},{"location":"Reference/Managers/#elysia.api.services.tree.TreeManager.delete_tree_local","title":"<code>delete_tree_local(conversation_id)</code>","text":"<p>Delete a tree from the TreeManager.</p> <p>Parameters:</p> Name Type Description Default <code>conversation_id</code> <code>str</code> <p>The conversation ID of the tree to be deleted.</p> required Source code in <code>elysia/api/services/tree.py</code> <pre><code>def delete_tree_local(self, conversation_id: str):\n    \"\"\"\n    Delete a tree from the TreeManager.\n\n    Args:\n        conversation_id (str): The conversation ID of the tree to be deleted.\n    \"\"\"\n    if conversation_id in self.trees:\n        del self.trees[conversation_id]\n</code></pre>"},{"location":"Reference/Managers/#elysia.api.services.tree.TreeManager.delete_tree_weaviate","title":"<code>delete_tree_weaviate(conversation_id, client_manager)</code>  <code>async</code>","text":"<p>Delete a tree from the stored trees in Weaviate.</p> <p>Parameters:</p> Name Type Description Default <code>conversation_id</code> <code>str</code> <p>The conversation ID of the tree to be deleted.</p> required <code>client_manager</code> <code>ClientManager</code> <p>The client manager pointing to the Weaviate instance containing the tree.</p> required Source code in <code>elysia/api/services/tree.py</code> <pre><code>async def delete_tree_weaviate(\n    self, conversation_id: str, client_manager: ClientManager\n):\n    \"\"\"\n    Delete a tree from the stored trees in Weaviate.\n\n    Args:\n        conversation_id (str): The conversation ID of the tree to be deleted.\n        client_manager (ClientManager): The client manager pointing to the Weaviate instance containing the tree.\n    \"\"\"\n    await delete_tree_from_weaviate(\n        conversation_id, \"ELYSIA_TREES__\", client_manager\n    )\n</code></pre>"},{"location":"Reference/Managers/#elysia.api.services.tree.TreeManager.get_event","title":"<code>get_event(conversation_id)</code>","text":"<p>Get the asyncio.Event for a tree in the TreeManager. This is cleared when the tree is processing, and set when the tree is idle. This is used to block the API from sending multiple requests to the tree at once.</p> <p>Parameters:</p> Name Type Description Default <code>conversation_id</code> <code>str</code> <p>The conversation ID which contains the tree.</p> required <p>Returns:</p> Type Description <code>Event</code> <p>The event for the tree.</p> Source code in <code>elysia/api/services/tree.py</code> <pre><code>def get_event(self, conversation_id: str):\n    \"\"\"\n    Get the asyncio.Event for a tree in the TreeManager.\n    This is cleared when the tree is processing, and set when the tree is idle.\n    This is used to block the API from sending multiple requests to the tree at once.\n\n    Args:\n        conversation_id (str): The conversation ID which contains the tree.\n\n    Returns:\n        (asyncio.Event): The event for the tree.\n    \"\"\"\n    return self.trees[conversation_id][\"event\"]\n</code></pre>"},{"location":"Reference/Managers/#elysia.api.services.tree.TreeManager.get_tree","title":"<code>get_tree(conversation_id)</code>","text":"<p>Get a tree from the TreeManager. Will raise a ValueError if the tree is not found.</p> <p>Parameters:</p> Name Type Description Default <code>conversation_id</code> <code>str</code> <p>The conversation ID which contains the tree.</p> required <p>Returns:</p> Type Description <code>Tree</code> <p>The tree associated with the conversation ID.</p> Source code in <code>elysia/api/services/tree.py</code> <pre><code>def get_tree(self, conversation_id: str):\n    \"\"\"\n    Get a tree from the TreeManager.\n    Will raise a ValueError if the tree is not found.\n\n    Args:\n        conversation_id (str): The conversation ID which contains the tree.\n\n    Returns:\n        (Tree): The tree associated with the conversation ID.\n    \"\"\"\n    if conversation_id not in self.trees:\n        raise ValueError(\n            f\"Tree {conversation_id} not found. Please initialise a tree first (by calling `add_tree`).\"\n        )\n\n    return self.trees[conversation_id][\"tree\"]\n</code></pre>"},{"location":"Reference/Managers/#elysia.api.services.tree.TreeManager.load_tree_weaviate","title":"<code>load_tree_weaviate(conversation_id, client_manager)</code>  <code>async</code>","text":"<p>Load a tree from Weaviate. The conversation ID from the loaded tree is placed into the tree manager (possibly overwriting an existing tree with the same conversation ID). Then the tree itself is not returned - instead the list of frontend payloads that were yielded to the frontend by the tree is returned.</p> <p>Parameters:</p> Name Type Description Default <code>conversation_id</code> <code>str</code> <p>The conversation ID which contains the tree.</p> required <code>client_manager</code> <code>ClientManager</code> <p>The client manager to use for the tree.</p> required <p>Returns:</p> Type Description <code>list</code> <p>A list of dictionaries, each containing a frontend payload that was used to generate the tree. The list is ordered by the time the payload was originally sent to the frontend (at the time it was saved).</p> Source code in <code>elysia/api/services/tree.py</code> <pre><code>async def load_tree_weaviate(\n    self, conversation_id: str, client_manager: ClientManager\n):\n    \"\"\"\n    Load a tree from Weaviate.\n    The conversation ID from the loaded tree is placed into the tree manager\n    (possibly overwriting an existing tree with the same conversation ID).\n    Then the tree itself is not returned - instead the list of frontend payloads\n    that were yielded to the frontend by the tree is returned.\n\n    Args:\n        conversation_id (str): The conversation ID which contains the tree.\n        client_manager (ClientManager): The client manager to use for the tree.\n\n    Returns:\n        (list): A list of dictionaries, each containing a frontend payload that was used to generate the tree.\n            The list is ordered by the time the payload was originally sent to the frontend (at the time it was saved).\n    \"\"\"\n    tree = await Tree.import_from_weaviate(\n        \"ELYSIA_TREES__\", conversation_id, client_manager\n    )\n    if conversation_id not in self.trees:\n        self.trees[conversation_id] = {\n            \"tree\": None,\n            \"event\": asyncio.Event(),\n            \"last_request\": datetime.datetime.now(),\n        }\n    self.trees[conversation_id][\"tree\"] = tree\n    self.trees[conversation_id][\"event\"].set()\n    self.update_tree_last_request(conversation_id)\n    return tree.returner.store\n</code></pre>"},{"location":"Reference/Managers/#elysia.api.services.tree.TreeManager.process_tree","title":"<code>process_tree(query, conversation_id, query_id=None, training_route='', collection_names=[], client_manager=None)</code>  <code>async</code>","text":"<p>Process a tree in the TreeManager. This is an async generator which yields results from the tree.async_run() method.</p> <p>Parameters:</p> Name Type Description Default <code>query</code> <code>str</code> <p>Required. The user input/prompt to process in the decision tree.</p> required <code>conversation_id</code> <code>str</code> <p>Required. The conversation ID which contains the tree.</p> required <code>query_id</code> <code>str</code> <p>Optional. A unique identifier for the query. If not supplied, a random UUID will be generated.</p> <code>None</code> <code>training_route</code> <code>str</code> <p>Optional. The training route, a string of the form \"tool1/tool2/tool1\" etc. See the <code>tree.async_run()</code> method for more details.</p> <code>''</code> <code>collection_names</code> <code>list[str]</code> <p>Optional. A list of collection names to use in the query. If not supplied, all collections will be used.</p> <code>[]</code> <code>client_manager</code> <code>ClientManager | None</code> <p>Optional. A client manager to use for the query. If not supplied, a new ClientManager will be created.</p> <code>None</code> Source code in <code>elysia/api/services/tree.py</code> <pre><code>async def process_tree(\n    self,\n    query: str,\n    conversation_id: str,\n    query_id: str | None = None,\n    training_route: str = \"\",\n    collection_names: list[str] = [],\n    client_manager: ClientManager | None = None,\n):\n    \"\"\"\n    Process a tree in the TreeManager.\n    This is an async generator which yields results from the tree.async_run() method.\n\n    Args:\n        query (str): Required. The user input/prompt to process in the decision tree.\n        conversation_id (str): Required. The conversation ID which contains the tree.\n        query_id (str): Optional. A unique identifier for the query.\n            If not supplied, a random UUID will be generated.\n        training_route (str): Optional. The training route, a string of the form \"tool1/tool2/tool1\" etc.\n            See the `tree.async_run()` method for more details.\n        collection_names (list[str]): Optional. A list of collection names to use in the query.\n            If not supplied, all collections will be used.\n        client_manager (ClientManager | None): Optional. A client manager to use for the query.\n            If not supplied, a new ClientManager will be created.\n    \"\"\"\n\n    if query_id is None:\n        query_id = str(uuid.uuid4())\n\n    tree: Tree = self.get_tree(conversation_id)\n    self.update_tree_last_request(conversation_id)\n\n    # wait for the tree to be idle\n    await self.trees[conversation_id][\"event\"].wait()\n\n    # clear the event, set it to working\n    self.trees[conversation_id][\"event\"].clear()\n\n    try:\n        async for yielded_result in tree.async_run(\n            query,\n            collection_names=collection_names,\n            client_manager=client_manager,\n            query_id=query_id,\n            training_route=training_route,\n            close_clients_after_completion=False,\n        ):\n            yield yielded_result\n            self.update_tree_last_request(conversation_id)\n\n    finally:\n        # set the event to idle\n        self.trees[conversation_id][\"event\"].set()\n</code></pre>"},{"location":"Reference/Managers/#elysia.api.services.tree.TreeManager.save_tree_weaviate","title":"<code>save_tree_weaviate(conversation_id, client_manager)</code>  <code>async</code>","text":"<p>Save a tree to Weaviate to collection ELYSIA_TREES__. Creates the collection if it doesn't exist.</p> <p>Parameters:</p> Name Type Description Default <code>conversation_id</code> <code>str</code> <p>The conversation ID which contains the tree.</p> required <code>client_manager</code> <code>ClientManager</code> <p>The client manager to use for the tree.</p> required Source code in <code>elysia/api/services/tree.py</code> <pre><code>async def save_tree_weaviate(\n    self, conversation_id: str, client_manager: ClientManager\n):\n    \"\"\"\n    Save a tree to Weaviate to collection ELYSIA_TREES__.\n    Creates the collection if it doesn't exist.\n\n    Args:\n        conversation_id (str): The conversation ID which contains the tree.\n        client_manager (ClientManager): The client manager to use for the tree.\n    \"\"\"\n    tree: Tree = self.get_tree(conversation_id)\n    await tree.export_to_weaviate(\"ELYSIA_TREES__\", client_manager)\n</code></pre>"},{"location":"Reference/Managers/#elysia.api.services.tree.TreeManager.tree_exists","title":"<code>tree_exists(conversation_id)</code>","text":"<p>Check if a tree exists in the TreeManager.</p> <p>Parameters:</p> Name Type Description Default <code>conversation_id</code> <code>str</code> <p>The conversation ID which may contain the tree.</p> required <p>Returns:</p> Type Description <code>bool</code> <p>True if the tree exists, False otherwise.</p> Source code in <code>elysia/api/services/tree.py</code> <pre><code>def tree_exists(self, conversation_id: str):\n    \"\"\"\n    Check if a tree exists in the TreeManager.\n\n    Args:\n        conversation_id (str): The conversation ID which may contain the tree.\n\n    Returns:\n        (bool): True if the tree exists, False otherwise.\n    \"\"\"\n    return conversation_id in self.trees\n</code></pre>"},{"location":"Reference/Objects/","title":"Objects","text":""},{"location":"Reference/Objects/#elysia.objects.Completed","title":"<code>Completed</code>","text":"<p>               Bases: <code>Update</code></p> <p>Completed message to be sent to the frontend (tree is complete all recursions).</p> Source code in <code>elysia/objects.py</code> <pre><code>class Completed(Update):\n    \"\"\"\n    Completed message to be sent to the frontend (tree is complete all recursions).\n    \"\"\"\n\n    def __init__(self):\n        Update.__init__(self, \"completed\", {})\n</code></pre>"},{"location":"Reference/Objects/#elysia.objects.Error","title":"<code>Error</code>","text":"<p>               Bases: <code>Update</code></p> <p>Error objects are used to communicate errors to the decision agent/tool calls. When yielded, Error objects are automatically saved inside the TreeData object. When calling the same tool again, the saved Error object is automatically loaded into any tool calls made with the same tool name. All errors are shown to the decision agent to help decide whether the tool should be called again (retried), or a different tool should be called.</p> Source code in <code>elysia/objects.py</code> <pre><code>class Error(Update):\n    \"\"\"\n    Error objects are used to communicate errors to the decision agent/tool calls.\n    When yielded, Error objects are automatically saved inside the TreeData object.\n    When calling the same tool again, the saved Error object is automatically loaded into any tool calls made with the same tool name.\n    All errors are shown to the decision agent to help decide whether the tool should be called again (retried), or a different tool should be called.\n    \"\"\"\n\n    def __init__(self, feedback: str = \"\", error_message: str = \"\"):\n        \"\"\"\n        Args:\n            feedback (str): The feedback to display to the decision agent.\n                Usually this will be the error message, but it could be formatted more specifically.\n        \"\"\"\n        self.feedback = feedback\n        self.error_message = error_message\n\n        if feedback == \"\":\n            self.feedback = \"An unknown issue occurred.\"\n\n        Update.__init__(\n            self,\n            \"self_healing_error\",\n            {\"feedback\": self.feedback, \"error_message\": self.error_message},\n        )\n</code></pre>"},{"location":"Reference/Objects/#elysia.objects.Error.__init__","title":"<code>__init__(feedback='', error_message='')</code>","text":"<p>Parameters:</p> Name Type Description Default <code>feedback</code> <code>str</code> <p>The feedback to display to the decision agent. Usually this will be the error message, but it could be formatted more specifically.</p> <code>''</code> Source code in <code>elysia/objects.py</code> <pre><code>def __init__(self, feedback: str = \"\", error_message: str = \"\"):\n    \"\"\"\n    Args:\n        feedback (str): The feedback to display to the decision agent.\n            Usually this will be the error message, but it could be formatted more specifically.\n    \"\"\"\n    self.feedback = feedback\n    self.error_message = error_message\n\n    if feedback == \"\":\n        self.feedback = \"An unknown issue occurred.\"\n\n    Update.__init__(\n        self,\n        \"self_healing_error\",\n        {\"feedback\": self.feedback, \"error_message\": self.error_message},\n    )\n</code></pre>"},{"location":"Reference/Objects/#elysia.objects.Result","title":"<code>Result</code>","text":"<p>               Bases: <code>Return</code></p> <p>Result objects are returned to the frontend. These are displayed on the frontend. E.g. a table, a chart, a text response, etc.</p> <p>You can yield a <code>Result</code> directly, and specify the <code>type</code> and <code>name</code> of the result.</p> Source code in <code>elysia/objects.py</code> <pre><code>class Result(Return):\n    \"\"\"\n    Result objects are returned to the frontend.\n    These are displayed on the frontend.\n    E.g. a table, a chart, a text response, etc.\n\n    You can yield a `Result` directly, and specify the `type` and `name` of the result.\n    \"\"\"\n\n    def __init__(\n        self,\n        objects: list[dict],\n        metadata: dict = {},\n        payload_type: str = \"default\",\n        name: str = \"default\",\n        mapping: dict | None = None,\n        llm_message: str | None = None,\n        unmapped_keys: list[str] = [\"_REF_ID\"],\n        display: bool = True,\n    ):\n        \"\"\"\n        Args:\n            objects (list[dict]): The objects attached to this result.\n            payload_type: (str): Identifier for the type of result.\n            metadata (dict): The metadata attached to this result,\n                for example, query used, time taken, any other information not directly within the objects\n            name (str): The name of the result, e.g. this could be the name of the collection queried.\n                Used to index the result in the environment.\n            mapping (dict | None): A mapping of the objects to the frontend.\n                Essentially, if the objects are going to be displayed on the frontend, the frontend has specific keys that it wants the objects to have.\n                This is a dictionary that maps from frontend keys to the object keys.\n            llm_message (str | None): A message to be displayed to the LLM to help it parse the result.\n                You can use the following placeholders that will automatically be replaced with the correct values:\n\n                - {type}: The type of the object\n                - {name}: The name of the object\n                - {num_objects}: The number of objects in the object\n                - {metadata_key}: Any key in the metadata dictionary\n            unmapped_keys (list[str]): A list of keys that are not mapped to the frontend.\n            display (bool): Whether to display the result on the frontend when yielding this object.\n                Defaults to `True`.\n        \"\"\"\n        Return.__init__(self, \"result\", payload_type)\n        self.objects = objects\n        self.metadata = metadata\n        self.name = name\n        self.mapping = mapping\n        self.llm_message = llm_message\n        self.unmapped_keys = unmapped_keys\n        self.display = display\n\n    def __len__(self):\n        return len(self.objects)\n\n    def format_llm_message(self):\n        \"\"\"\n        llm_message is a string that is used to help the LLM parse the output of the tool.\n        It is a placeholder for the actual message that will be displayed to the user.\n\n        You can use the following placeholders:\n\n        - {payload_type}: The type of the object\n        - {name}: The name of the object\n        - {num_objects}: The number of objects in the object\n        - {metadata_key}: Any key in the metadata dictionary\n        \"\"\"\n        if self.llm_message is None:\n            return \"\"\n\n        return self.llm_message.format_map(\n            {\n                \"payload_type\": self.payload_type,\n                \"name\": self.name,\n                \"num_objects\": len(self),\n                **self.metadata,\n            }\n        )\n\n    def do_mapping(self, objects: list[dict]):\n\n        if self.mapping is None:\n            return objects\n\n        output_objects = []\n        for obj in objects:\n            output_objects.append(\n                {\n                    key: obj[self.mapping[key]]\n                    for key in self.mapping\n                    if self.mapping[key] != \"\"\n                }\n            )\n            output_objects[-1].update(\n                {key: obj[key] for key in self.unmapped_keys if key in obj}\n            )\n\n        return output_objects\n\n    def to_json(self, mapping: bool = False):\n        \"\"\"\n        Convert the result to a list of dictionaries.\n\n        Args:\n            mapping (bool): Whether to map the objects to the frontend.\n                This will use the `mapping` dictionary created on initialisation of the `Result` object.\n                If `False`, the objects are returned as is.\n                Defaults to `False`.\n\n        Returns:\n            (list[dict]): A list of dictionaries, which can be serialised to JSON.\n        \"\"\"\n        from elysia.util.parsing import format_dict_to_serialisable\n\n        assert all(\n            isinstance(obj, dict) for obj in self.objects\n        ), \"All objects must be dictionaries\"\n\n        if mapping and self.mapping is not None:\n            output_objects = self.do_mapping(self.objects)\n        else:\n            output_objects = self.objects\n\n        for object in output_objects:\n            format_dict_to_serialisable(object)\n\n        return output_objects\n\n    async def to_frontend(\n        self,\n        user_id: str,\n        conversation_id: str,\n        query_id: str,\n    ):\n        \"\"\"\n        Convert the result to a frontend payload.\n        This is a wrapper around the `to_json` method.\n        But the objects and metadata are inside a `payload` key, which also includes a `type` key,\n        being the frontend identifier for the type of payload being sent.\n        (e.g. `ticket`, `product`, `message`, etc.)\n\n        The outside of the payload also contains the user_id, conversation_id, and query_id.\n\n        Args:\n            user_id (str): The user ID.\n            conversation_id (str): The conversation ID.\n            query_id (str): The query ID.\n\n        Returns:\n            (dict): The frontend payload, which is a dictionary with the following structure:\n                ```python\n                {\n                    \"type\": \"result\",\n                    \"user_id\": str,\n                    \"conversation_id\": str,\n                    \"query_id\": str,\n                    \"id\": str,\n                    \"payload\": dict = {\n                        \"type\": str,\n                        \"objects\": list[dict],\n                        \"metadata\": dict,\n                    },\n                }\n                ```\n        \"\"\"\n        if not self.display:\n            return\n\n        objects = self.to_json(mapping=True)\n        if len(objects) == 0:\n            return\n\n        payload = {\n            \"type\": self.payload_type,\n            \"objects\": objects,\n            \"metadata\": self.metadata,\n        }\n\n        return {\n            \"type\": self.frontend_type,\n            \"user_id\": user_id,\n            \"conversation_id\": conversation_id,\n            \"query_id\": query_id,\n            \"id\": self.frontend_type[:3] + \"-\" + str(uuid.uuid4()),\n            \"payload\": payload,\n        }\n\n    def llm_parse(self):\n        \"\"\"\n        This method is called when the result is displayed to the LLM.\n        It is used to display custom information to the LLM about the result.\n        If `llm_message` was defined, then the llm message is formatted using the placeholders.\n        Otherwise a default message is used.\n\n        Returns:\n            (str): The formatted llm message.\n        \"\"\"\n\n        if self.llm_message is not None:\n            return self.format_llm_message()\n        else:\n            # Default message\n            return f\"Displayed: A {self.payload_type} object with {len(self.objects)} objects.\"\n</code></pre>"},{"location":"Reference/Objects/#elysia.objects.Result.__init__","title":"<code>__init__(objects, metadata={}, payload_type='default', name='default', mapping=None, llm_message=None, unmapped_keys=['_REF_ID'], display=True)</code>","text":"<p>Parameters:</p> Name Type Description Default <code>objects</code> <code>list[dict]</code> <p>The objects attached to this result.</p> required <code>payload_type</code> <code>str</code> <p>(str): Identifier for the type of result.</p> <code>'default'</code> <code>metadata</code> <code>dict</code> <p>The metadata attached to this result, for example, query used, time taken, any other information not directly within the objects</p> <code>{}</code> <code>name</code> <code>str</code> <p>The name of the result, e.g. this could be the name of the collection queried. Used to index the result in the environment.</p> <code>'default'</code> <code>mapping</code> <code>dict | None</code> <p>A mapping of the objects to the frontend. Essentially, if the objects are going to be displayed on the frontend, the frontend has specific keys that it wants the objects to have. This is a dictionary that maps from frontend keys to the object keys.</p> <code>None</code> <code>llm_message</code> <code>str | None</code> <p>A message to be displayed to the LLM to help it parse the result. You can use the following placeholders that will automatically be replaced with the correct values:</p> <ul> <li>{type}: The type of the object</li> <li>{name}: The name of the object</li> <li>{num_objects}: The number of objects in the object</li> <li>{metadata_key}: Any key in the metadata dictionary</li> </ul> <code>None</code> <code>unmapped_keys</code> <code>list[str]</code> <p>A list of keys that are not mapped to the frontend.</p> <code>['_REF_ID']</code> <code>display</code> <code>bool</code> <p>Whether to display the result on the frontend when yielding this object. Defaults to <code>True</code>.</p> <code>True</code> Source code in <code>elysia/objects.py</code> <pre><code>def __init__(\n    self,\n    objects: list[dict],\n    metadata: dict = {},\n    payload_type: str = \"default\",\n    name: str = \"default\",\n    mapping: dict | None = None,\n    llm_message: str | None = None,\n    unmapped_keys: list[str] = [\"_REF_ID\"],\n    display: bool = True,\n):\n    \"\"\"\n    Args:\n        objects (list[dict]): The objects attached to this result.\n        payload_type: (str): Identifier for the type of result.\n        metadata (dict): The metadata attached to this result,\n            for example, query used, time taken, any other information not directly within the objects\n        name (str): The name of the result, e.g. this could be the name of the collection queried.\n            Used to index the result in the environment.\n        mapping (dict | None): A mapping of the objects to the frontend.\n            Essentially, if the objects are going to be displayed on the frontend, the frontend has specific keys that it wants the objects to have.\n            This is a dictionary that maps from frontend keys to the object keys.\n        llm_message (str | None): A message to be displayed to the LLM to help it parse the result.\n            You can use the following placeholders that will automatically be replaced with the correct values:\n\n            - {type}: The type of the object\n            - {name}: The name of the object\n            - {num_objects}: The number of objects in the object\n            - {metadata_key}: Any key in the metadata dictionary\n        unmapped_keys (list[str]): A list of keys that are not mapped to the frontend.\n        display (bool): Whether to display the result on the frontend when yielding this object.\n            Defaults to `True`.\n    \"\"\"\n    Return.__init__(self, \"result\", payload_type)\n    self.objects = objects\n    self.metadata = metadata\n    self.name = name\n    self.mapping = mapping\n    self.llm_message = llm_message\n    self.unmapped_keys = unmapped_keys\n    self.display = display\n</code></pre>"},{"location":"Reference/Objects/#elysia.objects.Result.format_llm_message","title":"<code>format_llm_message()</code>","text":"<p>llm_message is a string that is used to help the LLM parse the output of the tool. It is a placeholder for the actual message that will be displayed to the user.</p> <p>You can use the following placeholders:</p> <ul> <li>{payload_type}: The type of the object</li> <li>{name}: The name of the object</li> <li>{num_objects}: The number of objects in the object</li> <li>{metadata_key}: Any key in the metadata dictionary</li> </ul> Source code in <code>elysia/objects.py</code> <pre><code>def format_llm_message(self):\n    \"\"\"\n    llm_message is a string that is used to help the LLM parse the output of the tool.\n    It is a placeholder for the actual message that will be displayed to the user.\n\n    You can use the following placeholders:\n\n    - {payload_type}: The type of the object\n    - {name}: The name of the object\n    - {num_objects}: The number of objects in the object\n    - {metadata_key}: Any key in the metadata dictionary\n    \"\"\"\n    if self.llm_message is None:\n        return \"\"\n\n    return self.llm_message.format_map(\n        {\n            \"payload_type\": self.payload_type,\n            \"name\": self.name,\n            \"num_objects\": len(self),\n            **self.metadata,\n        }\n    )\n</code></pre>"},{"location":"Reference/Objects/#elysia.objects.Result.llm_parse","title":"<code>llm_parse()</code>","text":"<p>This method is called when the result is displayed to the LLM. It is used to display custom information to the LLM about the result. If <code>llm_message</code> was defined, then the llm message is formatted using the placeholders. Otherwise a default message is used.</p> <p>Returns:</p> Type Description <code>str</code> <p>The formatted llm message.</p> Source code in <code>elysia/objects.py</code> <pre><code>def llm_parse(self):\n    \"\"\"\n    This method is called when the result is displayed to the LLM.\n    It is used to display custom information to the LLM about the result.\n    If `llm_message` was defined, then the llm message is formatted using the placeholders.\n    Otherwise a default message is used.\n\n    Returns:\n        (str): The formatted llm message.\n    \"\"\"\n\n    if self.llm_message is not None:\n        return self.format_llm_message()\n    else:\n        # Default message\n        return f\"Displayed: A {self.payload_type} object with {len(self.objects)} objects.\"\n</code></pre>"},{"location":"Reference/Objects/#elysia.objects.Result.to_frontend","title":"<code>to_frontend(user_id, conversation_id, query_id)</code>  <code>async</code>","text":"<p>Convert the result to a frontend payload. This is a wrapper around the <code>to_json</code> method. But the objects and metadata are inside a <code>payload</code> key, which also includes a <code>type</code> key, being the frontend identifier for the type of payload being sent. (e.g. <code>ticket</code>, <code>product</code>, <code>message</code>, etc.)</p> <p>The outside of the payload also contains the user_id, conversation_id, and query_id.</p> <p>Parameters:</p> Name Type Description Default <code>user_id</code> <code>str</code> <p>The user ID.</p> required <code>conversation_id</code> <code>str</code> <p>The conversation ID.</p> required <code>query_id</code> <code>str</code> <p>The query ID.</p> required <p>Returns:</p> Type Description <code>dict</code> <p>The frontend payload, which is a dictionary with the following structure: <pre><code>{\n    \"type\": \"result\",\n    \"user_id\": str,\n    \"conversation_id\": str,\n    \"query_id\": str,\n    \"id\": str,\n    \"payload\": dict = {\n        \"type\": str,\n        \"objects\": list[dict],\n        \"metadata\": dict,\n    },\n}\n</code></pre></p> Source code in <code>elysia/objects.py</code> <pre><code>async def to_frontend(\n    self,\n    user_id: str,\n    conversation_id: str,\n    query_id: str,\n):\n    \"\"\"\n    Convert the result to a frontend payload.\n    This is a wrapper around the `to_json` method.\n    But the objects and metadata are inside a `payload` key, which also includes a `type` key,\n    being the frontend identifier for the type of payload being sent.\n    (e.g. `ticket`, `product`, `message`, etc.)\n\n    The outside of the payload also contains the user_id, conversation_id, and query_id.\n\n    Args:\n        user_id (str): The user ID.\n        conversation_id (str): The conversation ID.\n        query_id (str): The query ID.\n\n    Returns:\n        (dict): The frontend payload, which is a dictionary with the following structure:\n            ```python\n            {\n                \"type\": \"result\",\n                \"user_id\": str,\n                \"conversation_id\": str,\n                \"query_id\": str,\n                \"id\": str,\n                \"payload\": dict = {\n                    \"type\": str,\n                    \"objects\": list[dict],\n                    \"metadata\": dict,\n                },\n            }\n            ```\n    \"\"\"\n    if not self.display:\n        return\n\n    objects = self.to_json(mapping=True)\n    if len(objects) == 0:\n        return\n\n    payload = {\n        \"type\": self.payload_type,\n        \"objects\": objects,\n        \"metadata\": self.metadata,\n    }\n\n    return {\n        \"type\": self.frontend_type,\n        \"user_id\": user_id,\n        \"conversation_id\": conversation_id,\n        \"query_id\": query_id,\n        \"id\": self.frontend_type[:3] + \"-\" + str(uuid.uuid4()),\n        \"payload\": payload,\n    }\n</code></pre>"},{"location":"Reference/Objects/#elysia.objects.Result.to_json","title":"<code>to_json(mapping=False)</code>","text":"<p>Convert the result to a list of dictionaries.</p> <p>Parameters:</p> Name Type Description Default <code>mapping</code> <code>bool</code> <p>Whether to map the objects to the frontend. This will use the <code>mapping</code> dictionary created on initialisation of the <code>Result</code> object. If <code>False</code>, the objects are returned as is. Defaults to <code>False</code>.</p> <code>False</code> <p>Returns:</p> Type Description <code>list[dict]</code> <p>A list of dictionaries, which can be serialised to JSON.</p> Source code in <code>elysia/objects.py</code> <pre><code>def to_json(self, mapping: bool = False):\n    \"\"\"\n    Convert the result to a list of dictionaries.\n\n    Args:\n        mapping (bool): Whether to map the objects to the frontend.\n            This will use the `mapping` dictionary created on initialisation of the `Result` object.\n            If `False`, the objects are returned as is.\n            Defaults to `False`.\n\n    Returns:\n        (list[dict]): A list of dictionaries, which can be serialised to JSON.\n    \"\"\"\n    from elysia.util.parsing import format_dict_to_serialisable\n\n    assert all(\n        isinstance(obj, dict) for obj in self.objects\n    ), \"All objects must be dictionaries\"\n\n    if mapping and self.mapping is not None:\n        output_objects = self.do_mapping(self.objects)\n    else:\n        output_objects = self.objects\n\n    for object in output_objects:\n        format_dict_to_serialisable(object)\n\n    return output_objects\n</code></pre>"},{"location":"Reference/Objects/#elysia.objects.Retrieval","title":"<code>Retrieval</code>","text":"<p>               Bases: <code>Result</code></p> <p>Store of returned objects from a query/aggregate/any displayed results.</p> Source code in <code>elysia/objects.py</code> <pre><code>class Retrieval(Result):\n    \"\"\"\n    Store of returned objects from a query/aggregate/any displayed results.\n    \"\"\"\n\n    def __init__(\n        self,\n        objects: list[dict],\n        metadata: dict = {},\n        payload_type: str = \"default\",\n        name: str | None = None,\n        mapping: dict | None = None,\n        unmapped_keys: list[str] = [\n            \"uuid\",\n            \"ELYSIA_SUMMARY\",\n            \"collection_name\",\n            \"_REF_ID\",\n        ],\n        display: bool = True,\n    ) -&gt; None:\n        if name is None and \"collection_name\" in metadata:\n            result_name = metadata[\"collection_name\"]\n        elif name is None:\n            result_name = \"default\"\n        else:\n            result_name = name\n\n        Result.__init__(\n            self,\n            objects=objects,\n            payload_type=payload_type,\n            metadata=metadata,\n            name=result_name,\n            mapping=mapping,\n            unmapped_keys=unmapped_keys,\n            display=display,\n        )\n\n    def add_summaries(self, summaries: list[str] = []) -&gt; None:\n        for i, obj in enumerate(self.objects):\n            if i &lt; len(summaries):\n                obj[\"ELYSIA_SUMMARY\"] = summaries[i]\n            else:\n                obj[\"ELYSIA_SUMMARY\"] = \"\"\n\n    def llm_parse(self) -&gt; str:\n        out = \"\"\n        count = len(self.objects)\n\n        if \"collection_name\" in self.metadata:\n            if count != 0:\n                out += f\"\\nQueried collection: '{self.metadata['collection_name']}' and returned {count} objects, \"\n            else:\n                out += f\"\\nQueried collection: '{self.metadata['collection_name']}' but no objects were returned.\"\n                out += f\" Since it had no objects, judge the query that was created, and evaluate whether it was appropriate for the collection, the user prompt, and the data available.\"\n                out += f\" If it seemed innappropriate, you can choose to try again if you think it can still be completed (or there is more to do).\"\n        if \"return_type\" in self.metadata:\n            out += f\"\\nReturned with type '{self.metadata['return_type']}', \"\n        if \"output_type\" in self.metadata:\n            out += f\"\\noutputted '{'itemised summaries' if self.metadata['output_type'] == 'summary' else 'original objects'}'\\n\"\n        if \"query_text\" in self.metadata:\n            out += f\"\\nSearch terms: '{self.metadata['query_text']}'\"\n        if \"query_type\" in self.metadata:\n            out += f\"\\nType of query: '{self.metadata['query_type']}'\"\n        if \"impossible\" in self.metadata:\n            out += f\"\\nImpossible prompt: '{self.metadata['impossible']}'\"\n            if \"collection_name\" in self.metadata:\n                out += f\"\\nThis attempt at querying the collection: {self.metadata['collection_name']} was deemed impossible.\"\n            if \"impossible_reason\" in self.metadata:\n                out += f\"\\nReasoning for impossibility: {self.metadata['impossible_reason']}\"\n        if \"query_output\" in self.metadata:\n            out += f\"\\nThe query used was:\\n{self.metadata['query_output']}\"\n        return out\n\n    async def to_frontend(\n        self,\n        user_id: str,\n        conversation_id: str,\n        query_id: str,\n    ) -&gt; dict | None:\n        objects = self.to_json(mapping=True)\n        if len(objects) == 0:\n            return\n\n        payload = {\n            \"type\": self.payload_type,\n            \"objects\": objects,\n            \"metadata\": self.metadata,\n        }\n\n        if \"code\" in self.metadata:\n            payload[\"code\"] = self.metadata[\"code\"]\n\n        return {\n            \"type\": self.frontend_type,\n            \"user_id\": user_id,\n            \"conversation_id\": conversation_id,\n            \"query_id\": query_id,\n            \"id\": self.frontend_type[:3] + \"-\" + str(uuid.uuid4()),\n            \"payload\": payload,\n        }\n</code></pre>"},{"location":"Reference/Objects/#elysia.objects.Return","title":"<code>Return</code>","text":"<p>A Return object is something that is returned to the frontend. This kind of object is frontend-aware.</p> Source code in <code>elysia/objects.py</code> <pre><code>class Return:\n    \"\"\"\n    A Return object is something that is returned to the frontend.\n    This kind of object is frontend-aware.\n    \"\"\"\n\n    def __init__(self, frontend_type: str, payload_type: str):\n        self.frontend_type = frontend_type  # frontend identifier\n        self.payload_type = payload_type  # backend identifier\n</code></pre>"},{"location":"Reference/Objects/#elysia.objects.Status","title":"<code>Status</code>","text":"<p>               Bases: <code>Update</code></p> <p>Status message to be sent to the frontend for real-time updates in words.</p> Source code in <code>elysia/objects.py</code> <pre><code>class Status(Update):\n    \"\"\"\n    Status message to be sent to the frontend for real-time updates in words.\n    \"\"\"\n\n    def __init__(self, text: str):\n        self.text = text\n        Update.__init__(self, \"status\", {\"text\": text})\n</code></pre>"},{"location":"Reference/Objects/#elysia.objects.Text","title":"<code>Text</code>","text":"<p>               Bases: <code>Return</code></p> <p>Frontend Return Type 1: Text Objects is usually a one-element list containing a dict with a \"text\" key only. But is not limited to this.</p> Source code in <code>elysia/objects.py</code> <pre><code>class Text(Return):\n    \"\"\"\n    Frontend Return Type 1: Text\n    Objects is usually a one-element list containing a dict with a \"text\" key only.\n    But is not limited to this.\n    \"\"\"\n\n    def __init__(\n        self,\n        payload_type: str,\n        objects: list[dict],\n        metadata: dict = {},\n        display: bool = True,\n    ):\n        Return.__init__(self, \"text\", payload_type)\n        self.objects = objects\n        self.metadata = metadata\n        self.text = self._concat_text(self.objects)\n        self.display = display\n\n    def _concat_text(self, objects: list[dict]):\n        text = \"\"\n        for i, obj in enumerate(objects):\n            if \"text\" in obj:\n                spacer = \"\"\n                if (\n                    not obj[\"text\"].endswith(\" \")\n                    and not obj[\"text\"].endswith(\"\\n\")\n                    and i != len(objects) - 1\n                ):\n                    spacer += \" \"\n\n                if (\n                    i != len(objects) - 1\n                    and \"text\" in objects[i + 1]\n                    and objects[i + 1][\"text\"].startswith(\"* \")\n                    and not obj[\"text\"].endswith(\"\\n\")\n                ):\n                    spacer += \"\\n\"\n\n                text += obj[\"text\"] + spacer\n\n        text = text.replace(\"_REF_ID\", \"\")\n        text = text.replace(\"REF_ID\", \"\")\n        text = text.replace(\"  \", \" \")\n        return text\n\n    def to_json(self):\n        return {\n            \"type\": self.payload_type,\n            \"metadata\": self.metadata,\n            \"objects\": self.objects,\n        }\n\n    async def to_frontend(\n        self,\n        user_id: str,\n        conversation_id: str,\n        query_id: str,\n    ):\n        if not self.display:\n            return\n\n        return {\n            \"type\": self.frontend_type,\n            \"id\": self.frontend_type[:3] + \"-\" + str(uuid.uuid4()),\n            \"user_id\": user_id,\n            \"conversation_id\": conversation_id,\n            \"query_id\": query_id,\n            \"payload\": self.to_json(),\n        }\n</code></pre>"},{"location":"Reference/Objects/#elysia.objects.Tool","title":"<code>Tool</code>","text":"<p>The generic Tool class, which will be a superclass of any tools used by Elysia.</p> Source code in <code>elysia/objects.py</code> <pre><code>class Tool(metaclass=ToolMeta):\n    \"\"\"\n    The generic Tool class, which will be a superclass of any tools used by Elysia.\n    \"\"\"\n\n    @classmethod\n    def get_metadata(cls) -&gt; dict[str, str | bool | dict | None]:\n        \"\"\"Get tool metadata without instantiation.\"\"\"\n        return {\n            \"name\": getattr(cls, \"_tool_name\", None),\n            \"description\": getattr(cls, \"_tool_description\", None),\n            \"inputs\": getattr(cls, \"_tool_inputs\", None),\n            \"end\": getattr(cls, \"_tool_end\", False),\n        }\n\n    def __init__(\n        self,\n        name: str,\n        description: str,\n        status: str = \"\",\n        inputs: dict = {},\n        end: bool = False,\n        **kwargs,\n    ):\n        \"\"\"\n        Args:\n            name (str): The name of the tool. Required.\n            description (str): A detailed description of the tool to give to the LLM. Required.\n            status (str): A status update message to display while the tool is running. Optional, defaults to \"Running {name}...\".\n            inputs (dict): A dictionary of inputs for the tool, with the following structure:\n                ```python\n                {\n                    input_name: {\n                        \"description\": str,\n                        \"type\": str,\n                        \"default\": str,\n                        \"required\": bool\n                    }\n                }\n                ```\n            end (bool): Whether the tool is an end tool. Optional, defaults to False.\n        \"\"\"\n        self.name = name\n        self.description = description\n        self.inputs = inputs\n        self.end = end\n\n        if status == \"\":\n            self.status = f\"Running {self.name}...\"\n        else:\n            self.status = status\n\n    def get_default_inputs(self) -&gt; dict:\n        return {\n            key: value[\"default\"] if \"default\" in value else None\n            for key, value in self.inputs.items()\n        }\n\n    async def run_if_true(\n        self,\n        tree_data,\n        base_lm,\n        complex_lm,\n        client_manager,\n    ) -&gt; tuple[bool, dict]:\n        \"\"\"\n        This method is called to check if the tool should be run automatically.\n        If this returns `True`, then the tool is immediately called at the start of the tree.\n        Otherwise it does not appear in the decision tree.\n        You must also return a dictionary of inputs for the tool, which will be used to call the tool if `True` is returned.\n        If the inputs are None or an empty dictionary, then the default inputs will be used.\n\n        This must be an async function.\n\n        Args:\n            tree_data (TreeData): The tree data object.\n            base_lm (LM): The base language model, a dspy.LM object.\n            complex_lm (LM): The complex language model, a dspy.LM object.\n            client_manager (ClientManager): The client manager, a way of interfacing with a Weaviate client.\n\n        Returns:\n            bool: True if the tool should be run automatically, False otherwise.\n            dict: A dictionary of inputs for the tool, with the following structure:\n                ```python\n                {\n                    input_name: input_value\n                }\n                ```\n        \"\"\"\n        return False, {}\n\n    async def is_tool_available(\n        self,\n        tree_data,\n        base_lm,\n        complex_lm,\n        client_manager,\n    ) -&gt; bool:\n        \"\"\"\n        This method is called to check if the tool is available.\n        If this returns `True`, then the tool is available to be used by the LLM.\n        Otherwise it does not appear in the decision tree.\n\n        The difference between this and `run_if_true` is that `run_if_true` will _always_ run the __call__ method if it returns `True`,\n        even if the LLM does not choose to use the tool.\n\n        This must be an async function.\n\n        Args:\n            tree_data (TreeData): The tree data object.\n            base_lm (LM): The base language model, a dspy.LM object.\n            complex_lm (LM): The complex language model, a dspy.LM object.\n            client_manager (ClientManager): The client manager, a way of interfacing with a Weaviate client.\n\n        Returns:\n            bool: True if the tool is available, False otherwise.\n        \"\"\"\n        return True\n\n    async def __call__(\n        self, tree_data, inputs, base_lm, complex_lm, client_manager, **kwargs\n    ) -&gt; AsyncGenerator[Any, None]:\n        \"\"\"\n        This method is called to run the tool.\n\n        This must be an async generator, so objects must be yielded and not returned.\n\n        Args:\n            tree_data (TreeData): The data from the decision tree, includes the environment, user prompt, etc.\n                See the `TreeData` class for more details.\n            base_lm (LM): The base language model, a dspy.LM object.\n            complex_lm (LM): The complex language model, a dspy.LM object.\n            client_manager (ClientManager): The client manager, a way of interfacing with a Weaviate client.\n        \"\"\"\n        yield None\n</code></pre>"},{"location":"Reference/Objects/#elysia.objects.Tool.__call__","title":"<code>__call__(tree_data, inputs, base_lm, complex_lm, client_manager, **kwargs)</code>  <code>async</code>","text":"<p>This method is called to run the tool.</p> <p>This must be an async generator, so objects must be yielded and not returned.</p> <p>Parameters:</p> Name Type Description Default <code>tree_data</code> <code>TreeData</code> <p>The data from the decision tree, includes the environment, user prompt, etc. See the <code>TreeData</code> class for more details.</p> required <code>base_lm</code> <code>LM</code> <p>The base language model, a dspy.LM object.</p> required <code>complex_lm</code> <code>LM</code> <p>The complex language model, a dspy.LM object.</p> required <code>client_manager</code> <code>ClientManager</code> <p>The client manager, a way of interfacing with a Weaviate client.</p> required Source code in <code>elysia/objects.py</code> <pre><code>async def __call__(\n    self, tree_data, inputs, base_lm, complex_lm, client_manager, **kwargs\n) -&gt; AsyncGenerator[Any, None]:\n    \"\"\"\n    This method is called to run the tool.\n\n    This must be an async generator, so objects must be yielded and not returned.\n\n    Args:\n        tree_data (TreeData): The data from the decision tree, includes the environment, user prompt, etc.\n            See the `TreeData` class for more details.\n        base_lm (LM): The base language model, a dspy.LM object.\n        complex_lm (LM): The complex language model, a dspy.LM object.\n        client_manager (ClientManager): The client manager, a way of interfacing with a Weaviate client.\n    \"\"\"\n    yield None\n</code></pre>"},{"location":"Reference/Objects/#elysia.objects.Tool.__init__","title":"<code>__init__(name, description, status='', inputs={}, end=False, **kwargs)</code>","text":"<p>Parameters:</p> Name Type Description Default <code>name</code> <code>str</code> <p>The name of the tool. Required.</p> required <code>description</code> <code>str</code> <p>A detailed description of the tool to give to the LLM. Required.</p> required <code>status</code> <code>str</code> <p>A status update message to display while the tool is running. Optional, defaults to \"Running {name}...\".</p> <code>''</code> <code>inputs</code> <code>dict</code> <p>A dictionary of inputs for the tool, with the following structure: <pre><code>{\n    input_name: {\n        \"description\": str,\n        \"type\": str,\n        \"default\": str,\n        \"required\": bool\n    }\n}\n</code></pre></p> <code>{}</code> <code>end</code> <code>bool</code> <p>Whether the tool is an end tool. Optional, defaults to False.</p> <code>False</code> Source code in <code>elysia/objects.py</code> <pre><code>def __init__(\n    self,\n    name: str,\n    description: str,\n    status: str = \"\",\n    inputs: dict = {},\n    end: bool = False,\n    **kwargs,\n):\n    \"\"\"\n    Args:\n        name (str): The name of the tool. Required.\n        description (str): A detailed description of the tool to give to the LLM. Required.\n        status (str): A status update message to display while the tool is running. Optional, defaults to \"Running {name}...\".\n        inputs (dict): A dictionary of inputs for the tool, with the following structure:\n            ```python\n            {\n                input_name: {\n                    \"description\": str,\n                    \"type\": str,\n                    \"default\": str,\n                    \"required\": bool\n                }\n            }\n            ```\n        end (bool): Whether the tool is an end tool. Optional, defaults to False.\n    \"\"\"\n    self.name = name\n    self.description = description\n    self.inputs = inputs\n    self.end = end\n\n    if status == \"\":\n        self.status = f\"Running {self.name}...\"\n    else:\n        self.status = status\n</code></pre>"},{"location":"Reference/Objects/#elysia.objects.Tool.get_metadata","title":"<code>get_metadata()</code>  <code>classmethod</code>","text":"<p>Get tool metadata without instantiation.</p> Source code in <code>elysia/objects.py</code> <pre><code>@classmethod\ndef get_metadata(cls) -&gt; dict[str, str | bool | dict | None]:\n    \"\"\"Get tool metadata without instantiation.\"\"\"\n    return {\n        \"name\": getattr(cls, \"_tool_name\", None),\n        \"description\": getattr(cls, \"_tool_description\", None),\n        \"inputs\": getattr(cls, \"_tool_inputs\", None),\n        \"end\": getattr(cls, \"_tool_end\", False),\n    }\n</code></pre>"},{"location":"Reference/Objects/#elysia.objects.Tool.is_tool_available","title":"<code>is_tool_available(tree_data, base_lm, complex_lm, client_manager)</code>  <code>async</code>","text":"<p>This method is called to check if the tool is available. If this returns <code>True</code>, then the tool is available to be used by the LLM. Otherwise it does not appear in the decision tree.</p> <p>The difference between this and <code>run_if_true</code> is that <code>run_if_true</code> will always run the call method if it returns <code>True</code>, even if the LLM does not choose to use the tool.</p> <p>This must be an async function.</p> <p>Parameters:</p> Name Type Description Default <code>tree_data</code> <code>TreeData</code> <p>The tree data object.</p> required <code>base_lm</code> <code>LM</code> <p>The base language model, a dspy.LM object.</p> required <code>complex_lm</code> <code>LM</code> <p>The complex language model, a dspy.LM object.</p> required <code>client_manager</code> <code>ClientManager</code> <p>The client manager, a way of interfacing with a Weaviate client.</p> required <p>Returns:</p> Name Type Description <code>bool</code> <code>bool</code> <p>True if the tool is available, False otherwise.</p> Source code in <code>elysia/objects.py</code> <pre><code>async def is_tool_available(\n    self,\n    tree_data,\n    base_lm,\n    complex_lm,\n    client_manager,\n) -&gt; bool:\n    \"\"\"\n    This method is called to check if the tool is available.\n    If this returns `True`, then the tool is available to be used by the LLM.\n    Otherwise it does not appear in the decision tree.\n\n    The difference between this and `run_if_true` is that `run_if_true` will _always_ run the __call__ method if it returns `True`,\n    even if the LLM does not choose to use the tool.\n\n    This must be an async function.\n\n    Args:\n        tree_data (TreeData): The tree data object.\n        base_lm (LM): The base language model, a dspy.LM object.\n        complex_lm (LM): The complex language model, a dspy.LM object.\n        client_manager (ClientManager): The client manager, a way of interfacing with a Weaviate client.\n\n    Returns:\n        bool: True if the tool is available, False otherwise.\n    \"\"\"\n    return True\n</code></pre>"},{"location":"Reference/Objects/#elysia.objects.Tool.run_if_true","title":"<code>run_if_true(tree_data, base_lm, complex_lm, client_manager)</code>  <code>async</code>","text":"<p>This method is called to check if the tool should be run automatically. If this returns <code>True</code>, then the tool is immediately called at the start of the tree. Otherwise it does not appear in the decision tree. You must also return a dictionary of inputs for the tool, which will be used to call the tool if <code>True</code> is returned. If the inputs are None or an empty dictionary, then the default inputs will be used.</p> <p>This must be an async function.</p> <p>Parameters:</p> Name Type Description Default <code>tree_data</code> <code>TreeData</code> <p>The tree data object.</p> required <code>base_lm</code> <code>LM</code> <p>The base language model, a dspy.LM object.</p> required <code>complex_lm</code> <code>LM</code> <p>The complex language model, a dspy.LM object.</p> required <code>client_manager</code> <code>ClientManager</code> <p>The client manager, a way of interfacing with a Weaviate client.</p> required <p>Returns:</p> Name Type Description <code>bool</code> <code>bool</code> <p>True if the tool should be run automatically, False otherwise.</p> <code>dict</code> <code>dict</code> <p>A dictionary of inputs for the tool, with the following structure: <pre><code>{\n    input_name: input_value\n}\n</code></pre></p> Source code in <code>elysia/objects.py</code> <pre><code>async def run_if_true(\n    self,\n    tree_data,\n    base_lm,\n    complex_lm,\n    client_manager,\n) -&gt; tuple[bool, dict]:\n    \"\"\"\n    This method is called to check if the tool should be run automatically.\n    If this returns `True`, then the tool is immediately called at the start of the tree.\n    Otherwise it does not appear in the decision tree.\n    You must also return a dictionary of inputs for the tool, which will be used to call the tool if `True` is returned.\n    If the inputs are None or an empty dictionary, then the default inputs will be used.\n\n    This must be an async function.\n\n    Args:\n        tree_data (TreeData): The tree data object.\n        base_lm (LM): The base language model, a dspy.LM object.\n        complex_lm (LM): The complex language model, a dspy.LM object.\n        client_manager (ClientManager): The client manager, a way of interfacing with a Weaviate client.\n\n    Returns:\n        bool: True if the tool should be run automatically, False otherwise.\n        dict: A dictionary of inputs for the tool, with the following structure:\n            ```python\n            {\n                input_name: input_value\n            }\n            ```\n    \"\"\"\n    return False, {}\n</code></pre>"},{"location":"Reference/Objects/#elysia.objects.ToolMeta","title":"<code>ToolMeta</code>","text":"<p>               Bases: <code>type</code></p> <p>Metaclass that extracts tool metadata from init method.</p> Source code in <code>elysia/objects.py</code> <pre><code>class ToolMeta(type):\n    \"\"\"Metaclass that extracts tool metadata from __init__ method.\"\"\"\n\n    _tool_name: str | None = None\n    _tool_description: str | None = None\n    _tool_inputs: dict | None = None\n    _tool_end: bool | None = None\n\n    @staticmethod\n    def _convert_ast_dict(ast_dict: ast.Dict) -&gt; dict:\n        out = {}\n        for i in range(len(ast_dict.keys)):\n            k: ast.Constant = ast_dict.keys[i]  # type: ignore\n            v: ast.Dict | ast.List | ast.Constant = ast_dict.values[i]  # type: ignore\n\n            if isinstance(v, ast.Dict):\n                out[k.value] = ToolMeta._convert_ast_dict(v)\n            elif isinstance(v, ast.List):\n                out[k.value] = ToolMeta._convert_ast_list(v)\n            elif isinstance(v, ast.Constant):\n                out[k.value] = v.value\n        return out\n\n    @staticmethod\n    def _convert_ast_list(ast_list: ast.List) -&gt; list:\n        out = []\n        for v in ast_list.values:  # type: ignore\n            if isinstance(v, ast.Dict):\n                out.append(ToolMeta._convert_ast_dict(v))\n            elif isinstance(v, ast.List):\n                out.append(ToolMeta._convert_ast_list(v))\n            elif isinstance(v, ast.Constant):\n                out.append(v.value)\n        return out\n\n    def __new__(cls, name, bases, namespace):\n        new_class = super().__new__(cls, name, bases, namespace)\n\n        # Skip the base Tool class itself\n        if name == \"Tool\":\n            return new_class\n\n        # Extract metadata from __init__ method if it exists\n        if \"__init__\" in namespace:\n            try:\n                init_method = namespace[\"__init__\"]\n                source = inspect.getsource(init_method)\n                tree = ast.parse(source.strip())\n\n                # Find the super().__init__() call and extract arguments\n                for node in ast.walk(tree):\n                    if (\n                        isinstance(node, ast.Call)\n                        and isinstance(node.func, ast.Attribute)\n                        and node.func.attr == \"__init__\"\n                        and isinstance(node.func.value, ast.Call)\n                        and isinstance(node.func.value.func, ast.Name)\n                        and node.func.value.func.id == \"super\"\n                    ):\n\n                        # Extract keyword arguments\n                        for keyword in node.keywords:\n                            if keyword.arg == \"name\" and isinstance(\n                                keyword.value, ast.Constant\n                            ):\n                                new_class._tool_name = keyword.value.value\n                            elif keyword.arg == \"description\" and isinstance(\n                                keyword.value, ast.Constant\n                            ):\n                                new_class._tool_description = keyword.value.value\n                            elif keyword.arg == \"inputs\" and isinstance(\n                                keyword.value, ast.Dict\n                            ):\n                                new_class._tool_inputs = ToolMeta._convert_ast_dict(\n                                    keyword.value\n                                )\n                            elif keyword.arg == \"end\" and isinstance(\n                                keyword.value, ast.Constant\n                            ):\n                                new_class._tool_end = keyword.value.value\n                        break\n            except Exception:\n                # If parsing fails, just continue without setting class attributes\n                pass\n\n        return new_class\n</code></pre>"},{"location":"Reference/Objects/#elysia.objects.Update","title":"<code>Update</code>","text":"<p>               Bases: <code>Return</code></p> <p>Frontend Return Type 2: Update An update is something that is not displayed on the frontend, but gives information to the frontend. E.g. a warning, error, status message, etc.</p> Source code in <code>elysia/objects.py</code> <pre><code>class Update(Return):\n    \"\"\"\n    Frontend Return Type 2: Update\n    An update is something that is not _displayed_ on the frontend, but gives information to the frontend.\n    E.g. a warning, error, status message, etc.\n    \"\"\"\n\n    def __init__(self, frontend_type: str, object: dict):\n        Return.__init__(self, frontend_type, \"update\")\n        self.object = object\n\n    def to_json(self):\n        return self.object\n\n    async def to_frontend(self, user_id: str, conversation_id: str, query_id: str):\n        return {\n            \"type\": self.frontend_type,\n            \"user_id\": user_id,\n            \"conversation_id\": conversation_id,\n            \"query_id\": query_id,\n            \"id\": self.frontend_type[:3] + \"-\" + str(uuid.uuid4()),\n            \"payload\": self.to_json(),\n        }\n</code></pre>"},{"location":"Reference/Objects/#elysia.objects.Warning","title":"<code>Warning</code>","text":"<p>               Bases: <code>Update</code></p> <p>Warning message to be sent to the frontend.</p> Source code in <code>elysia/objects.py</code> <pre><code>class Warning(Update):\n    \"\"\"\n    Warning message to be sent to the frontend.\n    \"\"\"\n\n    def __init__(self, text: str):\n        self.text = text\n        Update.__init__(self, \"warning\", {\"text\": text})\n</code></pre>"},{"location":"Reference/Objects/#elysia.objects.tool","title":"<code>tool(function=None, *, status=None, end=False, tree=None, branch_id=None)</code>","text":"<pre><code>tool(function: Callable, *, status: str | None = None, end: bool = False, tree: Tree | None = None, branch_id: str | None = None) -&gt; Tool\n</code></pre><pre><code>tool(function: None = None, *, status: str | None = None, end: bool = False, tree: Tree | None = None, branch_id: str | None = None) -&gt; Callable[[Callable], Tool]\n</code></pre> <p>Create a tool from a python function. Use this decorator to create a tool from a function. The function must be an async function or async generator function.</p> <p>Parameters:</p> Name Type Description Default <code>function</code> <code>Callable</code> <p>The function to create a tool from.</p> <code>None</code> <code>status</code> <code>str | None</code> <p>The status message to display while the tool is running. Optional, defaults to None, which will use the default status message \"Running {tool_name}...\".</p> <code>None</code> <code>end</code> <code>bool</code> <p>Whether the tool can be at the end of the decision tree. Set to True when this tool is allowed to end the conversation. Optional, defaults to False.</p> <code>False</code> <code>tree</code> <code>Tree | None</code> <p>The tree to add the tool to. Optional, defaults to None, which will not add the tool to the tree.</p> <code>None</code> <code>branch_id</code> <code>str | None</code> <p>The branch of the tree to add the tool to. Optional, defaults to None, which will add the tool to the root branch.</p> <code>None</code> <p>Returns:</p> Type Description <code>Tool</code> <p>The tool object which can be added to the tree (via <code>tree.add_tool(...)</code>).</p> Source code in <code>elysia/objects.py</code> <pre><code>def tool(\n    function: Callable | None = None,\n    *,\n    status: str | None = None,\n    end: bool = False,\n    tree: \"Tree | None\" = None,\n    branch_id: str | None = None,\n) -&gt; Callable[[Callable], Tool] | Tool:\n    \"\"\"\n    Create a tool from a python function.\n    Use this decorator to create a tool from a function.\n    The function must be an async function or async generator function.\n\n    Args:\n        function (Callable): The function to create a tool from.\n        status (str | None): The status message to display while the tool is running.\n            Optional, defaults to None, which will use the default status message \"Running {tool_name}...\".\n        end (bool): Whether the tool can be at the end of the decision tree.\n            Set to True when this tool is allowed to end the conversation.\n            Optional, defaults to False.\n        tree (Tree | None): The tree to add the tool to.\n            Optional, defaults to None, which will not add the tool to the tree.\n        branch_id (str | None): The branch of the tree to add the tool to.\n            Optional, defaults to None, which will add the tool to the root branch.\n\n    Returns:\n        (Tool): The tool object which can be added to the tree (via `tree.add_tool(...)`).\n    \"\"\"\n\n    def decorator(function: Callable) -&gt; Tool:\n        async_function = inspect.iscoroutinefunction(function)\n        async_generator_function = inspect.isasyncgenfunction(function)\n\n        if not async_function and not async_generator_function:\n            raise TypeError(\n                \"The provided function must be an async function or async generator function.\"\n            )\n\n        if \"inputs\" in list(function.__annotations__.keys()):\n            raise TypeError(\n                \"The `inputs` argument is reserved in tool functions, please choose another name.\"\n            )\n\n        sig = inspect.signature(function)\n        defaults_mapping = {\n            k: v.default\n            for k, v in sig.parameters.items()\n            if v.default is not inspect.Parameter.empty\n        }\n\n        def list_to_list_of_dicts(result: list) -&gt; list[dict]:\n            objects = []\n            for obj in result:\n                if isinstance(obj, dict):\n                    objects.append(obj)\n                elif isinstance(obj, int | float | bool):\n                    objects.append(\n                        {\n                            \"tool_result\": obj,\n                        }\n                    )\n                elif isinstance(obj, list):\n                    objects.append(list_to_list_of_dicts(obj))\n                else:\n                    objects.append(\n                        {\n                            \"tool_result\": obj,\n                        }\n                    )\n            return objects\n\n        def return_mapping(result, inputs: dict):\n            if isinstance(result, Result | Text | Update | Status | Error):\n                return result\n            elif isinstance(result, str):\n                return Response(result)\n            elif isinstance(result, int | float | bool):\n                return Result(\n                    objects=[\n                        {\n                            \"tool_result\": result,\n                        }\n                    ],\n                    metadata={\n                        \"tool_name\": function.__name__,\n                        \"inputs_used\": inputs,\n                    },\n                )\n            elif isinstance(result, dict):\n                return Result(\n                    objects=[result],\n                    metadata={\n                        \"tool_name\": function.__name__,\n                        \"inputs_used\": inputs,\n                    },\n                )\n            elif isinstance(result, list):\n                return Result(\n                    objects=list_to_list_of_dicts(result),\n                    metadata={\n                        \"tool_name\": function.__name__,\n                        \"inputs_used\": inputs,\n                    },\n                )\n            else:\n                return Result(\n                    objects=[\n                        {\n                            \"tool_result\": result,\n                        }\n                    ],\n                    metadata={\n                        \"tool_name\": function.__name__,\n                        \"inputs_used\": inputs,\n                    },\n                )\n\n        class ToolClass(Tool):\n            def __init__(self, **kwargs):\n                super().__init__(\n                    name=function.__name__,\n                    description=function.__doc__ or \"\",\n                    status=(\n                        status\n                        if status is not None\n                        else f\"Running {function.__name__}...\"\n                    ),\n                    inputs={\n                        input_key: {\n                            \"description\": \"\",\n                            \"type\": input_value,\n                            \"default\": defaults_mapping.get(input_key, None),\n                            \"required\": defaults_mapping.get(input_key, None)\n                            is not None,\n                        }\n                        for input_key, input_value in function.__annotations__.items()\n                        if input_key\n                        not in [\n                            \"tree_data\",\n                            \"base_lm\",\n                            \"complex_lm\",\n                            \"client_manager\",\n                            \"return\",\n                        ]\n                    },\n                    end=end,\n                )\n                self._original_function = function\n\n            async def __call__(\n                self, tree_data, inputs, base_lm, complex_lm, client_manager, **kwargs\n            ):\n\n                if async_function:\n                    tool_output = [\n                        await function(\n                            **inputs,\n                            **{\n                                k: v\n                                for k, v in {\n                                    \"tree_data\": tree_data,\n                                    \"base_lm\": base_lm,\n                                    \"complex_lm\": complex_lm,\n                                    \"client_manager\": client_manager,\n                                    **kwargs,\n                                }.items()\n                                if k in function.__annotations__\n                            },\n                        )\n                    ]\n                elif async_generator_function:\n                    results = []\n                    async for result in function(\n                        **inputs,\n                        **{\n                            k: v\n                            for k, v in {\n                                \"tree_data\": tree_data,\n                                \"base_lm\": base_lm,\n                                \"complex_lm\": complex_lm,\n                                \"client_manager\": client_manager,\n                                **kwargs,\n                            }.items()\n                            if k in function.__annotations__\n                        },\n                    ):\n                        results.append(result)\n                    tool_output = results\n\n                for result in tool_output:\n                    mapped_result = return_mapping(result, inputs)\n                    yield mapped_result\n\n        tool_class = ToolClass()\n\n        if tree is not None:\n            tree.add_tool(tool_class, branch_id=branch_id)\n\n        return tool_class\n\n    if function is not None:\n        return decorator(function)\n    else:\n        return decorator\n</code></pre>"},{"location":"Reference/Objects/#elysia.tree.objects.CollectionData","title":"<code>CollectionData</code>","text":"<p>Store of data about the Weaviate collections that are used in the tree. These are the output of the <code>preprocess</code> function.</p> <p>You do not normally need to interact with this class directly. Instead, do so via the <code>TreeData</code> class, which has corresponding methods to get the data in a variety of formats. (Such as via the <code>output_full_metadata</code> method.)</p> Source code in <code>elysia/tree/objects.py</code> <pre><code>class CollectionData:\n    \"\"\"\n    Store of data about the Weaviate collections that are used in the tree.\n    These are the output of the `preprocess` function.\n\n    You do not normally need to interact with this class directly.\n    Instead, do so via the `TreeData` class, which has corresponding methods to get the data in a variety of formats.\n    (Such as via the `output_full_metadata` method.)\n    \"\"\"\n\n    def __init__(\n        self,\n        collection_names: list[str],\n        metadata: dict[str, Any] = {},\n        logger: Logger | None = None,\n    ):\n        self.collection_names = collection_names\n        self.metadata = metadata\n        self.logger = logger\n\n    async def set_collection_names(\n        self, collection_names: list[str], client_manager: ClientManager\n    ):\n        temp_metadata = {}\n\n        # check if any of these collections exist in the full metadata (cached)\n        collections_to_get = []\n        for collection_name in collection_names:\n            if collection_name not in self.metadata:\n                collections_to_get.append(collection_name)\n\n        self.removed_collections = []\n        self.incorrect_collections = []\n\n        metadata_name = \"ELYSIA_METADATA__\"\n\n        async with client_manager.connect_to_async_client() as client:\n            # check if the metadata collection exists\n            if not await client.collections.exists(metadata_name):\n                self.removed_collections.extend(collections_to_get)\n            else:\n                metadata_collection = client.collections.get(metadata_name)\n                filters = (\n                    Filter.any_of(\n                        [\n                            Filter.by_property(\"name\").equal(collection_name)\n                            for collection_name in collections_to_get\n                        ]\n                    )\n                    if len(collections_to_get) &gt;= 1\n                    else None\n                )\n                metadata = await metadata_collection.query.fetch_objects(\n                    filters=filters,\n                    limit=9999,\n                )\n                metadata_map = {\n                    metadata_obj.properties[\"name\"]: metadata_obj.properties\n                    for metadata_obj in metadata.objects\n                }\n\n                for collection_name in collections_to_get:\n\n                    if not await client.collections.exists(collection_name):\n                        self.incorrect_collections.append(collection_name)\n                        continue\n\n                    if collection_name not in metadata_map:\n                        self.removed_collections.append(collection_name)\n                    else:\n                        properties = metadata_map[collection_name]\n                        format_dict_to_serialisable(properties)  # type: ignore\n                        temp_metadata[collection_name] = properties\n\n        if len(self.removed_collections) &gt; 0 and self.logger:\n            self.logger.warning(\n                \"The following collections have not been pre-processed for Elysia. \"\n                f\"{self.removed_collections}. \"\n                \"Ignoring these collections for now.\"\n            )\n\n        if len(self.incorrect_collections) &gt; 0 and self.logger:\n            self.logger.warning(\n                \"The following collections cannot be found in this Weaviate cluster. \"\n                f\"{self.incorrect_collections}. \"\n                \"These are being ignored for now. Please check that the collection names are correct.\"\n            )\n\n        self.collection_names = [\n            collection_name\n            for collection_name in collection_names\n            if collection_name not in self.removed_collections\n            and collection_name not in self.incorrect_collections\n        ]\n\n        # add to cached full metadata\n        self.metadata = {\n            **self.metadata,\n            **{\n                collection_name: temp_metadata[collection_name]\n                for collection_name in temp_metadata\n                if collection_name not in self.metadata\n            },\n        }\n\n        return self.collection_names\n\n    def output_full_metadata(\n        self, collection_names: list[str] | None = None, with_mappings: bool = False\n    ):\n        if collection_names is None:\n            collection_names = self.collection_names\n\n        if with_mappings:\n            return {\n                collection_name: self.metadata[collection_name]\n                for collection_name in collection_names\n            }\n        else:\n            return {\n                collection_name: {\n                    k: v\n                    for k, v in self.metadata[collection_name].items()\n                    if k != \"mappings\"\n                }\n                for collection_name in collection_names\n            }\n\n    def output_collection_summaries(self, collection_names: list[str] | None = None):\n        if collection_names is None:\n            return {\n                collection_name: self.metadata[collection_name][\"summary\"]\n                for collection_name in self.collection_names\n            }\n        else:\n            return {\n                collection_name: self.metadata[collection_name][\"summary\"]\n                for collection_name in collection_names\n            }\n\n    def output_mapping_lists(self):\n        return {\n            collection_name: list(self.metadata[collection_name][\"mappings\"].keys())\n            for collection_name in self.collection_names\n        }\n\n    def output_mappings(self):\n        return {\n            collection_name: self.metadata[collection_name][\"mappings\"]\n            for collection_name in self.collection_names\n        }\n\n    def to_json(self):\n        return {\n            \"collection_names\": self.collection_names,\n            \"metadata\": self.metadata,\n        }\n\n    @classmethod\n    def from_json(cls, json_data: dict, logger: Logger | None = None):\n        return cls(\n            collection_names=json_data[\"collection_names\"],\n            metadata=json_data[\"metadata\"],\n            logger=logger,\n        )\n</code></pre>"},{"location":"Reference/Objects/#elysia.tree.objects.Environment","title":"<code>Environment</code>","text":"<p>Store of all objects across different types of queries and responses.</p> <p>The environment is how the tree stores all objects across different types of queries and responses. This includes things like retrieved objects, retrieved metadata, retrieved summaries, etc.</p> <p>This is persistent across the tree, so that all agents are aware of the same objects.</p> <p>The environment is formatted and keyed as follows: <pre><code>{\n    \"tool_name\": {\n        \"result_name\": [\n            {\n                \"metadata\": dict,\n                \"objects\": list[dict],\n            },\n            ...\n        ]\n    }\n}\n</code></pre></p> <p>Where <code>\"tool_name\"</code> is the name of the function that the result belongs to, e.g. if the result came from a tool called <code>\"query\"</code>, then <code>\"tool_name\"</code> is <code>\"query\"</code>.</p> <p><code>\"result_name\"</code> is the name of the Result object, which can be customised, e.g. if the result comes from a specific collection, then <code>\"result_name\"</code> is the name of the collection.</p> <p><code>\"metadata\"</code> is the metadata of the result, e.g. the time taken to retrieve the result, the query used, etc.</p> <p><code>\"objects\"</code> is the list of objects retrieved from the result. This is a list of dictionaries, where each dictionary is an object. It is important that <code>objects</code> should have be list of dictionaries. e.g. each object that was returned from a retrieval, where the fields of each dictionary are the fields of the object returned.</p> <p>Each list under <code>result_name</code> is a dictionary with both <code>metadata</code> and <code>objects</code> keys. This is if, for example, you retrieve multiple objects from the same collection, each one is stored with different metadata. Because, for example, the query used to retrieve each object may be different (and stored differently in the metadata).</p> <p>The environment is initialised with a default \"SelfInfo.generic\" key, which is a list of one object, containing information about Elysia itself.</p> <p>You can use various methods to add, remove, replace, and find objects in the environment. See the methods below for more information.</p> <p>Within the environment, there is a variable called <code>hidden_environment</code>, which is a dictionary of key-value pairs. This is used to store information that is not shown to the LLM, but is instead a 'store' of data that can be used across tools.</p> Source code in <code>elysia/tree/objects.py</code> <pre><code>class Environment:\n    \"\"\"\n    Store of all objects across different types of queries and responses.\n\n    The environment is how the tree stores all objects across different types of queries and responses.\n    This includes things like retrieved objects, retrieved metadata, retrieved summaries, etc.\n\n    This is persistent across the tree, so that all agents are aware of the same objects.\n\n    The environment is formatted and keyed as follows:\n    ```python\n    {\n        \"tool_name\": {\n            \"result_name\": [\n                {\n                    \"metadata\": dict,\n                    \"objects\": list[dict],\n                },\n                ...\n            ]\n        }\n    }\n    ```\n\n    Where `\"tool_name\"` is the name of the function that the result belongs to,\n    e.g. if the result came from a tool called `\"query\"`, then `\"tool_name\"` is `\"query\"`.\n\n    `\"result_name\"` is the name of the Result object, which can be customised,\n    e.g. if the result comes from a specific collection, then `\"result_name\"` is the name of the collection.\n\n    `\"metadata\"` is the metadata of the result,\n    e.g. the time taken to retrieve the result, the query used, etc.\n\n    `\"objects\"` is the list of objects retrieved from the result. This is a list of dictionaries, where each dictionary is an object.\n    It is important that `objects` should have be list of dictionaries.\n    e.g. each object that was returned from a retrieval, where the fields of each dictionary are the fields of the object returned.\n\n    Each list under `result_name` is a dictionary with both `metadata` and `objects` keys.\n    This is if, for example, you retrieve multiple objects from the same collection, each one is stored with different metadata.\n    Because, for example, the query used to retrieve each object may be different (and stored differently in the metadata).\n\n    The environment is initialised with a default \"SelfInfo.generic\" key, which is a list of one object, containing information about Elysia itself.\n\n    You can use various methods to add, remove, replace, and find objects in the environment. See the methods below for more information.\n\n    Within the environment, there is a variable called `hidden_environment`, which is a dictionary of key-value pairs.\n    This is used to store information that is not shown to the LLM, but is instead a 'store' of data that can be used across tools.\n    \"\"\"\n\n    def __init__(\n        self,\n        environment: dict[str, dict[str, Any]] | None = None,\n        self_info: bool = True,\n        hidden_environment: dict[str, Any] = {},\n    ):\n        if environment is None:\n            environment = {}\n        self.environment = environment\n        self.hidden_environment = hidden_environment\n        self.self_info = self_info\n        if self_info:\n            self.environment[\"SelfInfo\"] = {}\n            self.environment[\"SelfInfo\"][\"info\"] = [\n                {\n                    \"name\": \"Elysia\",\n                    \"description\": \"An agentic RAG service in Weaviate.\",\n                    \"purpose\": remove_whitespace(\n                        \"\"\"Elysia is an agentic retrieval augmented generation (RAG) service, where users can query from Weaviate collections,\n                    and the assistant will retrieve the most relevant information and answer the user's question. This includes a variety\n                    of different ways to query, such as by filtering, sorting, querying multiple collections, and providing summaries\n                    and textual responses.\n\n                    Elysia will dynamically display retrieved objects from the collections in the frontend.\n                    Elysia works via a tree-based approach, where the user's question is used to generate a tree of potential\n                    queries to retrieve the most relevant information.\n                    Each end of the tree connects to a separate agent that will perform a specific task, such as retrieval, aggregation, or generation, or more.\n\n                    The tree itself has decision nodes that determine the next step in the query.\n                    The decision nodes are decided via a decision-agent, which decides the task.\n\n                    The agents communicate via a series of different prompts, which are stored in the prompt-library.\n                    The decision-agent prompts are designed to be as general as possible, so that they can be used for a variety of different tasks.\n                    Some of these variables include conversation history, retrieved objects, the user's original question, train of thought via model reasoning, and more.\n\n                    The backend of Elysia is built with a range of libraries. Elysia is built with a lot of base python, and was constructed from the ground up to keep it as modular as possible.\n                    The LLM components are built with DSPy, a library for training and running LLMs.\n                    \"\"\"\n                    ),\n                }\n            ]\n\n    def is_empty(self):\n        \"\"\"\n        Check if the environment is empty.\n\n        The \"SelfInfo\" key is not counted towards the empty environment.\n\n        If the `.remove` method has been used, this is accounted for (e.g. empty lists count towards an empty environment).\n        \"\"\"\n        empty = True\n        for tool_key in self.environment.keys():\n            if tool_key == \"SelfInfo\":\n                continue\n\n            for result_key in self.environment[tool_key].keys():\n                if len(self.environment[tool_key][result_key]) &gt; 0:\n                    empty = False\n                    break\n        return empty\n\n    def add(self, tool_name: str, result: Result, include_duplicates: bool = False):\n        \"\"\"\n        Adds a result to the environment.\n        Is called automatically by the tree when a result is returned from an agent.\n\n        You can also add a result to the environment manually by using this method.\n        In this case, you must be adding a 'Result' object (which has an implicit 'name' attribute used to key the environment).\n        If you want to add something manually, you can use the `add_objects` method.\n\n        Each item is added with a `_REF_ID` attribute, which is a unique identifier used to identify the object in the environment.\n        If duplicate objects are detected, they are added with a duplicate `_REF_ID` entry detailing that they are a duplicate,\n        as well as the `_REF_ID` of the original object.\n\n        Args:\n            tool_name (str): The name of the tool called that the result belongs to.\n            result (Result): The result to add to the environment.\n            include_duplicates (bool): Optional. Whether to include duplicate objects in the environment.\n                Defaults to `False`, which still adds the duplicate object, but with a duplicate `_REF_ID` entry (and no repeating properties).\n                If `True`, the duplicate object is added with a new `_REF_ID` entry, and the repeated properties are added to the object.\n        \"\"\"\n        objects = result.to_json()\n        name = result.name\n        metadata = result.metadata\n        if tool_name not in self.environment:\n            self.environment[tool_name] = {}\n\n        self.add_objects(tool_name, name, objects, metadata, include_duplicates)\n\n    def add_objects(\n        self,\n        tool_name: str,\n        name: str,\n        objects: list[dict],\n        metadata: dict = {},\n        include_duplicates: bool = False,\n    ):\n        \"\"\"\n        Adds an object to the environment.\n        Is not called automatically by the tree, so you must manually call this method.\n        This is useful if you want to add an object to the environment manually that doesn't come from a Result object.\n\n        Each item is added with a `_REF_ID` attribute, which is a unique identifier used to identify the object in the environment.\n        If duplicate objects are detected, they are added with a duplicate `_REF_ID` entry detailing that they are a duplicate,\n        as well as the `_REF_ID` of the original object.\n\n        Args:\n            tool_name (str): The name of the tool called that the result belongs to.\n            name (str): The name of the result.\n            objects (list[dict]): The objects to add to the environment.\n            metadata (dict): Optional. The metadata of the objects to add to the environment.\n                Defaults to an empty dictionary.\n            include_duplicates (bool): Optional. Whether to include duplicate objects in the environment.\n                Defaults to `False`, which still adds the duplicate object, but with a duplicate `_REF_ID` entry (and no repeating properties).\n                If `True`, the duplicate object is added with a new `_REF_ID` entry, and the repeated properties are added to the object.\n\n        \"\"\"\n        if tool_name not in self.environment:\n            self.environment[tool_name] = {}\n\n        if name not in self.environment[tool_name]:\n            self.environment[tool_name][name] = []\n\n        if len(objects) &gt; 0:\n            self.environment[tool_name][name].append(\n                {\n                    \"metadata\": metadata,\n                    \"objects\": [],\n                }\n            )\n\n            for i, obj in enumerate(objects):\n                # check if the object is already in the environment\n                obj_found = False\n                where_obj = None\n                for env_item in self.environment[tool_name][name]:\n                    if obj in env_item[\"objects\"]:\n                        obj_found = True\n                        where_obj = env_item[\"objects\"].index(obj)\n                        _REF_ID = env_item[\"objects\"][where_obj][\"_REF_ID\"]\n                        break\n\n                if obj_found and not include_duplicates:\n                    self.environment[tool_name][name][-1][\"objects\"].append(\n                        {\n                            \"object_info\": f\"[repeat]\",\n                            \"_REF_ID\": _REF_ID,\n                        }\n                    )\n                elif \"_REF_ID\" not in obj:\n                    _REF_ID = f\"{tool_name}_{name}_{len(self.environment[tool_name][name])}_{i}\"\n                    self.environment[tool_name][name][-1][\"objects\"].append(\n                        {\n                            \"_REF_ID\": _REF_ID,\n                            **obj,\n                        }\n                    )\n                else:\n                    self.environment[tool_name][name][-1][\"objects\"].append(obj)\n\n    def remove(self, tool_name: str, name: str, index: int | None = None):\n        \"\"\"\n        Replaces the list of objects for the given `tool_name` and `name` with an empty list.\n\n        Args:\n            tool_name (str): The name of the tool called that the result belongs to.\n            name (str): The name of the result.\n            index (int | None): The index of the object to remove.\n                If `None`, the entire list corresponding to `tool_name`/`name` is deleted.\n                If an integer, the object at the given index is removed.\n                Defaults to `None`.\n                If `index=-1`, the last object is removed.\n        \"\"\"\n        if tool_name in self.environment:\n            if name in self.environment[tool_name]:\n                if index is None:\n                    self.environment[tool_name][name] = []\n                else:\n                    self.environment[tool_name][name].pop(index)\n\n    def replace(\n        self,\n        tool_name: str,\n        name: str,\n        objects: list[dict],\n        metadata: dict = {},\n        index: int | None = None,\n    ):\n        \"\"\"\n        Replaces the list of objects for the given `tool_name` and `name` with the given list of objects.\n\n        Args:\n            tool_name (str): The name of the tool called that the result belongs to.\n            name (str): The name of the result.\n            objects (list[dict]): The objects to replace the existing objects with.\n            metadata (dict): The metadata of the objects to replace the existing objects with.\n            index (int | None): The index of the object to replace.\n                If `None`, the entire list corresponding to `tool_name`/`name` is deleted and replaced with the new objects.\n                If an integer, the object at the given index is replaced with the new objects.\n                Defaults to `None`.\n        \"\"\"\n        if tool_name in self.environment:\n            if name in self.environment[tool_name]:\n                if index is None:\n                    self.environment[tool_name][name] = [\n                        {\n                            \"metadata\": metadata,\n                            \"objects\": objects,\n                        }\n                    ]\n                else:\n                    self.environment[tool_name][name][index] = {\n                        \"metadata\": metadata,\n                        \"objects\": objects,\n                    }\n\n    def find(self, tool_name: str, name: str, index: int | None = None):\n        \"\"\"\n        Finds a corresponding list of objects in the environment.\n        Keyed via `tool_name` and `name`. See the base class description for more information on how the environment is keyed.\n\n        Args:\n            tool_name (str): The name of the tool called that the result belongs to.\n            name (str): The name of the result.\n            index (int | None): The index of the object to find.\n                If `None`, the entire list corresponding to `tool_name`/`name` is returned.\n                If an integer, the object at the given index is returned.\n\n        Returns:\n            (list[dict]): if `index` is `None` - The list of objects for the given `tool_name` and `name`.\n            (dict): if `index` is an integer - The object at the given `index` for the given `tool_name` and `name`.\n            (None): If the `tool_name` or `name` is not found in the environment.\n        \"\"\"\n\n        if tool_name not in self.environment:\n            return None\n        if name not in self.environment[tool_name]:\n            return None\n\n        if index is None:\n            return self.environment[tool_name][name]\n        else:\n            return self.environment[tool_name][name][index]\n\n    def to_json(self, remove_unserialisable: bool = False):\n        \"\"\"\n        Converts the environment to a JSON serialisable format.\n        Used to access specific objects from the environment.\n        \"\"\"\n\n        env_copy = deepcopy(self.environment)\n        hidden_env_copy = deepcopy(self.hidden_environment)\n\n        # Check if environment and hidden_environment are JSON serialisable\n        for tool_name in env_copy:\n            if tool_name != \"SelfInfo\":\n                for name in self.environment[tool_name]:\n                    for obj_metadata in self.environment[tool_name][name]:\n                        format_dict_to_serialisable(\n                            obj_metadata[\"metadata\"], remove_unserialisable\n                        )\n                        for obj in obj_metadata[\"objects\"]:\n                            format_dict_to_serialisable(obj, remove_unserialisable)\n\n        format_dict_to_serialisable(hidden_env_copy, remove_unserialisable)\n\n        return {\n            \"environment\": env_copy,\n            \"hidden_environment\": hidden_env_copy,\n            \"self_info\": self.self_info,\n        }\n\n    @classmethod\n    def from_json(cls, json_data: dict):\n        return cls(\n            environment=json_data[\"environment\"],\n            hidden_environment=json_data[\"hidden_environment\"],\n            self_info=json_data[\"self_info\"],\n        )\n</code></pre>"},{"location":"Reference/Objects/#elysia.tree.objects.Environment.add","title":"<code>add(tool_name, result, include_duplicates=False)</code>","text":"<p>Adds a result to the environment. Is called automatically by the tree when a result is returned from an agent.</p> <p>You can also add a result to the environment manually by using this method. In this case, you must be adding a 'Result' object (which has an implicit 'name' attribute used to key the environment). If you want to add something manually, you can use the <code>add_objects</code> method.</p> <p>Each item is added with a <code>_REF_ID</code> attribute, which is a unique identifier used to identify the object in the environment. If duplicate objects are detected, they are added with a duplicate <code>_REF_ID</code> entry detailing that they are a duplicate, as well as the <code>_REF_ID</code> of the original object.</p> <p>Parameters:</p> Name Type Description Default <code>tool_name</code> <code>str</code> <p>The name of the tool called that the result belongs to.</p> required <code>result</code> <code>Result</code> <p>The result to add to the environment.</p> required <code>include_duplicates</code> <code>bool</code> <p>Optional. Whether to include duplicate objects in the environment. Defaults to <code>False</code>, which still adds the duplicate object, but with a duplicate <code>_REF_ID</code> entry (and no repeating properties). If <code>True</code>, the duplicate object is added with a new <code>_REF_ID</code> entry, and the repeated properties are added to the object.</p> <code>False</code> Source code in <code>elysia/tree/objects.py</code> <pre><code>def add(self, tool_name: str, result: Result, include_duplicates: bool = False):\n    \"\"\"\n    Adds a result to the environment.\n    Is called automatically by the tree when a result is returned from an agent.\n\n    You can also add a result to the environment manually by using this method.\n    In this case, you must be adding a 'Result' object (which has an implicit 'name' attribute used to key the environment).\n    If you want to add something manually, you can use the `add_objects` method.\n\n    Each item is added with a `_REF_ID` attribute, which is a unique identifier used to identify the object in the environment.\n    If duplicate objects are detected, they are added with a duplicate `_REF_ID` entry detailing that they are a duplicate,\n    as well as the `_REF_ID` of the original object.\n\n    Args:\n        tool_name (str): The name of the tool called that the result belongs to.\n        result (Result): The result to add to the environment.\n        include_duplicates (bool): Optional. Whether to include duplicate objects in the environment.\n            Defaults to `False`, which still adds the duplicate object, but with a duplicate `_REF_ID` entry (and no repeating properties).\n            If `True`, the duplicate object is added with a new `_REF_ID` entry, and the repeated properties are added to the object.\n    \"\"\"\n    objects = result.to_json()\n    name = result.name\n    metadata = result.metadata\n    if tool_name not in self.environment:\n        self.environment[tool_name] = {}\n\n    self.add_objects(tool_name, name, objects, metadata, include_duplicates)\n</code></pre>"},{"location":"Reference/Objects/#elysia.tree.objects.Environment.add_objects","title":"<code>add_objects(tool_name, name, objects, metadata={}, include_duplicates=False)</code>","text":"<p>Adds an object to the environment. Is not called automatically by the tree, so you must manually call this method. This is useful if you want to add an object to the environment manually that doesn't come from a Result object.</p> <p>Each item is added with a <code>_REF_ID</code> attribute, which is a unique identifier used to identify the object in the environment. If duplicate objects are detected, they are added with a duplicate <code>_REF_ID</code> entry detailing that they are a duplicate, as well as the <code>_REF_ID</code> of the original object.</p> <p>Parameters:</p> Name Type Description Default <code>tool_name</code> <code>str</code> <p>The name of the tool called that the result belongs to.</p> required <code>name</code> <code>str</code> <p>The name of the result.</p> required <code>objects</code> <code>list[dict]</code> <p>The objects to add to the environment.</p> required <code>metadata</code> <code>dict</code> <p>Optional. The metadata of the objects to add to the environment. Defaults to an empty dictionary.</p> <code>{}</code> <code>include_duplicates</code> <code>bool</code> <p>Optional. Whether to include duplicate objects in the environment. Defaults to <code>False</code>, which still adds the duplicate object, but with a duplicate <code>_REF_ID</code> entry (and no repeating properties). If <code>True</code>, the duplicate object is added with a new <code>_REF_ID</code> entry, and the repeated properties are added to the object.</p> <code>False</code> Source code in <code>elysia/tree/objects.py</code> <pre><code>def add_objects(\n    self,\n    tool_name: str,\n    name: str,\n    objects: list[dict],\n    metadata: dict = {},\n    include_duplicates: bool = False,\n):\n    \"\"\"\n    Adds an object to the environment.\n    Is not called automatically by the tree, so you must manually call this method.\n    This is useful if you want to add an object to the environment manually that doesn't come from a Result object.\n\n    Each item is added with a `_REF_ID` attribute, which is a unique identifier used to identify the object in the environment.\n    If duplicate objects are detected, they are added with a duplicate `_REF_ID` entry detailing that they are a duplicate,\n    as well as the `_REF_ID` of the original object.\n\n    Args:\n        tool_name (str): The name of the tool called that the result belongs to.\n        name (str): The name of the result.\n        objects (list[dict]): The objects to add to the environment.\n        metadata (dict): Optional. The metadata of the objects to add to the environment.\n            Defaults to an empty dictionary.\n        include_duplicates (bool): Optional. Whether to include duplicate objects in the environment.\n            Defaults to `False`, which still adds the duplicate object, but with a duplicate `_REF_ID` entry (and no repeating properties).\n            If `True`, the duplicate object is added with a new `_REF_ID` entry, and the repeated properties are added to the object.\n\n    \"\"\"\n    if tool_name not in self.environment:\n        self.environment[tool_name] = {}\n\n    if name not in self.environment[tool_name]:\n        self.environment[tool_name][name] = []\n\n    if len(objects) &gt; 0:\n        self.environment[tool_name][name].append(\n            {\n                \"metadata\": metadata,\n                \"objects\": [],\n            }\n        )\n\n        for i, obj in enumerate(objects):\n            # check if the object is already in the environment\n            obj_found = False\n            where_obj = None\n            for env_item in self.environment[tool_name][name]:\n                if obj in env_item[\"objects\"]:\n                    obj_found = True\n                    where_obj = env_item[\"objects\"].index(obj)\n                    _REF_ID = env_item[\"objects\"][where_obj][\"_REF_ID\"]\n                    break\n\n            if obj_found and not include_duplicates:\n                self.environment[tool_name][name][-1][\"objects\"].append(\n                    {\n                        \"object_info\": f\"[repeat]\",\n                        \"_REF_ID\": _REF_ID,\n                    }\n                )\n            elif \"_REF_ID\" not in obj:\n                _REF_ID = f\"{tool_name}_{name}_{len(self.environment[tool_name][name])}_{i}\"\n                self.environment[tool_name][name][-1][\"objects\"].append(\n                    {\n                        \"_REF_ID\": _REF_ID,\n                        **obj,\n                    }\n                )\n            else:\n                self.environment[tool_name][name][-1][\"objects\"].append(obj)\n</code></pre>"},{"location":"Reference/Objects/#elysia.tree.objects.Environment.find","title":"<code>find(tool_name, name, index=None)</code>","text":"<p>Finds a corresponding list of objects in the environment. Keyed via <code>tool_name</code> and <code>name</code>. See the base class description for more information on how the environment is keyed.</p> <p>Parameters:</p> Name Type Description Default <code>tool_name</code> <code>str</code> <p>The name of the tool called that the result belongs to.</p> required <code>name</code> <code>str</code> <p>The name of the result.</p> required <code>index</code> <code>int | None</code> <p>The index of the object to find. If <code>None</code>, the entire list corresponding to <code>tool_name</code>/<code>name</code> is returned. If an integer, the object at the given index is returned.</p> <code>None</code> <p>Returns:</p> Type Description <code>list[dict]</code> <p>if <code>index</code> is <code>None</code> - The list of objects for the given <code>tool_name</code> and <code>name</code>.</p> <code>dict</code> <p>if <code>index</code> is an integer - The object at the given <code>index</code> for the given <code>tool_name</code> and <code>name</code>.</p> <code>None</code> <p>If the <code>tool_name</code> or <code>name</code> is not found in the environment.</p> Source code in <code>elysia/tree/objects.py</code> <pre><code>def find(self, tool_name: str, name: str, index: int | None = None):\n    \"\"\"\n    Finds a corresponding list of objects in the environment.\n    Keyed via `tool_name` and `name`. See the base class description for more information on how the environment is keyed.\n\n    Args:\n        tool_name (str): The name of the tool called that the result belongs to.\n        name (str): The name of the result.\n        index (int | None): The index of the object to find.\n            If `None`, the entire list corresponding to `tool_name`/`name` is returned.\n            If an integer, the object at the given index is returned.\n\n    Returns:\n        (list[dict]): if `index` is `None` - The list of objects for the given `tool_name` and `name`.\n        (dict): if `index` is an integer - The object at the given `index` for the given `tool_name` and `name`.\n        (None): If the `tool_name` or `name` is not found in the environment.\n    \"\"\"\n\n    if tool_name not in self.environment:\n        return None\n    if name not in self.environment[tool_name]:\n        return None\n\n    if index is None:\n        return self.environment[tool_name][name]\n    else:\n        return self.environment[tool_name][name][index]\n</code></pre>"},{"location":"Reference/Objects/#elysia.tree.objects.Environment.is_empty","title":"<code>is_empty()</code>","text":"<p>Check if the environment is empty.</p> <p>The \"SelfInfo\" key is not counted towards the empty environment.</p> <p>If the <code>.remove</code> method has been used, this is accounted for (e.g. empty lists count towards an empty environment).</p> Source code in <code>elysia/tree/objects.py</code> <pre><code>def is_empty(self):\n    \"\"\"\n    Check if the environment is empty.\n\n    The \"SelfInfo\" key is not counted towards the empty environment.\n\n    If the `.remove` method has been used, this is accounted for (e.g. empty lists count towards an empty environment).\n    \"\"\"\n    empty = True\n    for tool_key in self.environment.keys():\n        if tool_key == \"SelfInfo\":\n            continue\n\n        for result_key in self.environment[tool_key].keys():\n            if len(self.environment[tool_key][result_key]) &gt; 0:\n                empty = False\n                break\n    return empty\n</code></pre>"},{"location":"Reference/Objects/#elysia.tree.objects.Environment.remove","title":"<code>remove(tool_name, name, index=None)</code>","text":"<p>Replaces the list of objects for the given <code>tool_name</code> and <code>name</code> with an empty list.</p> <p>Parameters:</p> Name Type Description Default <code>tool_name</code> <code>str</code> <p>The name of the tool called that the result belongs to.</p> required <code>name</code> <code>str</code> <p>The name of the result.</p> required <code>index</code> <code>int | None</code> <p>The index of the object to remove. If <code>None</code>, the entire list corresponding to <code>tool_name</code>/<code>name</code> is deleted. If an integer, the object at the given index is removed. Defaults to <code>None</code>. If <code>index=-1</code>, the last object is removed.</p> <code>None</code> Source code in <code>elysia/tree/objects.py</code> <pre><code>def remove(self, tool_name: str, name: str, index: int | None = None):\n    \"\"\"\n    Replaces the list of objects for the given `tool_name` and `name` with an empty list.\n\n    Args:\n        tool_name (str): The name of the tool called that the result belongs to.\n        name (str): The name of the result.\n        index (int | None): The index of the object to remove.\n            If `None`, the entire list corresponding to `tool_name`/`name` is deleted.\n            If an integer, the object at the given index is removed.\n            Defaults to `None`.\n            If `index=-1`, the last object is removed.\n    \"\"\"\n    if tool_name in self.environment:\n        if name in self.environment[tool_name]:\n            if index is None:\n                self.environment[tool_name][name] = []\n            else:\n                self.environment[tool_name][name].pop(index)\n</code></pre>"},{"location":"Reference/Objects/#elysia.tree.objects.Environment.replace","title":"<code>replace(tool_name, name, objects, metadata={}, index=None)</code>","text":"<p>Replaces the list of objects for the given <code>tool_name</code> and <code>name</code> with the given list of objects.</p> <p>Parameters:</p> Name Type Description Default <code>tool_name</code> <code>str</code> <p>The name of the tool called that the result belongs to.</p> required <code>name</code> <code>str</code> <p>The name of the result.</p> required <code>objects</code> <code>list[dict]</code> <p>The objects to replace the existing objects with.</p> required <code>metadata</code> <code>dict</code> <p>The metadata of the objects to replace the existing objects with.</p> <code>{}</code> <code>index</code> <code>int | None</code> <p>The index of the object to replace. If <code>None</code>, the entire list corresponding to <code>tool_name</code>/<code>name</code> is deleted and replaced with the new objects. If an integer, the object at the given index is replaced with the new objects. Defaults to <code>None</code>.</p> <code>None</code> Source code in <code>elysia/tree/objects.py</code> <pre><code>def replace(\n    self,\n    tool_name: str,\n    name: str,\n    objects: list[dict],\n    metadata: dict = {},\n    index: int | None = None,\n):\n    \"\"\"\n    Replaces the list of objects for the given `tool_name` and `name` with the given list of objects.\n\n    Args:\n        tool_name (str): The name of the tool called that the result belongs to.\n        name (str): The name of the result.\n        objects (list[dict]): The objects to replace the existing objects with.\n        metadata (dict): The metadata of the objects to replace the existing objects with.\n        index (int | None): The index of the object to replace.\n            If `None`, the entire list corresponding to `tool_name`/`name` is deleted and replaced with the new objects.\n            If an integer, the object at the given index is replaced with the new objects.\n            Defaults to `None`.\n    \"\"\"\n    if tool_name in self.environment:\n        if name in self.environment[tool_name]:\n            if index is None:\n                self.environment[tool_name][name] = [\n                    {\n                        \"metadata\": metadata,\n                        \"objects\": objects,\n                    }\n                ]\n            else:\n                self.environment[tool_name][name][index] = {\n                    \"metadata\": metadata,\n                    \"objects\": objects,\n                }\n</code></pre>"},{"location":"Reference/Objects/#elysia.tree.objects.Environment.to_json","title":"<code>to_json(remove_unserialisable=False)</code>","text":"<p>Converts the environment to a JSON serialisable format. Used to access specific objects from the environment.</p> Source code in <code>elysia/tree/objects.py</code> <pre><code>def to_json(self, remove_unserialisable: bool = False):\n    \"\"\"\n    Converts the environment to a JSON serialisable format.\n    Used to access specific objects from the environment.\n    \"\"\"\n\n    env_copy = deepcopy(self.environment)\n    hidden_env_copy = deepcopy(self.hidden_environment)\n\n    # Check if environment and hidden_environment are JSON serialisable\n    for tool_name in env_copy:\n        if tool_name != \"SelfInfo\":\n            for name in self.environment[tool_name]:\n                for obj_metadata in self.environment[tool_name][name]:\n                    format_dict_to_serialisable(\n                        obj_metadata[\"metadata\"], remove_unserialisable\n                    )\n                    for obj in obj_metadata[\"objects\"]:\n                        format_dict_to_serialisable(obj, remove_unserialisable)\n\n    format_dict_to_serialisable(hidden_env_copy, remove_unserialisable)\n\n    return {\n        \"environment\": env_copy,\n        \"hidden_environment\": hidden_env_copy,\n        \"self_info\": self.self_info,\n    }\n</code></pre>"},{"location":"Reference/Objects/#elysia.tree.objects.TreeData","title":"<code>TreeData</code>","text":"<p>Store of data across the tree. This includes things like conversation history, actions, decisions, etc. These data are given to ALL agents, so every agent is aware of the stage of the decision processes.</p> <p>This also contains functions that process the data into an LLM friendly format, such as a string with extra description. E.g. the number of trees completed is converted into a string (i/N)      and additional warnings if i is close to N.</p> <p>The TreeData has the following objects:</p> <ul> <li>collection_data (CollectionData): The collection metadata/schema, which contains information about the collections used in the tree.     This is the store of data that is saved by the <code>preprocess</code> function, and retrieved on initialisation of this object.</li> <li>atlas (Atlas): The atlas, described in the Atlas class.</li> <li>user_prompt (str): The user's prompt.</li> <li>conversation_history (list[dict]): The conversation history stored in the current tree, of the form:     <pre><code>[\n    {\n        \"role\": \"user\" | \"assistant\",\n        \"content\": str,\n    },\n    ...\n]\n</code></pre></li> <li>environment (Environment): The environment, described in the Environment class.</li> <li>tasks_completed (list[dict]): The tasks completed as a list of dictionaries.     This is separate from the environment, as it separates what tasks were completed in each prompt in which order.</li> <li>num_trees_completed (int): The current level of the decision tree, how many iterations have been completed so far.</li> <li>recursion_limit (int): The maximum number of iterations allowed in the decision tree.</li> <li>errors (dict): A dictionary of self-healing errors that have occurred in the tree. Keyed by the function name that caused the error.</li> </ul> <p>In general, you should not initialise this class directly. But you can access the data in this class to access the relevant data from the tree (in e.g. tool construction/usage).</p> Source code in <code>elysia/tree/objects.py</code> <pre><code>class TreeData:\n    \"\"\"\n    Store of data across the tree.\n    This includes things like conversation history, actions, decisions, etc.\n    These data are given to ALL agents, so every agent is aware of the stage of the decision processes.\n\n    This also contains functions that process the data into an LLM friendly format,\n    such as a string with extra description.\n    E.g. the number of trees completed is converted into a string (i/N)\n         and additional warnings if i is close to N.\n\n    The TreeData has the following objects:\n\n    - collection_data (CollectionData): The collection metadata/schema, which contains information about the collections used in the tree.\n        This is the store of data that is saved by the `preprocess` function, and retrieved on initialisation of this object.\n    - atlas (Atlas): The atlas, described in the Atlas class.\n    - user_prompt (str): The user's prompt.\n    - conversation_history (list[dict]): The conversation history stored in the current tree, of the form:\n        ```python\n        [\n            {\n                \"role\": \"user\" | \"assistant\",\n                \"content\": str,\n            },\n            ...\n        ]\n        ```\n    - environment (Environment): The environment, described in the Environment class.\n    - tasks_completed (list[dict]): The tasks completed as a list of dictionaries.\n        This is separate from the environment, as it separates what tasks were completed in each prompt in which order.\n    - num_trees_completed (int): The current level of the decision tree, how many iterations have been completed so far.\n    - recursion_limit (int): The maximum number of iterations allowed in the decision tree.\n    - errors (dict): A dictionary of self-healing errors that have occurred in the tree. Keyed by the function name that caused the error.\n\n    In general, you should not initialise this class directly.\n    But you can access the data in this class to access the relevant data from the tree (in e.g. tool construction/usage).\n    \"\"\"\n\n    def __init__(\n        self,\n        collection_data: CollectionData,\n        atlas: Atlas,\n        user_prompt: str | None = None,\n        conversation_history: list[dict] | None = None,\n        environment: Environment | None = None,\n        tasks_completed: list[dict] | None = None,\n        num_trees_completed: int | None = None,\n        recursion_limit: int | None = None,\n        settings: Settings | None = None,\n    ):\n        if settings is None:\n            self.settings = environment_settings\n        else:\n            self.settings = settings\n\n        # -- Base Data --\n        if user_prompt is None:\n            self.user_prompt = \"\"\n        else:\n            self.user_prompt = user_prompt\n\n        if conversation_history is None:\n            self.conversation_history = []\n        else:\n            self.conversation_history = conversation_history\n\n        if environment is None:\n            self.environment = Environment()\n        else:\n            self.environment = environment\n\n        if tasks_completed is None:\n            self.tasks_completed = []\n        else:\n            self.tasks_completed = tasks_completed\n\n        if num_trees_completed is None:\n            self.num_trees_completed = 0\n        else:\n            self.num_trees_completed = num_trees_completed\n\n        if recursion_limit is None:\n            self.recursion_limit = 3\n        else:\n            self.recursion_limit = recursion_limit\n\n        # -- Atlas --\n        self.atlas = atlas\n\n        # -- Collection Data --\n        self.collection_data = collection_data\n        self.collection_names = []\n\n        # -- Errors --\n        self.errors: dict[str, list[str]] = {}\n        self.current_task = None\n\n    def set_property(self, property: str, value: Any):\n        self.__dict__[property] = value\n\n    def update_string(self, property: str, value: str):\n        if property not in self.__dict__:\n            self.__dict__[property] = \"\"\n        self.__dict__[property] += value\n\n    def update_list(self, property: str, value: Any):\n        if property not in self.__dict__:\n            self.__dict__[property] = []\n        self.__dict__[property].append(value)\n\n    def update_dict(self, property: str, key: str, value: Any):\n        if property not in self.__dict__:\n            self.__dict__[property] = {}\n        self.__dict__[property][key] = value\n\n    def delete_from_dict(self, property: str, key: str):\n        if property in self.__dict__ and key in self.__dict__[property]:\n            del self.__dict__[property][key]\n\n    def soft_reset(self):\n        self.previous_reasoning = {}\n\n    def _update_task(self, task_dict, key, value):\n        if value is not None:\n            if key in task_dict:\n                # If key already exists, append to it\n                if isinstance(value, str):\n                    task_dict[key] += \"\\n\" + value\n                elif isinstance(value, int) or isinstance(value, float):\n                    task_dict[key] += value\n                elif isinstance(value, list):\n                    task_dict[key].extend(value)\n                elif isinstance(value, dict):\n                    task_dict[key].update(value)\n                elif isinstance(value, bool):\n                    task_dict[key] = value\n            elif key not in task_dict:\n                # If key does not exist, create it\n                task_dict[key] = value\n\n    def update_tasks_completed(\n        self, prompt: str, task: str, num_trees_completed: int, **kwargs\n    ):\n        # search to see if the current prompt already has an entry for this task\n        prompt_found = False\n        task_found = False\n        iteration_found = False\n\n        for i, task_prompt in enumerate(self.tasks_completed):\n            if task_prompt[\"prompt\"] == prompt:\n                prompt_found = True\n                for j, task_j in enumerate(task_prompt[\"task\"]):\n                    if task_j[\"task\"] == task:\n                        task_found = True\n                        task_i = j  # position of the task in the prompt\n\n                    if task_j[\"iteration\"] == num_trees_completed:\n                        iteration_found = True\n\n        # If the prompt is not found, add it to the list\n        if not prompt_found:\n            self.tasks_completed.append({\"prompt\": prompt, \"task\": [{}]})\n            self.tasks_completed[-1][\"task\"][0][\"task\"] = task\n            self.tasks_completed[-1][\"task\"][0][\"iteration\"] = num_trees_completed\n            for kwarg in kwargs:\n                self._update_task(\n                    self.tasks_completed[-1][\"task\"][0], kwarg, kwargs[kwarg]\n                )\n            return\n\n        # If the prompt is found but the task is not, add it to the list\n        if prompt_found and not task_found:\n            self.tasks_completed[-1][\"task\"].append({})\n            self.tasks_completed[-1][\"task\"][-1][\"task\"] = task\n            self.tasks_completed[-1][\"task\"][-1][\"iteration\"] = num_trees_completed\n            for kwarg in kwargs:\n                self._update_task(\n                    self.tasks_completed[-1][\"task\"][-1], kwarg, kwargs[kwarg]\n                )\n            return\n\n        # task already exists in this query, but the iteration is new\n        if prompt_found and task_found and not iteration_found:\n            self.tasks_completed[-1][\"task\"].append({})\n            self.tasks_completed[-1][\"task\"][-1][\"task\"] = task\n            self.tasks_completed[-1][\"task\"][-1][\"iteration\"] = num_trees_completed\n            for kwarg in kwargs:\n                self._update_task(\n                    self.tasks_completed[-1][\"task\"][-1], kwarg, kwargs[kwarg]\n                )\n            return\n\n        # If the prompt is found and the task is found, update the task\n        if prompt_found and task_found:\n            for kwarg in kwargs:\n                self._update_task(\n                    self.tasks_completed[-1][\"task\"][task_i], kwarg, kwargs[kwarg]\n                )\n\n    def set_current_task(self, task: str):\n        self.current_task = task\n\n    def get_errors(self):\n        if self.current_task == \"elysia_decision_node\":\n            return self.errors\n        elif self.current_task is None or self.current_task not in self.errors:\n            return []\n        else:\n            return self.errors[self.current_task]\n\n    def clear_error(self, task: str):\n        if task in self.errors:\n            self.errors[task] = []\n\n    def tasks_completed_string(self):\n        \"\"\"\n        Output a nicely formatted string of the tasks completed so far, designed to be used in the LLM prompt.\n        This is where the outputs of the `llm_message` fields are displayed.\n        You can use this if you are interfacing with LLMs in tools, to help it understand the context of the tasks completed so far.\n\n        Returns:\n            (str): A separated and formatted string of the tasks completed so far in an LLM-parseable format.\n        \"\"\"\n        out = \"\"\n        for j, task_prompt in enumerate(self.tasks_completed):\n            out += f\"&lt;prompt_{j+1}&gt;\\n\"\n            out += f\"Prompt: {task_prompt['prompt']}\\n\"\n\n            for i, task in enumerate(task_prompt[\"task\"]):\n                out += f\"&lt;task_{i+1}&gt;\\n\"\n\n                if \"action\" in task and task[\"action\"]:\n                    out += f\"Chosen action: {task['task']} (this does not mean it has been completed, only that it was chosen) \"\n                    out += \"(Use the environment to judge if a task is completed)\"\n                else:\n                    out += f\"Chosen subcategory: {task['task']} (this action has not been completed, this is only a subcategory)\"\n\n                if \"error\" in task and task[\"error\"]:\n                    out += f\" (There was an error during this tool call)\\n\"\n                else:\n                    out += f\" (Successfully completed)\\n\"\n\n                for key in task:\n                    if key != \"task\" and key != \"action\":\n                        out += f\"{key.capitalize()}: {task[key]}\\n\"\n\n                out += f\"&lt;/task_{i+1}&gt;\\n\"\n            out += f\"&lt;/prompt_{j+1}&gt;\\n\"\n\n        return out\n\n    async def set_collection_names(\n        self, collection_names: list[str], client_manager: ClientManager\n    ):\n        self.collection_names = await self.collection_data.set_collection_names(\n            collection_names, client_manager\n        )\n        return self.collection_names\n\n    def tree_count_string(self):\n        out = f\"{self.num_trees_completed+1}/{self.recursion_limit}\"\n        if self.num_trees_completed == self.recursion_limit - 1:\n            out += \" (this is the last decision you can make before being cut off)\"\n        if self.num_trees_completed &gt;= self.recursion_limit:\n            out += \" (recursion limit reached, write your full chat response accordingly - the decision process has been cut short, and it is likely the user's question has not been fully answered and you either haven't been able to do it or it was impossible)\"\n        return out\n\n    def output_collection_metadata(\n        self, collection_names: list[str] | None = None, with_mappings: bool = False\n    ):\n        \"\"\"\n        Outputs the full metadata for the given collection names.\n\n        Args:\n            with_mappings (bool): Whether to output the mappings for the collections as well as the other metadata.\n\n        Returns:\n            dict (dict[str, dict]): A dictionary of collection names to their metadata.\n                The metadata are of the form:\n                ```python\n                {\n                    # summary statistics of each field in the collection\n                    \"fields\": list = [\n                        field_name_1: dict = {\n                            \"description\": str,\n                            \"range\": list[float],\n                            \"type\": str,\n                            \"groups\": dict[str, str],\n                            \"mean\": float\n                        },\n                        field_name_2: dict = {\n                            ... # same fields as above\n                        },\n                        ...\n                    ],\n\n                    # mapping_1, mapping_2 etc refer to frontend-specific types that the AI has deemed appropriate for this data\n                    # then the dict is to map the frontend fields to the data fields\n                    \"mappings\": dict = {\n                        mapping_1: dict = {\n                            \"frontend_field_1\": \"data_field_1\",\n                            \"frontend_field_2\": \"data_field_2\",\n                            ...\n                        },\n                        mapping_2: dict = {\n                            ... # same fields as above\n                        },\n                        ...,\n                    },\n\n                    # number of items in collection (float but just for consistency)\n                    \"length\": float,\n\n                    # AI generated summary of the dataset\n                    \"summary\": str,\n\n                    # name of collection\n                    \"name\": str,\n\n                    # what named vectors are available and their properties (if any)\n                    \"named_vectors\": list = [\n                        {\n                            \"name\": str,\n                            \"enabled\": bool,\n                            \"source_properties\": list,\n                            \"description\": str # defaults to empty\n                        },\n                        ...\n                    ],\n\n                    # some config settings relevant for queries\n                    \"index_properties\": {\n                        \"isNullIndexed\": bool,\n                        \"isLengthIndexed\": bool,\n                        \"isTimestampIndexed\": bool,\n                    },\n                }\n                ```\n                If `with_mappings` is `False`, then the mappings are not included.\n                Each key in the outer level dictionary is a collection name.\n\n        \"\"\"\n\n        if collection_names is None:\n            collection_names = self.collection_names\n\n        return self.collection_data.output_full_metadata(\n            collection_names, with_mappings\n        )\n\n    def output_collection_return_types(self) -&gt; dict[str, list[str]]:\n        \"\"\"\n        Outputs the return types for the collections in the tree data.\n        Essentially, this is a list of the keys that can be used to map the objects to the frontend.\n\n        Returns:\n            (dict): A dictionary of collection names to their return types.\n                ```python\n                {\n                    collection_name_1: list[str],\n                    collection_name_2: list[str],\n                    ...,\n                }\n                ```\n                Each of these lists is a list of the keys that can be used to map the objects to the frontend.\n        \"\"\"\n        collection_return_types = self.collection_data.output_mapping_lists()\n        out = {\n            collection_name: collection_return_types[collection_name]\n            for collection_name in self.collection_names\n        }\n        return out\n\n    def to_json(self, remove_unserialisable: bool = False):\n        out = {\n            k: v\n            for k, v in self.__dict__.items()\n            if k not in [\"collection_data\", \"atlas\", \"environment\", \"settings\"]\n        }\n        out[\"collection_data\"] = self.collection_data.to_json()\n        out[\"atlas\"] = self.atlas.model_dump()\n        out[\"environment\"] = self.environment.to_json(remove_unserialisable)\n        out[\"settings\"] = self.settings.to_json()\n        return out\n\n    @classmethod\n    def from_json(cls, json_data: dict):\n        settings = Settings.from_json(json_data[\"settings\"])\n        logger = settings.logger\n        collection_data = CollectionData.from_json(json_data[\"collection_data\"], logger)\n        atlas = Atlas.model_validate(json_data[\"atlas\"])\n        environment = Environment.from_json(json_data[\"environment\"])\n\n        tree_data = cls(\n            collection_data=collection_data,\n            atlas=atlas,\n            environment=environment,\n            settings=settings,\n        )\n        for item in json_data:\n            if item not in [\"collection_data\", \"atlas\", \"environment\", \"settings\"]:\n                tree_data.set_property(item, json_data[item])\n        return tree_data\n</code></pre>"},{"location":"Reference/Objects/#elysia.tree.objects.TreeData.output_collection_metadata","title":"<code>output_collection_metadata(collection_names=None, with_mappings=False)</code>","text":"<p>Outputs the full metadata for the given collection names.</p> <p>Parameters:</p> Name Type Description Default <code>with_mappings</code> <code>bool</code> <p>Whether to output the mappings for the collections as well as the other metadata.</p> <code>False</code> <p>Returns:</p> Name Type Description <code>dict</code> <code>dict[str, dict]</code> <p>A dictionary of collection names to their metadata. The metadata are of the form: <pre><code>{\n    # summary statistics of each field in the collection\n    \"fields\": list = [\n        field_name_1: dict = {\n            \"description\": str,\n            \"range\": list[float],\n            \"type\": str,\n            \"groups\": dict[str, str],\n            \"mean\": float\n        },\n        field_name_2: dict = {\n            ... # same fields as above\n        },\n        ...\n    ],\n\n    # mapping_1, mapping_2 etc refer to frontend-specific types that the AI has deemed appropriate for this data\n    # then the dict is to map the frontend fields to the data fields\n    \"mappings\": dict = {\n        mapping_1: dict = {\n            \"frontend_field_1\": \"data_field_1\",\n            \"frontend_field_2\": \"data_field_2\",\n            ...\n        },\n        mapping_2: dict = {\n            ... # same fields as above\n        },\n        ...,\n    },\n\n    # number of items in collection (float but just for consistency)\n    \"length\": float,\n\n    # AI generated summary of the dataset\n    \"summary\": str,\n\n    # name of collection\n    \"name\": str,\n\n    # what named vectors are available and their properties (if any)\n    \"named_vectors\": list = [\n        {\n            \"name\": str,\n            \"enabled\": bool,\n            \"source_properties\": list,\n            \"description\": str # defaults to empty\n        },\n        ...\n    ],\n\n    # some config settings relevant for queries\n    \"index_properties\": {\n        \"isNullIndexed\": bool,\n        \"isLengthIndexed\": bool,\n        \"isTimestampIndexed\": bool,\n    },\n}\n</code></pre> If <code>with_mappings</code> is <code>False</code>, then the mappings are not included. Each key in the outer level dictionary is a collection name.</p> Source code in <code>elysia/tree/objects.py</code> <pre><code>def output_collection_metadata(\n    self, collection_names: list[str] | None = None, with_mappings: bool = False\n):\n    \"\"\"\n    Outputs the full metadata for the given collection names.\n\n    Args:\n        with_mappings (bool): Whether to output the mappings for the collections as well as the other metadata.\n\n    Returns:\n        dict (dict[str, dict]): A dictionary of collection names to their metadata.\n            The metadata are of the form:\n            ```python\n            {\n                # summary statistics of each field in the collection\n                \"fields\": list = [\n                    field_name_1: dict = {\n                        \"description\": str,\n                        \"range\": list[float],\n                        \"type\": str,\n                        \"groups\": dict[str, str],\n                        \"mean\": float\n                    },\n                    field_name_2: dict = {\n                        ... # same fields as above\n                    },\n                    ...\n                ],\n\n                # mapping_1, mapping_2 etc refer to frontend-specific types that the AI has deemed appropriate for this data\n                # then the dict is to map the frontend fields to the data fields\n                \"mappings\": dict = {\n                    mapping_1: dict = {\n                        \"frontend_field_1\": \"data_field_1\",\n                        \"frontend_field_2\": \"data_field_2\",\n                        ...\n                    },\n                    mapping_2: dict = {\n                        ... # same fields as above\n                    },\n                    ...,\n                },\n\n                # number of items in collection (float but just for consistency)\n                \"length\": float,\n\n                # AI generated summary of the dataset\n                \"summary\": str,\n\n                # name of collection\n                \"name\": str,\n\n                # what named vectors are available and their properties (if any)\n                \"named_vectors\": list = [\n                    {\n                        \"name\": str,\n                        \"enabled\": bool,\n                        \"source_properties\": list,\n                        \"description\": str # defaults to empty\n                    },\n                    ...\n                ],\n\n                # some config settings relevant for queries\n                \"index_properties\": {\n                    \"isNullIndexed\": bool,\n                    \"isLengthIndexed\": bool,\n                    \"isTimestampIndexed\": bool,\n                },\n            }\n            ```\n            If `with_mappings` is `False`, then the mappings are not included.\n            Each key in the outer level dictionary is a collection name.\n\n    \"\"\"\n\n    if collection_names is None:\n        collection_names = self.collection_names\n\n    return self.collection_data.output_full_metadata(\n        collection_names, with_mappings\n    )\n</code></pre>"},{"location":"Reference/Objects/#elysia.tree.objects.TreeData.output_collection_return_types","title":"<code>output_collection_return_types()</code>","text":"<p>Outputs the return types for the collections in the tree data. Essentially, this is a list of the keys that can be used to map the objects to the frontend.</p> <p>Returns:</p> Type Description <code>dict</code> <p>A dictionary of collection names to their return types. <pre><code>{\n    collection_name_1: list[str],\n    collection_name_2: list[str],\n    ...,\n}\n</code></pre> Each of these lists is a list of the keys that can be used to map the objects to the frontend.</p> Source code in <code>elysia/tree/objects.py</code> <pre><code>def output_collection_return_types(self) -&gt; dict[str, list[str]]:\n    \"\"\"\n    Outputs the return types for the collections in the tree data.\n    Essentially, this is a list of the keys that can be used to map the objects to the frontend.\n\n    Returns:\n        (dict): A dictionary of collection names to their return types.\n            ```python\n            {\n                collection_name_1: list[str],\n                collection_name_2: list[str],\n                ...,\n            }\n            ```\n            Each of these lists is a list of the keys that can be used to map the objects to the frontend.\n    \"\"\"\n    collection_return_types = self.collection_data.output_mapping_lists()\n    out = {\n        collection_name: collection_return_types[collection_name]\n        for collection_name in self.collection_names\n    }\n    return out\n</code></pre>"},{"location":"Reference/Objects/#elysia.tree.objects.TreeData.tasks_completed_string","title":"<code>tasks_completed_string()</code>","text":"<p>Output a nicely formatted string of the tasks completed so far, designed to be used in the LLM prompt. This is where the outputs of the <code>llm_message</code> fields are displayed. You can use this if you are interfacing with LLMs in tools, to help it understand the context of the tasks completed so far.</p> <p>Returns:</p> Type Description <code>str</code> <p>A separated and formatted string of the tasks completed so far in an LLM-parseable format.</p> Source code in <code>elysia/tree/objects.py</code> <pre><code>def tasks_completed_string(self):\n    \"\"\"\n    Output a nicely formatted string of the tasks completed so far, designed to be used in the LLM prompt.\n    This is where the outputs of the `llm_message` fields are displayed.\n    You can use this if you are interfacing with LLMs in tools, to help it understand the context of the tasks completed so far.\n\n    Returns:\n        (str): A separated and formatted string of the tasks completed so far in an LLM-parseable format.\n    \"\"\"\n    out = \"\"\n    for j, task_prompt in enumerate(self.tasks_completed):\n        out += f\"&lt;prompt_{j+1}&gt;\\n\"\n        out += f\"Prompt: {task_prompt['prompt']}\\n\"\n\n        for i, task in enumerate(task_prompt[\"task\"]):\n            out += f\"&lt;task_{i+1}&gt;\\n\"\n\n            if \"action\" in task and task[\"action\"]:\n                out += f\"Chosen action: {task['task']} (this does not mean it has been completed, only that it was chosen) \"\n                out += \"(Use the environment to judge if a task is completed)\"\n            else:\n                out += f\"Chosen subcategory: {task['task']} (this action has not been completed, this is only a subcategory)\"\n\n            if \"error\" in task and task[\"error\"]:\n                out += f\" (There was an error during this tool call)\\n\"\n            else:\n                out += f\" (Successfully completed)\\n\"\n\n            for key in task:\n                if key != \"task\" and key != \"action\":\n                    out += f\"{key.capitalize()}: {task[key]}\\n\"\n\n            out += f\"&lt;/task_{i+1}&gt;\\n\"\n        out += f\"&lt;/prompt_{j+1}&gt;\\n\"\n\n    return out\n</code></pre>"},{"location":"Reference/PayloadTypes/","title":"Payload Types","text":"<p>Below is the full contents of the <code>return_types.py</code> file, which specifies the different ways that Elysia sends results whenever <code>tree.async_run()</code> yields an object. This is primarily intended for interacting with the frontend - giving the frontend a specific 'payload type' and ensuring that all objects sent conform to the same 'mapping'.</p> <p>Each individual payload type has its own mapping. In this file, the keys of each dictionary are the allowed fields, and the values are descriptions for each field. The <code>specific_return_types</code> has broad descriptions of each class.</p> <pre><code>specific_return_types = {\n    \"conversation\": (\n        \"Full conversations, including all messages and message authors, with timestamps and context of other messages in the conversation. \"\n        \"This type can only be selected if there is a field that uniquely identifies what conversation each message belongs to, e.g. a 'Conversation ID', \"\n        \"as well as a field that uniquely identifies each message within the conversation, e.g. a 'Message ID'.\"\n    ),\n    \"message\": (\n        \"Individual messages, only including the author of each individual message and timestamp, \"\n        \"without surrounding context of other messages by different people. \"\n        \"If the 'conversation' field is suitable, then this is also suitable by definition.\"\n    ),\n    \"ticket\": (\"Support tickets, similar to Github issues or similar.\"),\n    \"product\": (\n        \"Products items, so usually involving descriptions, prices, ratings, reviews, etc, but not always. \"\n        \"Contains an image field, and space for plenty of metadata.\"\n    ),\n    \"document\": (\n        \"Text-based information, optionally with a title, author, date, and content, but not always. \"\n        \"Ideal for any text-based information.\"\n    ),\n}\n\nall_return_types = {\n    **specific_return_types,\n    \"generic\": (\n        \"Any other type of information that does not fit into the more specific categories. \"\n        \"Contains fields for a range of different types of information, and is a good option for a wide range of data if no other display type is available. \"\n    ),\n    \"table\": (\n        \"A table of information, with rows and columns. Used for displaying all of the data in a structured way. \"\n        \"This is a fall-back option if not other display type is available. \"\n        \"Alternatively, if the data or query requires a more analytical insight, this could be a good option.\"\n    ),\n}\n\nconversation = {\n    \"content\": \"the content or text of the message, what was written. string\",\n    \"author\": \"the author of the message. string\",\n    \"timestamp\": \"the timestamp of the message in any format. datetime/string/other\",\n    \"conversation_id\": \"the id of the conversation that the message belongs to. integer/string/other\",\n    \"message_id\": \"the id of the message itself, within the conversation. integer/string/other\",\n}\n\nmessage = {\n    \"content\": \"the content or text of the message, what was written. string\",\n    \"author\": \"the author of the message. string\",\n    \"timestamp\": \"the timestamp of the message in any format. datetime/string/other\",\n    \"conversation_id\": \"the id of the conversation that the message belongs to. integer/string/other\",\n    \"message_id\": \"the id or index of the message, used to either identify a message within a conversation or the message itself. integer/string/other\",\n}\n\nticket = {\n    \"title\": \"the title of the ticket. string\",\n    \"subtitle\": \"the subtitle of the ticket. string\",\n    \"author\": \"the author of the ticket. string\",\n    \"content\": \"the text of the ticket. string\",\n    \"created_at\": \"the timestamp of the original creation time/date of the ticket in any format. datetime/string/other\",\n    \"updated_at\": \"the timestamp of the last update time/date of the ticket in any format. datetime/string/other\",\n    \"url\": \"the url of the ticket. string\",\n    \"status\": \"the status of the ticket. string\",\n    \"id\": \"the id of the ticket. integer/string/other\",\n    \"tags\": \"the tags of the ticket. list[string/other]\",\n    \"comments\": \"either the comments of the ticket, or the number of comments. list[string/dict/other] / integer\",\n}\n\nproduct = {\n    \"name\": \"the name of the product. string\",\n    \"description\": \"the description of the product. string\",\n    \"price\": \"the price of the product. float/integer/other\",\n    \"category\": \"the category of the product. string\",\n    \"subcategory\": \"the subcategory of the product. string\",\n    \"collection\": \"the collection that the product belongs to. string\",\n    \"rating\": \"the rating of the product. float/integer/other\",\n    \"reviews\": \"the reviews of the product, or number of reviews. list[string/dict/other] / integer\",\n    \"tags\": \"the tags of the product. list[string/other]\",\n    \"url\": \"the url of the product. string\",\n    \"image\": \"the image of the product. string/other\",\n    \"brand\": \"the brand of the product. string\",\n    \"id\": \"the id of the product. integer/string/other\",\n    \"colors\": \"the color(s) of the product. list[string/other] / string\",\n    \"sizes\": \"the size(s) of the product. list[string/other] / string\",\n}\n\ndocument = {\n    \"title\": \"the title of the document. string\",\n    \"author\": \"the author or username or creator of the document. string\",\n    \"date\": \"any date or time format. datetime/string/other\",\n    \"content\": \"the textual content of the document. string/other\",\n    \"category\": \"some string describing the category of the document, e.g. type of something. string\",\n}\n\ngeneric = {\n    \"title\": \"the title of the information. string\",\n    \"subtitle\": \"the subtitle of the information. string\",\n    \"content\": \"the content of the information. string/other\",\n    \"url\": \"the url of the information. string\",\n    \"id\": \"the id of the information. integer/string/other\",\n    \"author\": \"the author of the information. string/other\",\n    \"timestamp\": \"the timestamp of the information in any format. datetime/string/other\",\n    \"tags\": \"the tags of the information. list[string/other]\",\n    \"category\": \"some string describing the category of the information, e.g. type of something. string\",\n    \"subcategory\": \"some string describing a nested level of category of the data. string\",\n}\n\ntypes_dict: dict[str, dict[str, str]] = {\n    \"conversation\": conversation,\n    \"message\": message,\n    \"ticket\": ticket,\n    \"product\": product,\n    \"generic\": generic,\n    \"document\": document,\n    \"table\": {},\n}\n</code></pre>"},{"location":"Reference/Preprocessor/","title":"Preprocessor","text":""},{"location":"Reference/Preprocessor/#elysia.preprocessing.collection.delete_preprocessed_collection","title":"<code>delete_preprocessed_collection(collection_name, client_manager=None)</code>","text":"<p>Delete a preprocessed collection. This function allows you to delete the preprocessing done for a particular collection. It does so by deleting the object in the ELYSIA_METADATA__ collection with the name of the collection.</p> <p>Parameters:</p> Name Type Description Default <code>collection_name</code> <code>str</code> <p>The name of the collection to delete.</p> required <code>client_manager</code> <code>ClientManager</code> <p>The client manager to use.</p> <code>None</code> Source code in <code>elysia/preprocessing/collection.py</code> <pre><code>def delete_preprocessed_collection(\n    collection_name: str, client_manager: ClientManager | None = None\n) -&gt; None:\n    \"\"\"\n    Delete a preprocessed collection.\n    This function allows you to delete the preprocessing done for a particular collection.\n    It does so by deleting the object in the ELYSIA_METADATA__ collection with the name of the collection.\n\n    Args:\n        collection_name (str): The name of the collection to delete.\n        client_manager (ClientManager): The client manager to use.\n    \"\"\"\n    return asyncio_run(\n        delete_preprocessed_collection_async(collection_name, client_manager)\n    )\n</code></pre>"},{"location":"Reference/Preprocessor/#elysia.preprocessing.collection.delete_preprocessed_collection_async","title":"<code>delete_preprocessed_collection_async(collection_name, client_manager=None)</code>  <code>async</code>","text":"<p>Delete the preprocessed collection from the Weaviate cluster. This function simply deletes the cached preprocessed metadata from the Weaviate cluster. It does so by deleting the object in the collection ELYSIA_METADATA__ with the name of the collection.</p> <p>Parameters:</p> Name Type Description Default <code>collection_name</code> <code>str</code> <p>The name of the collection to delete the preprocessed metadata for.</p> required <code>client_manager</code> <code>ClientManager</code> <p>The client manager to use. If not provided, a new ClientManager will be created using the environment variables/configured settings.</p> <code>None</code> Source code in <code>elysia/preprocessing/collection.py</code> <pre><code>async def delete_preprocessed_collection_async(\n    collection_name: str, client_manager: ClientManager | None = None\n) -&gt; None:\n    \"\"\"\n    Delete the preprocessed collection from the Weaviate cluster.\n    This function simply deletes the cached preprocessed metadata from the Weaviate cluster.\n    It does so by deleting the object in the collection ELYSIA_METADATA__ with the name of the collection.\n\n    Args:\n        collection_name (str): The name of the collection to delete the preprocessed metadata for.\n        client_manager (ClientManager): The client manager to use.\n            If not provided, a new ClientManager will be created using the environment variables/configured settings.\n    \"\"\"\n    if client_manager is None:\n        client_manager = ClientManager()\n        close_clients_after_completion = True\n    else:\n        close_clients_after_completion = False\n\n    async with client_manager.connect_to_async_client() as client:\n        if await client.collections.exists(f\"ELYSIA_METADATA__\"):\n            metadata_collection = client.collections.get(\"ELYSIA_METADATA__\")\n            metadata = await metadata_collection.query.fetch_objects(\n                filters=Filter.by_property(\"name\").equal(collection_name),\n                limit=1,\n            )\n            if metadata is not None and len(metadata.objects) &gt; 0:\n                await metadata_collection.data.delete_by_id(metadata.objects[0].uuid)\n            else:\n                raise Exception(f\"Metadata for {collection_name} does not exist\")\n\n    if close_clients_after_completion:\n        await client_manager.close_clients()\n</code></pre>"},{"location":"Reference/Preprocessor/#elysia.preprocessing.collection.edit_preprocessed_collection","title":"<code>edit_preprocessed_collection(collection_name, client_manager=None, named_vectors=None, summary=None, mappings=None, fields=None)</code>","text":"<p>Edit a preprocessed collection. This function allows you to edit the named vectors, summary, mappings, and fields of a preprocessed collection. It does so by updating the ELYSIA_METADATA__ collection. Find available mappings in the <code>elysia.util.return_types</code> module.</p> <p>Parameters:</p> Name Type Description Default <code>collection_name</code> <code>str</code> <p>The name of the collection to edit.</p> required <code>client_manager</code> <code>ClientManager</code> <p>The client manager to use. If not provided, a new ClientManager will be created using the environment variables/configured settings.</p> <code>None</code> <code>named_vectors</code> <code>list[dict]</code> <p>The named vectors to update. This has fields \"name\", \"enabled\", and \"description\". The \"name\" is used to identify the named vector to change (the name will not change). Set \"enabled\" to True/False to enable/disable the named vector. Set \"description\" to describe the named vector. The description of named vectors is not automatically generated by the LLM. Any named vectors that are not provided will not be updated. If None or not provided, the named vectors will not be updated.</p> <code>None</code> <code>summary</code> <code>str</code> <p>The summary to update. The summary is a short description of the collection, generated by the LLM. This will replace the existing summary of the collection. If None or not provided, the summary will not be updated.</p> <code>None</code> <code>mappings</code> <code>dict</code> <p>The mappings to update. The mappings are what the frontend will use to display the collection, and the associated fields. I.e., which fields correspond to which output fields on the frontend. The keys of the outer level of the dictionary are the mapping names, the values are dictionaries with the mappings. The inner dictionary has the keys as the collection fields, and the values as the frontend fields. If None or not provided, the mappings will not be updated.</p> <code>None</code> <code>fields</code> <code>list[dict]</code> <p>The fields to update. Each element in the list is a dictionary with the following fields: - \"name\": The name of the field. (This is used to identify the field to change, the name will not change). - \"description\": The description of the field to update. Any fields that are not provided will not be updated. If None or not provided, the fields will not be updated.</p> <code>None</code> <p>Returns:</p> Name Type Description <code>dict</code> <code>None</code> <p>The updated preprocessed collection.</p> Source code in <code>elysia/preprocessing/collection.py</code> <pre><code>def edit_preprocessed_collection(\n    collection_name: str,\n    client_manager: ClientManager | None = None,\n    named_vectors: list[dict] | None = None,\n    summary: str | None = None,\n    mappings: dict[str, dict[str, str]] | None = None,\n    fields: list[dict[str, str] | None] | None = None,\n) -&gt; None:\n    \"\"\"\n    Edit a preprocessed collection.\n    This function allows you to edit the named vectors, summary, mappings, and fields of a preprocessed collection.\n    It does so by updating the ELYSIA_METADATA__ collection.\n    Find available mappings in the `elysia.util.return_types` module.\n\n    Args:\n        collection_name (str): The name of the collection to edit.\n        client_manager (ClientManager): The client manager to use.\n            If not provided, a new ClientManager will be created using the environment variables/configured settings.\n        named_vectors (list[dict]): The named vectors to update. This has fields \"name\", \"enabled\", and \"description\".\n            The \"name\" is used to identify the named vector to change (the name will not change).\n            Set \"enabled\" to True/False to enable/disable the named vector.\n            Set \"description\" to describe the named vector.\n            The description of named vectors is not automatically generated by the LLM.\n            Any named vectors that are not provided will not be updated.\n            If None or not provided, the named vectors will not be updated.\n        summary (str): The summary to update.\n            The summary is a short description of the collection, generated by the LLM.\n            This will replace the existing summary of the collection.\n            If None or not provided, the summary will not be updated.\n        mappings (dict): The mappings to update.\n            The mappings are what the frontend will use to display the collection, and the associated fields.\n            I.e., which fields correspond to which output fields on the frontend.\n            The keys of the outer level of the dictionary are the mapping names, the values are dictionaries with the mappings.\n            The inner dictionary has the keys as the collection fields, and the values as the frontend fields.\n            If None or not provided, the mappings will not be updated.\n        fields (list[dict]): The fields to update.\n            Each element in the list is a dictionary with the following fields:\n            - \"name\": The name of the field. (This is used to identify the field to change, the name will not change).\n            - \"description\": The description of the field to update.\n            Any fields that are not provided will not be updated.\n            If None or not provided, the fields will not be updated.\n\n    Returns:\n        dict: The updated preprocessed collection.\n    \"\"\"\n\n    return asyncio_run(\n        edit_preprocessed_collection_async(\n            collection_name, client_manager, named_vectors, summary, mappings, fields\n        )\n    )\n</code></pre>"},{"location":"Reference/Preprocessor/#elysia.preprocessing.collection.edit_preprocessed_collection_async","title":"<code>edit_preprocessed_collection_async(collection_name, client_manager=None, named_vectors=None, summary=None, mappings=None, fields=None)</code>  <code>async</code>","text":"<p>Async version of <code>edit_preprocessed_collection</code>.</p> <p>Parameters:</p> Name Type Description Default <code>collection_name</code> <code>str</code> <p>The name of the collection to edit.</p> required <code>client_manager</code> <code>ClientManager</code> <p>The client manager to use. If not provided, a new ClientManager will be created using the environment variables/configured settings.</p> <code>None</code> <code>named_vectors</code> <code>list[dict]</code> <p>The named vectors to update. This has fields \"name\", \"enabled\", and \"description\". The \"name\" is used to identify the named vector to change (the name will not change). Set \"enabled\" to True/False to enable/disable the named vector. Set \"description\" to describe the named vector. The description of named vectors is not automatically generated by the LLM. Any named vectors that are not provided will not be updated. If None or not provided, the named vectors will not be updated.</p> <code>None</code> <code>summary</code> <code>str</code> <p>The summary to update. The summary is a short description of the collection, generated by the LLM. This will replace the existing summary of the collection. If None or not provided, the summary will not be updated.</p> <code>None</code> <code>mappings</code> <code>dict</code> <p>The mappings to update. The mappings are what the frontend will use to display the collection, and the associated fields. I.e., which fields correspond to which output fields on the frontend. The keys of the outer level of the dictionary are the mapping names, the values are dictionaries with the mappings. The inner dictionary has the keys as the collection fields, and the values as the frontend fields. If None or not provided, the mappings will not be updated.</p> <code>None</code> <code>fields</code> <code>list[dict]</code> <p>The fields to update. Each element in the list is a dictionary with the following fields: - \"name\": The name of the field. (This is used to identify the field to change, the name will not change). - \"description\": The description of the field to update. Any fields that are not provided will not be updated. If None or not provided, the fields will not be updated.</p> <code>None</code> <p>Returns:</p> Name Type Description <code>dict</code> <code>dict</code> <p>The updated preprocessed collection.</p> Source code in <code>elysia/preprocessing/collection.py</code> <pre><code>async def edit_preprocessed_collection_async(\n    collection_name: str,\n    client_manager: ClientManager | None = None,\n    named_vectors: list[dict] | None = None,\n    summary: str | None = None,\n    mappings: dict[str, dict[str, str]] | None = None,\n    fields: list[dict[str, str] | None] | None = None,\n) -&gt; dict:\n    \"\"\"\n    Async version of `edit_preprocessed_collection`.\n\n    Args:\n        collection_name (str): The name of the collection to edit.\n        client_manager (ClientManager): The client manager to use.\n            If not provided, a new ClientManager will be created using the environment variables/configured settings.\n        named_vectors (list[dict]): The named vectors to update. This has fields \"name\", \"enabled\", and \"description\".\n            The \"name\" is used to identify the named vector to change (the name will not change).\n            Set \"enabled\" to True/False to enable/disable the named vector.\n            Set \"description\" to describe the named vector.\n            The description of named vectors is not automatically generated by the LLM.\n            Any named vectors that are not provided will not be updated.\n            If None or not provided, the named vectors will not be updated.\n        summary (str): The summary to update.\n            The summary is a short description of the collection, generated by the LLM.\n            This will replace the existing summary of the collection.\n            If None or not provided, the summary will not be updated.\n        mappings (dict): The mappings to update.\n            The mappings are what the frontend will use to display the collection, and the associated fields.\n            I.e., which fields correspond to which output fields on the frontend.\n            The keys of the outer level of the dictionary are the mapping names, the values are dictionaries with the mappings.\n            The inner dictionary has the keys as the collection fields, and the values as the frontend fields.\n            If None or not provided, the mappings will not be updated.\n        fields (list[dict]): The fields to update.\n            Each element in the list is a dictionary with the following fields:\n            - \"name\": The name of the field. (This is used to identify the field to change, the name will not change).\n            - \"description\": The description of the field to update.\n            Any fields that are not provided will not be updated.\n            If None or not provided, the fields will not be updated.\n\n    Returns:\n        dict: The updated preprocessed collection.\n    \"\"\"\n\n    if client_manager is None:\n        client_manager = ClientManager()\n        close_clients_after_completion = True\n    else:\n        close_clients_after_completion = False\n\n    async with client_manager.connect_to_async_client() as client:\n        metadata_name = f\"ELYSIA_METADATA__\"\n\n        # check if the collection itself exists\n        if not await client.collections.exists(collection_name):\n            raise Exception(f\"Collection {collection_name} does not exist\")\n\n        # check if the metadata collection exists\n        if not await client.collections.exists(metadata_name):\n            raise Exception(f\"Metadata collection does not exist\")\n\n        else:\n            metadata_collection = client.collections.get(metadata_name)\n            metadata = await metadata_collection.query.fetch_objects(\n                filters=Filter.by_property(\"name\").equal(collection_name),\n                limit=1,\n            )\n            uuid = metadata.objects[0].uuid\n            properties: dict = metadata.objects[0].properties  # type: ignore\n\n        # update the named vectors\n        if named_vectors is not None:\n            for named_vector in named_vectors:\n                for property_named_vector in properties[\"named_vectors\"]:\n                    if property_named_vector[\"name\"] == named_vector[\"name\"]:\n\n                        if named_vector[\"enabled\"] is not None:\n                            property_named_vector[\"enabled\"] = named_vector[\"enabled\"]\n\n                        if named_vector[\"description\"] is not None:\n                            property_named_vector[\"description\"] = named_vector[\n                                \"description\"\n                            ]\n\n        # update the summary\n        if summary is not None:\n            properties[\"summary\"] = summary\n\n        # update the mappings\n        if mappings is not None:\n            if \"table\" in mappings:\n                mappings[\"table\"] = {\n                    field[\"name\"]: field[\"name\"] for field in properties[\"fields\"]\n                }\n\n            # format all mappings\n            for mapping_type, mapping in mappings.items():\n                if mapping_type == \"table\":\n                    continue\n\n                # check if the mapping_type is valid\n                if mapping_type not in rt.types_dict:\n                    raise ValueError(\n                        f\"Invalid mapping type: {mapping_type}. Valid mapping types are: {list(rt.types_dict.keys())}\"\n                    )\n\n                # check if the mapping is valid\n                for field_name, field_value in mapping.items():\n                    if field_name not in rt.types_dict[mapping_type]:\n                        raise ValueError(\n                            f\"Invalid field name: {field_name} for mapping type: {mapping_type}. \"\n                            f\"Valid fields are: {list(rt.types_dict[mapping_type].keys())}\"\n                        )\n\n                # add empty fields\n                for true_field in rt.types_dict[mapping_type]:\n                    if true_field not in mapping:\n                        mapping[true_field] = \"\"\n\n            properties[\"mappings\"] = mappings\n\n            # check if the `conversation_id` field is in the mapping (required for conversation type)\n            if \"conversation\" in mappings and (\n                mappings[\"conversation\"][\"conversation_id\"] is None\n                or mappings[\"conversation\"][\"conversation_id\"] == \"\"\n            ):\n                raise ValueError(\n                    \"Conversation type requires a conversation_id field, but none was found in the mappings for conversation. \"\n                )\n\n            if \"conversation\" in mappings and (\n                mappings[\"conversation\"][\"message_id\"] is None\n                or mappings[\"conversation\"][\"message_id\"] == \"\"\n            ):\n                raise ValueError(\n                    \"Conversation type requires a message_id field, but none was found in the mappings for conversation. \"\n                )\n\n            # check if there is a message type as well as conversation\n            if \"message\" not in mappings and \"conversation\" in mappings:\n                raise ValueError(\n                    \"Conversation type requires message type to also be set as a fallback.\"\n                )\n\n        # update the fields\n        if fields is not None:\n            for field in fields:\n                for property_field in properties[\"fields\"]:\n                    if field is not None and property_field[\"name\"] == field[\"name\"]:\n                        property_field[\"description\"] = field[\"description\"]\n\n        format_dict_to_serialisable(properties)\n\n        # update the collection\n        await metadata_collection.data.update(uuid=uuid, properties=properties)\n\n    if close_clients_after_completion:\n        await client_manager.close_clients()\n\n    return properties\n</code></pre>"},{"location":"Reference/Preprocessor/#elysia.preprocessing.collection.preprocess","title":"<code>preprocess(collection_names, client_manager=None, min_sample_size=5, max_sample_size=100, num_sample_tokens=30000, settings=environment_settings, force=False)</code>","text":"<p>Preprocess a collection, obtain a LLM-generated summary of the collection, a set of statistics for each field (such as unique categories), and a set of mappings from the fields to the frontend-specific fields in Elysia.</p> <p>In order: 1. Evaluate all the data fields and groups/statistics of the data fields as a whole 2. Write a summary of the collection via an LLM 3. Evaluate what return types are available for this collection 4. For each data field in the collection, evaluate what corresponding entry goes to what field in the return type (mapping) 5. Save as a ELYSIA_METADATA__ collection</p> <p>Depending on the size of objects in the collection, you can choose the minimum and maximum sample size, which will be used to create a sample of objects for the LLM to create a collection summary. If your objects are particularly large, you can set the sample size to be smaller, to use less tokens and speed up the LLM processing. If your objects are small, you can set the sample size to be larger, to get a more accurate summary. This is a trade-off between speed/compute and accuracy.</p> <p>But note that the pre-processing step only needs to be done once for each collection. The output of this function is cached, so that if you run it again, it will not re-process the collection (unless the force flag is set to True).</p> <p>This function saves the output into a collection called ELYSIA_METADATA__, which is automatically called by Elysia. This is saved to whatever Weaviate cluster URL/API key you have configured, or in your environment variables. You can change this by setting the <code>wcd_url</code> and <code>wcd_api_key</code> in the settings, and pass this Settings object to this function.</p> <p>Parameters:</p> Name Type Description Default <code>collection_names</code> <code>str | list[str]</code> <p>The name(s) of the collections to preprocess. Can supply either a single string for one collection, or a list of strings for multiple collections.</p> required <code>client_manager</code> <code>ClientManager</code> <p>The client manager to use. If not provided, a new ClientManager will be created using the environment variables/configured settings.</p> <code>None</code> <code>min_sample_size</code> <code>int</code> <p>The minimum number of objects to sample from the collection to evaluate the statistics/summary. Optional, defaults to 10.</p> <code>5</code> <code>max_sample_size</code> <code>int</code> <p>The maximum number of objects to sample from the collection to evaluate the statistics/summary. Optional, defaults to 20.</p> <code>100</code> <code>num_sample_tokens</code> <code>int</code> <p>The maximum number of tokens in the sample objects used to evaluate the summary. Optional, defaults to 30000.</p> <code>30000</code> <code>settings</code> <code>Settings</code> <p>The settings to use. Optional, defaults to the environment variables/configured settings.</p> <code>settings</code> <code>force</code> <code>bool</code> <p>Whether to force the preprocessor to run even if the collection already exists. Optional, defaults to False.</p> <code>False</code> Source code in <code>elysia/preprocessing/collection.py</code> <pre><code>def preprocess(\n    collection_names: str | list[str],\n    client_manager: ClientManager | None = None,\n    min_sample_size: int = 5,\n    max_sample_size: int = 100,\n    num_sample_tokens: int = 30000,\n    settings: Settings = environment_settings,\n    force: bool = False,\n) -&gt; None:\n    \"\"\"\n    Preprocess a collection, obtain a LLM-generated summary of the collection,\n    a set of statistics for each field (such as unique categories), and a set of mappings\n    from the fields to the frontend-specific fields in Elysia.\n\n    In order:\n    1. Evaluate all the data fields and groups/statistics of the data fields as a whole\n    2. Write a summary of the collection via an LLM\n    3. Evaluate what return types are available for this collection\n    4. For each data field in the collection, evaluate what corresponding entry goes to what field in the return type (mapping)\n    5. Save as a ELYSIA_METADATA__ collection\n\n    Depending on the size of objects in the collection, you can choose the minimum and maximum sample size,\n    which will be used to create a sample of objects for the LLM to create a collection summary.\n    If your objects are particularly large, you can set the sample size to be smaller, to use less tokens and speed up the LLM processing.\n    If your objects are small, you can set the sample size to be larger, to get a more accurate summary.\n    This is a trade-off between speed/compute and accuracy.\n\n    But note that the pre-processing step only needs to be done once for each collection.\n    The output of this function is cached, so that if you run it again, it will not re-process the collection (unless the force flag is set to True).\n\n    This function saves the output into a collection called ELYSIA_METADATA__, which is automatically called by Elysia.\n    This is saved to whatever Weaviate cluster URL/API key you have configured, or in your environment variables.\n    You can change this by setting the `wcd_url` and `wcd_api_key` in the settings, and pass this Settings object to this function.\n\n    Args:\n        collection_names (str | list[str]): The name(s) of the collections to preprocess.\n            Can supply either a single string for one collection, or a list of strings for multiple collections.\n        client_manager (ClientManager): The client manager to use.\n            If not provided, a new ClientManager will be created using the environment variables/configured settings.\n        min_sample_size (int): The minimum number of objects to sample from the collection to evaluate the statistics/summary. Optional, defaults to 10.\n        max_sample_size (int): The maximum number of objects to sample from the collection to evaluate the statistics/summary. Optional, defaults to 20.\n        num_sample_tokens (int): The maximum number of tokens in the sample objects used to evaluate the summary. Optional, defaults to 30000.\n        settings (Settings): The settings to use. Optional, defaults to the environment variables/configured settings.\n        force (bool): Whether to force the preprocessor to run even if the collection already exists. Optional, defaults to False.\n    \"\"\"\n\n    asyncio_run(\n        _preprocess_async(\n            collection_names,\n            client_manager,\n            min_sample_size,\n            max_sample_size,\n            num_sample_tokens,\n            settings,\n            force,\n        )\n    )\n</code></pre>"},{"location":"Reference/Preprocessor/#elysia.preprocessing.collection.preprocess_async","title":"<code>preprocess_async(collection_name, client_manager=None, min_sample_size=10, max_sample_size=20, num_sample_tokens=30000, force=False, percentage_correct_threshold=0.3, settings=environment_settings)</code>  <code>async</code>","text":"<p>Preprocess a collection, obtain a LLM-generated summary of the collection, a set of statistics for each field (such as unique categories), and a set of mappings from the fields to the frontend-specific fields in Elysia.</p> <p>In order:</p> <ol> <li>Evaluate all the data fields and groups/statistics of the data fields as a whole</li> <li>Write a summary of the collection via an LLM</li> <li>Evaluate what return types are available for this collection</li> <li>For each data field in the collection, evaluate what corresponding entry goes to what field in the return type (mapping)</li> <li>Save as a ELYSIA_METADATA__ collection</li> </ol> <p>Parameters:</p> Name Type Description Default <code>collection_name</code> <code>str</code> <p>The name of the collection to preprocess.</p> required <code>client_manager</code> <code>ClientManager</code> <p>The client manager to use.</p> <code>None</code> <code>min_sample_size</code> <code>int</code> <p>The minimum number of objects to sample from the collection to evaluate the statistics/summary. Optional, defaults to 10.</p> <code>10</code> <code>max_sample_size</code> <code>int</code> <p>The maximum number of objects to sample from the collection to evaluate the statistics/summary. Optional, defaults to 20.</p> <code>20</code> <code>num_sample_tokens</code> <code>int</code> <p>The number of tokens to approximately sample from the collection to evaluate the summary. The preprocessor will aim to use this many tokens in the sample objects to evaluate the summary. But will not exceed the maximum number of objects specified by <code>max_sample_size</code>, and always use at least <code>min_sample_size</code> objects.</p> <code>30000</code> <code>force</code> <code>bool</code> <p>Whether to force the preprocessor to run even if the collection already exists. Optional, defaults to False.</p> <code>False</code> <code>threshold_for_missing_fields</code> <code>float</code> <p>The threshold for the number of missing fields in the data mapping. Optional, defaults to 0.1.</p> required <code>settings</code> <code>Settings</code> <p>The settings to use. Optional, defaults to the environment variables/configured settings.</p> <code>settings</code> <p>Returns:</p> Type Description <code>AsyncGenerator[dict, None]</code> <p>AsyncGenerator[dict, None]: A generator that yields dictionaries with the status updates and progress of the preprocessor.</p> Source code in <code>elysia/preprocessing/collection.py</code> <pre><code>async def preprocess_async(\n    collection_name: str,\n    client_manager: ClientManager | None = None,\n    min_sample_size: int = 10,\n    max_sample_size: int = 20,\n    num_sample_tokens: int = 30000,\n    force: bool = False,\n    percentage_correct_threshold: float = 0.3,\n    settings: Settings = environment_settings,\n) -&gt; AsyncGenerator[dict, None]:\n    \"\"\"\n    Preprocess a collection, obtain a LLM-generated summary of the collection,\n    a set of statistics for each field (such as unique categories), and a set of mappings\n    from the fields to the frontend-specific fields in Elysia.\n\n    In order:\n\n    1. Evaluate all the data fields and groups/statistics of the data fields as a whole\n    2. Write a summary of the collection via an LLM\n    3. Evaluate what return types are available for this collection\n    4. For each data field in the collection, evaluate what corresponding entry goes to what field in the return type (mapping)\n    5. Save as a ELYSIA_METADATA__ collection\n\n    Args:\n        collection_name (str): The name of the collection to preprocess.\n        client_manager (ClientManager): The client manager to use.\n        min_sample_size (int): The minimum number of objects to sample from the collection to evaluate the statistics/summary. Optional, defaults to 10.\n        max_sample_size (int): The maximum number of objects to sample from the collection to evaluate the statistics/summary. Optional, defaults to 20.\n        num_sample_tokens (int): The number of tokens to approximately sample from the collection to evaluate the summary.\n            The preprocessor will aim to use this many tokens in the sample objects to evaluate the summary.\n            But will not exceed the maximum number of objects specified by `max_sample_size`, and always use at least `min_sample_size` objects.\n        force (bool): Whether to force the preprocessor to run even if the collection already exists. Optional, defaults to False.\n        threshold_for_missing_fields (float): The threshold for the number of missing fields in the data mapping. Optional, defaults to 0.1.\n        settings (Settings): The settings to use. Optional, defaults to the environment variables/configured settings.\n\n    Returns:\n        AsyncGenerator[dict, None]: A generator that yields dictionaries with the status updates and progress of the preprocessor.\n    \"\"\"\n\n    collection_summariser_prompt = dspy.ChainOfThought(CollectionSummariserPrompt)\n    return_type_prompt = dspy.ChainOfThought(ReturnTypePrompt)\n    data_mapping_prompt = dspy.ChainOfThought(DataMappingPrompt)\n    prompt_suggestor_prompt = dspy.ChainOfThought(PromptSuggestorPrompt)\n\n    lm = load_base_lm(settings)\n    logger = settings.logger\n    process_update = ProcessUpdate(collection_name, len(rt.specific_return_types) + 5)\n\n    if client_manager is None:\n        client_manager = ClientManager(\n            wcd_url=settings.WCD_URL, wcd_api_key=settings.WCD_API_KEY\n        )\n        close_clients_after_completion = True\n    else:\n        close_clients_after_completion = False\n\n    try:\n        # Check if the collection exists\n        async with client_manager.connect_to_async_client() as client:\n            if not await client.collections.exists(collection_name):\n                raise Exception(f\"Collection {collection_name} does not exist!\")\n\n        # Check if the preprocessed collection exists\n        if (\n            await preprocessed_collection_exists_async(collection_name, client_manager)\n            and not force\n        ):\n            logger.info(f\"Preprocessed metadata for {collection_name} already exists!\")\n            return\n\n        # Get the collection and its properties\n        async with client_manager.connect_to_async_client() as client:\n            collection = client.collections.get(collection_name)\n            properties = await async_get_collection_data_types(client, collection_name)\n\n        # get number of items in collection\n        agg = await collection.aggregate.over_all(total_count=True)\n        len_collection: int = agg.total_count  # type: ignore\n\n        # Randomly sample sample_size objects for the summary\n        indices = random.sample(\n            range(len_collection),\n            max(min(max_sample_size, len_collection), 1),\n        )\n\n        # Get first object to estimate token count\n        obj = await collection.query.fetch_objects(limit=1, offset=indices[0])\n        token_count_0 = len(nlp(str(obj.objects[0].properties)))\n        subset_objects: list[dict] = [obj.objects[0].properties]  # type: ignore\n\n        # Get number of objects to sample to get close to num_sample_tokens\n        num_sample_objects = max(min_sample_size, num_sample_tokens // token_count_0)\n\n        for index in indices[1:num_sample_objects]:\n            obj = await collection.query.fetch_objects(limit=1, offset=index)\n            subset_objects.append(obj.objects[0].properties)  # type: ignore\n\n        # Estimate number of tokens\n        logger.debug(\n            f\"Estimated token count of sample: {token_count_0*len(subset_objects)}\"\n        )\n        logger.debug(f\"Number of objects in sample: {len(subset_objects)}\")\n\n        # Summarise the collection using LLM and the subset of the data\n        summary, field_descriptions = await _summarise_collection(\n            collection_summariser_prompt,\n            properties,\n            subset_objects,\n            len_collection,\n            settings,\n            lm,\n        )\n\n        yield await process_update(\n            message=\"Generated summary of collection\",\n        )\n\n        if len_collection &gt; max_sample_size:\n            full_response = subset_objects\n        else:\n            weaviate_resp = await collection.query.fetch_objects(limit=len_collection)\n            full_response = [obj.properties for obj in weaviate_resp.objects]\n\n        # Initialise the output\n        named_vectors, vectoriser = await _find_vectorisers(collection)\n        out = {\n            \"name\": collection_name,\n            \"length\": len_collection,\n            \"summary\": summary,\n            \"index_properties\": await _evaluate_index_properties(collection),\n            \"named_vectors\": named_vectors,\n            \"vectorizer\": vectoriser,\n            \"fields\": [],\n            \"mappings\": {},\n        }\n\n        # Evaluate the summary statistics of each field\n        for property in properties:\n            out[\"fields\"].append(\n                await _evaluate_field_statistics(\n                    collection, properties, property, len_collection, full_response\n                )\n            )\n            if property in field_descriptions:\n                out[\"fields\"][-1][\"description\"] = field_descriptions[property]\n            else:\n                out[\"fields\"][-1][\"description\"] = \"\"\n\n        yield await process_update(\n            message=\"Evaluated field statistics\",\n        )\n\n        return_types = await _evaluate_return_types(\n            return_type_prompt,\n            summary,\n            properties,\n            subset_objects,\n            settings,\n            lm,\n        )\n\n        yield await process_update(\n            message=\"Evaluated return types\",\n        )\n        process_update.update_total(len(return_types) + 5)\n\n        # suggest prompts\n        out[\"prompts\"] = await _suggest_prompts(\n            prompt_suggestor_prompt,\n            out,\n            subset_objects,\n            settings,\n            lm,\n        )\n\n        yield await process_update(\n            message=\"Created suggestions for prompts\",\n        )\n\n        # For each return type created above, define the mappings from the properties to the frontend types\n        mappings = {}\n        for return_type in return_types:\n            fields = rt.types_dict[return_type]\n\n            mapping = await _define_mappings(\n                data_mapping_prompt,\n                mapping_type=return_type,\n                input_fields=list(fields.keys()),\n                output_fields=list(properties.keys()),\n                properties=properties,\n                collection_information=out,\n                example_objects=subset_objects,\n                settings=settings,\n                lm=lm,\n            )\n\n            # remove any extra fields the model may have added\n            mapping = {k: v for k, v in mapping.items() if k in list(fields.keys())}\n\n            yield await process_update(\n                message=f\"Defined mappings for {return_type}\",\n            )\n\n            mappings[return_type] = mapping\n\n        new_return_types = []\n        for return_type in return_types:\n\n            # check if the `conversation_id` field is in the mapping (required for conversation type)\n            if return_type == \"conversation\" and (\n                (\n                    mappings[return_type][\"conversation_id\"] is None\n                    or mappings[return_type][\"conversation_id\"] == \"\"\n                )\n                or (\n                    mappings[return_type][\"message_id\"] is None\n                    or mappings[return_type][\"message_id\"] == \"\"\n                )\n            ):\n                continue\n\n            # If less than threshold_for_missing_fields%, keep the return type\n            num_missing = sum([m == \"\" for m in list(mappings[return_type].values())])\n            perc_correct = 1 - (num_missing / len(mappings[return_type].keys()))\n            if perc_correct &gt;= percentage_correct_threshold:\n                new_return_types.append(return_type)\n\n        # If no return types are left, fall-back to generic\n        if len(new_return_types) == 0:\n\n            # Map for generic\n            mapping = await _define_mappings(\n                data_mapping_prompt,\n                mapping_type=\"generic\",\n                input_fields=list(rt.generic.keys()),\n                output_fields=list(properties.keys()),\n                properties=properties,\n                collection_information=out,\n                example_objects=subset_objects,\n                settings=settings,\n                lm=lm,\n            )\n            yield await process_update(\n                message=\"No display types found, defined mappings for generic\",\n            )\n\n            # remove any extra fields the model may have added\n            mapping = {k: v for k, v in mapping.items() if k in list(rt.generic.keys())}\n            mappings[\"generic\"] = mapping\n\n            # re-check the threshold for missing fields on generic\n            num_missing = sum([m == \"\" for m in list(mappings[return_type].values())])\n            perc_correct = 1 - (num_missing / len(mappings[return_type].keys()))\n            if perc_correct &gt;= percentage_correct_threshold:\n                new_return_types = [\"generic\"]\n\n        # Add the mappings to the output\n        out[\"mappings\"] = {\n            return_type: mappings[return_type] for return_type in new_return_types\n        }\n\n        # always include the table return type\n        out[\"mappings\"][\"table\"] = {field: field for field in properties.keys()}\n\n        # Delete existing metadata if it exists\n        if await preprocessed_collection_exists_async(collection_name, client_manager):\n            await delete_preprocessed_collection_async(collection_name, client_manager)\n\n        # Save final metadata to a collection\n        async with client_manager.connect_to_async_client() as client:\n            if await client.collections.exists(f\"ELYSIA_METADATA__\"):\n                metadata_collection = client.collections.get(\"ELYSIA_METADATA__\")\n            else:\n                metadata_collection = await client.collections.create(\n                    f\"ELYSIA_METADATA__\",\n                    vectorizer_config=Configure.Vectorizer.none(),\n                    properties=[\n                        Property(\n                            name=\"name\",\n                            data_type=DataType.TEXT,\n                            tokenization=Tokenization.FIELD,\n                        ),\n                        Property(\n                            name=\"length\",\n                            data_type=DataType.NUMBER,\n                        ),\n                        Property(\n                            name=\"summary\",\n                            data_type=DataType.TEXT,\n                        ),\n                        Property(\n                            name=\"index_properties\",\n                            data_type=DataType.OBJECT,\n                            nested_properties=[\n                                Property(\n                                    name=\"isNullIndexed\",\n                                    data_type=DataType.BOOL,\n                                ),\n                                Property(\n                                    name=\"isLengthIndexed\",\n                                    data_type=DataType.BOOL,\n                                ),\n                                Property(\n                                    name=\"isTimestampIndexed\",\n                                    data_type=DataType.BOOL,\n                                ),\n                            ],\n                        ),\n                        Property(\n                            name=\"named_vectors\",\n                            data_type=DataType.OBJECT_ARRAY,\n                            nested_properties=[\n                                Property(\n                                    name=\"name\",\n                                    data_type=DataType.TEXT,\n                                ),\n                                Property(\n                                    name=\"vectorizer\",\n                                    data_type=DataType.TEXT,\n                                ),\n                                Property(\n                                    name=\"model\",\n                                    data_type=DataType.TEXT,\n                                ),\n                                Property(\n                                    name=\"source_properties\",\n                                    data_type=DataType.TEXT_ARRAY,\n                                ),\n                                Property(\n                                    name=\"enabled\",\n                                    data_type=DataType.BOOL,\n                                ),\n                                Property(\n                                    name=\"description\",\n                                    data_type=DataType.TEXT,\n                                ),\n                            ],\n                        ),\n                        Property(\n                            name=\"vectorizer\",\n                            data_type=DataType.OBJECT,\n                            nested_properties=[\n                                Property(name=\"vectorizer\", data_type=DataType.TEXT),\n                                Property(name=\"model\", data_type=DataType.TEXT),\n                            ],\n                        ),\n                        Property(\n                            name=\"fields\",\n                            data_type=DataType.OBJECT_ARRAY,\n                            nested_properties=[\n                                Property(\n                                    name=\"name\",\n                                    data_type=DataType.TEXT,\n                                ),\n                                Property(\n                                    name=\"type\",\n                                    data_type=DataType.TEXT,\n                                ),\n                                Property(\n                                    name=\"description\",\n                                    data_type=DataType.TEXT,\n                                ),\n                                Property(\n                                    name=\"range\",\n                                    data_type=DataType.NUMBER_ARRAY,\n                                ),\n                                Property(\n                                    name=\"date_range\",\n                                    data_type=DataType.DATE_ARRAY,\n                                ),\n                                Property(\n                                    name=\"groups\",\n                                    data_type=DataType.OBJECT_ARRAY,\n                                    nested_properties=[\n                                        Property(\n                                            name=\"value\",\n                                            data_type=DataType.TEXT,\n                                        ),\n                                        Property(name=\"count\", data_type=DataType.INT),\n                                    ],\n                                ),\n                                Property(\n                                    name=\"date_median\",\n                                    data_type=DataType.DATE,\n                                ),\n                                Property(\n                                    name=\"mean\",\n                                    data_type=DataType.NUMBER,\n                                ),\n                            ],\n                        ),\n                        # leave mappings for auto-schema generation\n                    ],\n                    inverted_index_config=Configure.inverted_index(\n                        index_null_state=True,\n                    ),\n                )\n            await metadata_collection.data.insert(out)\n\n        yield await process_update(\n            completed=True,\n            message=\"Saved metadata to Weaviate\",\n        )\n\n    except Exception as e:\n        yield await process_update(\n            error=f\"Error preprocessing collection: {str(e)}\",\n        )\n\n    finally:\n        if close_clients_after_completion:\n            await client_manager.close_clients()\n</code></pre>"},{"location":"Reference/Preprocessor/#elysia.preprocessing.collection.preprocessed_collection_exists","title":"<code>preprocessed_collection_exists(collection_name, client_manager=None)</code>","text":"<p>Check if the preprocessed collection exists in the Weaviate cluster. This function simply checks if the cached preprocessed metadata exists in the Weaviate cluster. It does so by checking if the collection name exists in the ELYSIA_METADATA__ collection.</p> <p>Parameters:</p> Name Type Description Default <code>collection_name</code> <code>str</code> <p>The name of the collection to check.</p> required <code>client_manager</code> <code>ClientManager</code> <p>The client manager to use.</p> <code>None</code> Source code in <code>elysia/preprocessing/collection.py</code> <pre><code>def preprocessed_collection_exists(\n    collection_name: str, client_manager: ClientManager | None = None\n) -&gt; bool:\n    \"\"\"\n    Check if the preprocessed collection exists in the Weaviate cluster.\n    This function simply checks if the cached preprocessed metadata exists in the Weaviate cluster.\n    It does so by checking if the collection name exists in the ELYSIA_METADATA__ collection.\n\n    Args:\n        collection_name (str): The name of the collection to check.\n        client_manager (ClientManager): The client manager to use.\n    \"\"\"\n    return asyncio_run(\n        preprocessed_collection_exists_async(collection_name, client_manager)\n    )\n</code></pre>"},{"location":"Reference/Preprocessor/#elysia.preprocessing.collection.preprocessed_collection_exists_async","title":"<code>preprocessed_collection_exists_async(collection_name, client_manager=None)</code>  <code>async</code>","text":"<p>Async version of <code>preprocessed_collection_exists</code>.</p> <p>Parameters:</p> Name Type Description Default <code>collection_name</code> <code>str</code> <p>The name of the collection to check.</p> required <code>client_manager</code> <code>ClientManager</code> <p>The client manager to use. If not provided, a new ClientManager will be created using the environment variables/configured settings.</p> <code>None</code> <p>Returns:</p> Name Type Description <code>bool</code> <code>bool</code> <p>True if the collection exists, False otherwise.</p> Source code in <code>elysia/preprocessing/collection.py</code> <pre><code>async def preprocessed_collection_exists_async(\n    collection_name: str, client_manager: ClientManager | None = None\n) -&gt; bool:\n    \"\"\"\n    Async version of `preprocessed_collection_exists`.\n\n    Args:\n        collection_name (str): The name of the collection to check.\n        client_manager (ClientManager): The client manager to use.\n            If not provided, a new ClientManager will be created using the environment variables/configured settings.\n\n    Returns:\n        bool: True if the collection exists, False otherwise.\n    \"\"\"\n    if client_manager is None:\n        client_manager = ClientManager()\n        close_clients_after_completion = True\n    else:\n        close_clients_after_completion = False\n\n    async with client_manager.connect_to_async_client() as client:\n        metadata_exists = await client.collections.exists(f\"ELYSIA_METADATA__\")\n        if not metadata_exists:\n            return False\n\n        metadata_collection = client.collections.get(\"ELYSIA_METADATA__\")\n        metadata = await metadata_collection.query.fetch_objects(\n            filters=Filter.by_property(\"name\").equal(collection_name)\n        )\n\n    if close_clients_after_completion:\n        await client_manager.close_clients()\n\n    return metadata is not None and len(metadata.objects) &gt; 0\n</code></pre>"},{"location":"Reference/Preprocessor/#elysia.preprocessing.collection.view_preprocessed_collection","title":"<code>view_preprocessed_collection(collection_name, client_manager=None)</code>","text":"<p>View a preprocessed collection. This function allows you to view the preprocessed collection generated by the preprocess function. It does so by querying the ELYSIA_METADATA__ collection.</p> <p>Parameters:</p> Name Type Description Default <code>collection_name</code> <code>str</code> <p>The name of the collection to view.</p> required <code>client_manager</code> <code>ClientManager</code> <p>The client manager to use. If not provided, a new ClientManager will be created using the environment variables/configured settings.</p> <code>None</code> <p>Returns:</p> Name Type Description <code>dict</code> <code>dict</code> <p>The preprocessed collection.</p> Source code in <code>elysia/preprocessing/collection.py</code> <pre><code>def view_preprocessed_collection(\n    collection_name: str, client_manager: ClientManager | None = None\n) -&gt; dict:\n    \"\"\"\n    View a preprocessed collection.\n    This function allows you to view the preprocessed collection generated by the preprocess function.\n    It does so by querying the ELYSIA_METADATA__ collection.\n\n    Args:\n        collection_name (str): The name of the collection to view.\n        client_manager (ClientManager): The client manager to use.\n            If not provided, a new ClientManager will be created using the environment variables/configured settings.\n\n    Returns:\n        dict: The preprocessed collection.\n    \"\"\"\n    return asyncio_run(\n        view_preprocessed_collection_async(collection_name, client_manager)\n    )\n</code></pre>"},{"location":"Reference/Preprocessor/#elysia.preprocessing.collection.view_preprocessed_collection_async","title":"<code>view_preprocessed_collection_async(collection_name, client_manager=None)</code>  <code>async</code>","text":"<p>Async version of <code>view_preprocessed_collection</code>.</p> <p>Parameters:</p> Name Type Description Default <code>collection_name</code> <code>str</code> <p>The name of the collection to view.</p> required <code>client_manager</code> <code>ClientManager</code> <p>The client manager to use. If not provided, a new ClientManager will be created using the environment variables/configured settings.</p> <code>None</code> <p>Returns:</p> Name Type Description <code>dict</code> <code>dict</code> <p>The preprocessed collection.</p> Source code in <code>elysia/preprocessing/collection.py</code> <pre><code>async def view_preprocessed_collection_async(\n    collection_name: str, client_manager: ClientManager | None = None\n) -&gt; dict:\n    \"\"\"\n    Async version of `view_preprocessed_collection`.\n\n    Args:\n        collection_name (str): The name of the collection to view.\n        client_manager (ClientManager): The client manager to use.\n            If not provided, a new ClientManager will be created using the environment variables/configured settings.\n\n    Returns:\n        dict: The preprocessed collection.\n    \"\"\"\n\n    if client_manager is None:\n        client_manager = ClientManager()\n        close_clients_after_completion = True\n    else:\n        close_clients_after_completion = False\n\n    async with client_manager.connect_to_async_client() as client:\n        metadata_name = f\"ELYSIA_METADATA__\"\n\n        # check if the collection itself exists\n        if not await client.collections.exists(collection_name):\n            raise Exception(f\"Collection {collection_name} does not exist\")\n\n        # check if the metadata collection exists\n        if not await client.collections.exists(metadata_name):\n            raise Exception(f\"Metadata collection does not exist\")\n\n        else:\n            metadata_collection = client.collections.get(metadata_name)\n            metadata = await metadata_collection.query.fetch_objects(\n                filters=Filter.by_property(\"name\").equal(collection_name),\n                limit=1,\n            )\n            if len(metadata.objects) == 0:\n                raise Exception(f\"Metadata for {collection_name} does not exist\")\n\n            properties: dict = metadata.objects[0].properties  # type: ignore\n\n    if close_clients_after_completion:\n        await client_manager.close_clients()\n\n    return properties\n</code></pre>"},{"location":"Reference/Settings/","title":"Settings","text":""},{"location":"Reference/Settings/#elysia.config.Settings","title":"<code>Settings</code>","text":"<p>Settings for Elysia. This class handles the configuration of various settings within Elysia. This includes: - The base and complex models to use. - The providers for the base and complex models. - The Weaviate cloud URL and API key. - The API keys for the providers. - The logger and logging level.</p> <p>The Settings object is set as at a default <code>settings</code> object if running Elysia as a package. You can import this via <code>elysia.config.settings</code>. This is initialised to default values from the environment variables.</p> <p>Or, you can create your own Settings object, and configure it as you wish. The Settings object can be passed to different Elysia classes and functions, such as <code>Tree</code> and <code>preprocess</code>. These will not use the global <code>settings</code> object, but instead use the Settings object you passed to them.</p> Source code in <code>elysia/config.py</code> <pre><code>class Settings:\n    \"\"\"\n    Settings for Elysia.\n    This class handles the configuration of various settings within Elysia.\n    This includes:\n    - The base and complex models to use.\n    - The providers for the base and complex models.\n    - The Weaviate cloud URL and API key.\n    - The API keys for the providers.\n    - The logger and logging level.\n\n    The Settings object is set as at a default `settings` object if running Elysia as a package.\n    You can import this via `elysia.config.settings`.\n    This is initialised to default values from the environment variables.\n\n    Or, you can create your own Settings object, and configure it as you wish.\n    The Settings object can be passed to different Elysia classes and functions, such as `Tree` and `preprocess`.\n    These will not use the global `settings` object, but instead use the Settings object you passed to them.\n    \"\"\"\n\n    def __init__(self):\n        \"\"\"\n        Initialize the settings for Elysia.\n        These are all settings initialised to None, and should be set using the `configure` method.\n        \"\"\"\n        # Default settings\n        self.SETTINGS_ID = str(random.randint(100000000000000, 999999999999999))\n\n        self.base_init()\n\n    def base_init(self):\n        self.BASE_MODEL: str | None = None\n        self.BASE_PROVIDER: str | None = None\n        self.COMPLEX_MODEL: str | None = None\n        self.COMPLEX_PROVIDER: str | None = None\n\n        self.WCD_URL: str = \"\"\n        self.WCD_API_KEY: str = \"\"\n\n        self.MODEL_API_BASE: str | None = None\n\n        self.API_KEYS: dict[str, str] = {}\n\n        self.logger = logging.getLogger(\"rich\")\n        self.logger.setLevel(logging.INFO)\n\n        # Remove any existing handlers before adding a new one\n        for handler in self.logger.handlers[:]:\n            self.logger.removeHandler(handler)\n        self.logger.addHandler(RichHandler(rich_tracebacks=True, markup=True))\n\n        self.logger.propagate = False\n        self.LOGGING_LEVEL = \"INFO\"\n        self.LOGGING_LEVEL_INT = 20\n\n        # Experimental features\n        self.USE_FEEDBACK = False\n        self.BASE_USE_REASONING = True\n        self.COMPLEX_USE_REASONING = True\n\n    def setup_app_logger(self, logger: logging.Logger):\n        \"\"\"\n        Override existing logger with the app-level logger.\n\n        Args:\n            logger (Logger): The logger to use.\n        \"\"\"\n        self.logger = logger\n        self.LOGGING_LEVEL_INT = logger.level\n        inverted_logging_mapping = {\n            v: k for k, v in logging.getLevelNamesMapping().items()\n        }\n        self.LOGGING_LEVEL = inverted_logging_mapping[self.LOGGING_LEVEL_INT]\n\n    def configure_logger(\n        self,\n        level: Literal[\n            \"DEBUG\", \"INFO\", \"WARNING\", \"ERROR\", \"CRITICAL\", \"NOTSET\"\n        ] = \"NOTSET\",\n    ):\n        \"\"\"\n        Configure the logger with a RichHandler.\n\n        Args:\n            level (Literal[\"DEBUG\", \"INFO\", \"WARNING\", \"ERROR\", \"CRITICAL\", \"NOTSET\"]): The logging level to use.\n        \"\"\"\n        self.logger.setLevel(level)\n        self.LOGGING_LEVEL = level\n        self.LOGGING_LEVEL_INT = logging.getLevelNamesMapping()[level]\n\n    def set_api_key(self, api_key: str, api_key_name: str) -&gt; None:\n        self.API_KEYS[api_key_name] = api_key\n\n    def get_api_key(self, api_key_name: str) -&gt; str:\n        return self.API_KEYS[api_key_name]\n\n    def load_settings(self, settings: dict):\n        for item in settings:\n            setattr(self, item, settings[item])\n\n        # self.logger = logging.getLogger(\"rich\")\n        # self.logger.setLevel(self.LOGGING_LEVEL)\n        # for handler in self.logger.handlers[:]:\n        #     self.logger.removeHandler(handler)\n        # self.logger.addHandler(RichHandler(rich_tracebacks=True, markup=True))\n\n    @classmethod\n    def from_smart_setup(cls):\n        settings = cls()\n        settings.set_from_env()\n        settings.smart_setup()\n        return settings\n\n    @classmethod\n    def from_env_vars(cls):\n        settings = cls()\n        settings.set_from_env()\n        return settings\n\n    def set_from_env(self):\n        self.BASE_MODEL = os.getenv(\"BASE_MODEL\", None)\n        self.COMPLEX_MODEL = os.getenv(\"COMPLEX_MODEL\", None)\n        self.BASE_PROVIDER = os.getenv(\"BASE_PROVIDER\", None)\n        self.COMPLEX_PROVIDER = os.getenv(\"COMPLEX_PROVIDER\", None)\n        self.MODEL_API_BASE = os.getenv(\"MODEL_API_BASE\", None)\n        self.LOGGING_LEVEL = os.getenv(\"LOGGING_LEVEL\", \"NOTSET\")\n        self.set_api_keys_from_env()\n\n    def set_api_keys_from_env(self):\n\n        self.WCD_URL = os.getenv(\n            \"WEAVIATE_URL\",\n            os.getenv(\"WCD_URL\", \"\"),\n        )\n        self.WCD_API_KEY = os.getenv(\n            \"WEAVIATE_API_KEY\",\n            os.getenv(\"WCD_API_KEY\", \"\"),\n        )\n\n        self.API_KEYS = {\n            env_var.lower(): os.getenv(env_var, \"\")\n            for env_var in os.environ\n            if is_api_key(env_var) and env_var.lower() != \"wcd_api_key\"\n        }\n        for api_key in self.API_KEYS:\n            self.set_api_key(self.API_KEYS[api_key], api_key)\n\n    def smart_setup(self):\n\n        # Check if the user has set the base model etc from the environment variables\n        if os.getenv(\"BASE_MODEL\", None):\n            self.BASE_MODEL = os.getenv(\"BASE_MODEL\")\n        if os.getenv(\"COMPLEX_MODEL\", None):\n            self.COMPLEX_MODEL = os.getenv(\"COMPLEX_MODEL\")\n        if os.getenv(\"BASE_PROVIDER\", None):\n            self.BASE_PROVIDER = os.getenv(\"BASE_PROVIDER\")\n        if os.getenv(\"COMPLEX_PROVIDER\", None):\n            self.COMPLEX_PROVIDER = os.getenv(\"COMPLEX_PROVIDER\")\n\n        self.MODEL_API_BASE = os.getenv(\"MODEL_API_BASE\", None)\n        self.LOGGING_LEVEL = os.getenv(\"LOGGING_LEVEL\", \"NOTSET\")\n\n        self.set_api_keys_from_env()\n\n        # check what API keys are available\n        if (\n            self.BASE_MODEL is None\n            or self.COMPLEX_MODEL is None\n            or self.BASE_PROVIDER is None\n            or self.COMPLEX_PROVIDER is None\n        ):\n            if os.getenv(\"OPENROUTER_API_KEY\", None):\n                # use gemini 2.0 flash\n                self.BASE_PROVIDER = \"openrouter/google\"\n                self.COMPLEX_PROVIDER = \"openrouter/google\"\n                self.BASE_MODEL = \"gemini-2.0-flash-001\"\n                self.COMPLEX_MODEL = \"gemini-2.5-flash\"\n            elif os.getenv(\"GEMINI_API_KEY\", None):\n                # use gemini 2.0 flash\n                self.BASE_PROVIDER = \"gemini\"\n                self.COMPLEX_PROVIDER = \"gemini\"\n                self.BASE_MODEL = \"gemini-2.0-flash-001\"\n                self.COMPLEX_MODEL = \"gemini-2.5-flash\"\n            elif os.getenv(\"OPENAI_API_KEY\", None):\n                # use gpt family\n                self.BASE_PROVIDER = \"openai\"\n                self.COMPLEX_PROVIDER = \"openai\"\n                self.BASE_MODEL = \"gpt-4.1-mini\"\n                self.COMPLEX_MODEL = \"gpt-4.1\"\n            elif os.getenv(\"ANTHROPIC_API_KEY\", None):\n                # use claude family\n                self.BASE_PROVIDER = \"anthropic\"\n                self.COMPLEX_PROVIDER = \"anthropic\"\n                self.BASE_MODEL = \"claude-3-5-haiku-latest\"\n                self.COMPLEX_MODEL = \"claude-sonnet-4-0\"\n\n    def configure(\n        self,\n        replace: bool = False,\n        **kwargs,\n    ):\n        \"\"\"\n        Configure the settings for Elysia for the current Settings object.\n\n        Args:\n            replace (bool): Whether to override the current settings with the new settings.\n                When this is True, all existing settings are removed, and only the new settings are used.\n                Defaults to False.\n            **kwargs (str): One or more of the following:\n                - base_model (str): The base model to use. e.g. \"gpt-4o-mini\"\n                - complex_model (str): The complex model to use. e.g. \"gpt-4o\"\n                - base_provider (str): The provider to use for base_model. E.g. \"openai\" or \"openrouter/openai\"\n                - complex_provider (str): The provider to use for complex_model. E.g. \"openai\" or \"openrouter/openai\"\n                - model_api_base (str): The API base to use.\n                - wcd_url (str): The Weaviate cloud URL to use.\n                - wcd_api_key (str): The Weaviate cloud API key to use.\n                - logging_level (str): The logging level to use. e.g. \"DEBUG\", \"INFO\", \"WARNING\", \"ERROR\", \"CRITICAL\"\n                - use_feedback (bool): EXPERIMENTAL. Whether to use feedback from previous runs of the tree.\n                    If True, the tree will use TrainingUpdate objects that have been saved in previous runs of the decision tree.\n                    These are implemented via few-shot examples for the decision node.\n                    They are collected in the 'feedback' collection (ELYSIA_FEEDBACK__).\n                    Relevant examples are retrieved from the collection based on searching the collection via the user's prompt.\n                - base_use_reasoning (bool): Whether to use reasoning output for the base model.\n                    If True, the model will generate reasoning before coming to its solution.\n                - complex_use_reasoning (bool): Whether to use reasoning output for the complex model.\n                    If True, the model will generate reasoning before coming to its solution.\n                - Additional API keys to set. E.g. `openai_apikey=\"...\"`, if this argument ends with `apikey` or `api_key`,\n                    it will be added to the `API_KEYS` dictionary.\n\n        \"\"\"\n        if replace:\n            self.base_init()\n\n        # convert all kwargs to lowercase for consistency\n        kwargs = {kwarg.lower(): kwargs[kwarg] for kwarg in kwargs}\n\n        if \"base_model\" in kwargs:\n            if \"base_provider\" not in kwargs:\n                raise ValueError(\n                    \"Provider must be specified if base_model is set. \"\n                    \"E.g. `elysia.config.configure(base_model='gpt-4o-mini', base_provider='openai')`\"\n                )\n\n            if kwargs[\"base_provider\"] == \"ollama\" and (\n                not kwargs[\"model_api_base\"] or \"MODEL_API_BASE\" not in dir(self)\n            ):\n                raise ValueError(\n                    \"Using local models via ollama requires MODEL_API_BASE to be set. \"\n                    \"This is likely to be http://localhost:11434. \"\n                    \"e.g. `elysia.config.configure(model_api_base='http://localhost:11434')`\"\n                )\n\n            self.BASE_MODEL = kwargs[\"base_model\"]\n            self.BASE_PROVIDER = kwargs[\"base_provider\"]\n\n            kwargs.pop(\"base_model\")\n            kwargs.pop(\"base_provider\")\n\n            # self.load_base_dspy_model()\n\n        if \"complex_model\" in kwargs:\n            if \"complex_provider\" not in kwargs:\n                raise ValueError(\n                    \"Provider must be specified if complex_model is set. \"\n                    \"E.g. `elysia.config.configure(complex_model='gpt-4o', complex_provider='openai')`\"\n                )\n\n            if kwargs[\"complex_provider\"] == \"ollama\" and (\n                not kwargs[\"model_api_base\"] or \"MODEL_API_BASE\" not in dir(self)\n            ):\n                raise ValueError(\n                    \"Using local models via ollama requires MODEL_API_BASE to be set. \"\n                    \"This is likely to be http://localhost:11434. \"\n                    \"e.g. `elysia.config.configure(model_api_base='http://localhost:11434')`\"\n                )\n\n            self.COMPLEX_MODEL = kwargs[\"complex_model\"]\n            self.COMPLEX_PROVIDER = kwargs[\"complex_provider\"]\n\n            kwargs.pop(\"complex_model\")\n            kwargs.pop(\"complex_provider\")\n\n            # self.load_complex_dspy_model()\n\n        if \"model_api_base\" in kwargs:\n            self.MODEL_API_BASE = kwargs[\"model_api_base\"]\n            kwargs.pop(\"model_api_base\")\n\n        if \"wcd_url\" in kwargs:\n            self.WCD_URL = kwargs[\"wcd_url\"]\n            kwargs.pop(\"wcd_url\")\n\n        if \"wcd_api_key\" in kwargs:\n            self.WCD_API_KEY = kwargs[\"wcd_api_key\"]\n            kwargs.pop(\"wcd_api_key\")\n\n        if \"weaviate_url\" in kwargs:\n            self.WCD_URL = kwargs[\"weaviate_url\"]\n            kwargs.pop(\"weaviate_url\")\n\n        if \"weaviate_api_key\" in kwargs:\n            self.WCD_API_KEY = kwargs[\"weaviate_api_key\"]\n            kwargs.pop(\"weaviate_api_key\")\n\n        if \"logging_level\" in kwargs or \"logger_level\" in kwargs:\n\n            self.LOGGING_LEVEL = (\n                kwargs[\"logging_level\"]\n                if \"logging_level\" in kwargs\n                else kwargs[\"logger_level\"]\n            )\n            self.LOGGING_LEVEL_INT = logging.getLevelNamesMapping()[self.LOGGING_LEVEL]\n            self.logger.setLevel(self.LOGGING_LEVEL)\n            if \"logging_level\" in kwargs:\n                kwargs.pop(\"logging_level\")\n            if \"logger_level\" in kwargs:\n                kwargs.pop(\"logger_level\")\n            if \"logging_level_int\" in kwargs:\n                kwargs.pop(\"logging_level_int\")\n            if \"logger_level_int\" in kwargs:\n                kwargs.pop(\"logger_level_int\")\n\n        if \"logging_level_int\" in kwargs or \"logger_level_int\" in kwargs:\n\n            self.LOGGING_LEVEL_INT = (\n                kwargs[\"logging_level_int\"]\n                if \"logging_level_int\" in kwargs\n                else kwargs[\"logger_level_int\"]\n            )\n            self.LOGGING_LEVEL = {\n                v: k for k, v in logging.getLevelNamesMapping().items()\n            }[self.LOGGING_LEVEL_INT]\n            self.logger.setLevel(self.LOGGING_LEVEL)\n\n        if \"settings_id\" in kwargs:\n            self.SETTINGS_ID = kwargs[\"settings_id\"]\n            kwargs.pop(\"settings_id\")\n\n        if \"use_feedback\" in kwargs:\n            self.USE_FEEDBACK = kwargs[\"use_feedback\"]\n            kwargs.pop(\"use_feedback\")\n\n        if \"base_use_reasoning\" in kwargs:\n            self.BASE_USE_REASONING = kwargs[\"base_use_reasoning\"]\n            kwargs.pop(\"base_use_reasoning\")\n\n        if \"complex_use_reasoning\" in kwargs:\n            self.COMPLEX_USE_REASONING = kwargs[\"complex_use_reasoning\"]\n            kwargs.pop(\"complex_use_reasoning\")\n\n        if \"api_keys\" in kwargs and isinstance(kwargs[\"api_keys\"], dict):\n            for key, value in kwargs[\"api_keys\"].items():\n                self.set_api_key(value, key)\n            kwargs.pop(\"api_keys\")\n\n        # remainder of kwargs are API keys or saved there\n        removed_kwargs = []\n        for key, value in kwargs.items():\n            if is_api_key(key):\n                self.set_api_key(value, key)\n                removed_kwargs.append(key)\n\n        for key in removed_kwargs:\n            kwargs.pop(key)\n\n        # remaining kwargs are not API keys\n        if len(kwargs) &gt; 0:\n            self.logger.warning(\n                \"Unknown arguments to configure: \" + \", \".join(kwargs.keys())\n            )\n\n    def __repr__(self) -&gt; str:\n        out = \"\"\n        if \"BASE_MODEL\" in dir(self) and self.BASE_MODEL is not None:\n            out += f\"Base model: {self.BASE_MODEL}\\n\"\n        else:\n            out += \"Base model: not set\\n\"\n        if \"COMPLEX_MODEL\" in dir(self) and self.COMPLEX_MODEL is not None:\n            out += f\"Complex model: {self.COMPLEX_MODEL}\\n\"\n        else:\n            out += \"Complex model: not set\\n\"\n        if \"BASE_PROVIDER\" in dir(self) and self.BASE_PROVIDER is not None:\n            out += f\"Base provider: {self.BASE_PROVIDER}\\n\"\n        else:\n            out += \"Base provider: not set\\n\"\n        if \"COMPLEX_PROVIDER\" in dir(self) and self.COMPLEX_PROVIDER is not None:\n            out += f\"Complex provider: {self.COMPLEX_PROVIDER}\\n\"\n        else:\n            out += \"Complex provider: not set\\n\"\n        if \"MODEL_API_BASE\" in dir(self):\n            out += f\"Model API base: {self.MODEL_API_BASE}\\n\"\n        else:\n            out += \"Model API base: not set\\n\"\n        return out\n\n    def to_json(self):\n        return {\n            item: getattr(self, item)\n            for item in dir(self)\n            if not item.startswith(\"_\")\n            and not isinstance(getattr(self, item), Callable)\n            and item not in [\"BASE_MODEL_LM\", \"COMPLEX_MODEL_LM\", \"logger\"]\n        }\n\n    @classmethod\n    def from_json(cls, json_data: dict):\n        settings = cls()\n        for item in json_data:\n            if item not in [\"logger\"]:\n                setattr(settings, item, json_data[item])\n\n        settings.logger.setLevel(settings.LOGGING_LEVEL)\n\n        return settings\n\n    def check(self):\n        return {\n            \"base_model\": self.BASE_MODEL is not None and self.BASE_MODEL != \"\",\n            \"base_provider\": self.BASE_PROVIDER is not None\n            and self.BASE_PROVIDER != \"\",\n            \"complex_model\": self.COMPLEX_MODEL is not None\n            and self.COMPLEX_MODEL != \"\",\n            \"complex_provider\": self.COMPLEX_PROVIDER is not None\n            and self.COMPLEX_PROVIDER != \"\",\n            \"wcd_url\": self.WCD_URL != \"\",\n            \"wcd_api_key\": self.WCD_API_KEY != \"\",\n        }\n</code></pre>"},{"location":"Reference/Settings/#elysia.config.Settings.__init__","title":"<code>__init__()</code>","text":"<p>Initialize the settings for Elysia. These are all settings initialised to None, and should be set using the <code>configure</code> method.</p> Source code in <code>elysia/config.py</code> <pre><code>def __init__(self):\n    \"\"\"\n    Initialize the settings for Elysia.\n    These are all settings initialised to None, and should be set using the `configure` method.\n    \"\"\"\n    # Default settings\n    self.SETTINGS_ID = str(random.randint(100000000000000, 999999999999999))\n\n    self.base_init()\n</code></pre>"},{"location":"Reference/Settings/#elysia.config.Settings.configure","title":"<code>configure(replace=False, **kwargs)</code>","text":"<p>Configure the settings for Elysia for the current Settings object.</p> <p>Parameters:</p> Name Type Description Default <code>replace</code> <code>bool</code> <p>Whether to override the current settings with the new settings. When this is True, all existing settings are removed, and only the new settings are used. Defaults to False.</p> <code>False</code> <code>**kwargs</code> <code>str</code> <p>One or more of the following: - base_model (str): The base model to use. e.g. \"gpt-4o-mini\" - complex_model (str): The complex model to use. e.g. \"gpt-4o\" - base_provider (str): The provider to use for base_model. E.g. \"openai\" or \"openrouter/openai\" - complex_provider (str): The provider to use for complex_model. E.g. \"openai\" or \"openrouter/openai\" - model_api_base (str): The API base to use. - wcd_url (str): The Weaviate cloud URL to use. - wcd_api_key (str): The Weaviate cloud API key to use. - logging_level (str): The logging level to use. e.g. \"DEBUG\", \"INFO\", \"WARNING\", \"ERROR\", \"CRITICAL\" - use_feedback (bool): EXPERIMENTAL. Whether to use feedback from previous runs of the tree.     If True, the tree will use TrainingUpdate objects that have been saved in previous runs of the decision tree.     These are implemented via few-shot examples for the decision node.     They are collected in the 'feedback' collection (ELYSIA_FEEDBACK__).     Relevant examples are retrieved from the collection based on searching the collection via the user's prompt. - base_use_reasoning (bool): Whether to use reasoning output for the base model.     If True, the model will generate reasoning before coming to its solution. - complex_use_reasoning (bool): Whether to use reasoning output for the complex model.     If True, the model will generate reasoning before coming to its solution. - Additional API keys to set. E.g. <code>openai_apikey=\"...\"</code>, if this argument ends with <code>apikey</code> or <code>api_key</code>,     it will be added to the <code>API_KEYS</code> dictionary.</p> <code>{}</code> Source code in <code>elysia/config.py</code> <pre><code>def configure(\n    self,\n    replace: bool = False,\n    **kwargs,\n):\n    \"\"\"\n    Configure the settings for Elysia for the current Settings object.\n\n    Args:\n        replace (bool): Whether to override the current settings with the new settings.\n            When this is True, all existing settings are removed, and only the new settings are used.\n            Defaults to False.\n        **kwargs (str): One or more of the following:\n            - base_model (str): The base model to use. e.g. \"gpt-4o-mini\"\n            - complex_model (str): The complex model to use. e.g. \"gpt-4o\"\n            - base_provider (str): The provider to use for base_model. E.g. \"openai\" or \"openrouter/openai\"\n            - complex_provider (str): The provider to use for complex_model. E.g. \"openai\" or \"openrouter/openai\"\n            - model_api_base (str): The API base to use.\n            - wcd_url (str): The Weaviate cloud URL to use.\n            - wcd_api_key (str): The Weaviate cloud API key to use.\n            - logging_level (str): The logging level to use. e.g. \"DEBUG\", \"INFO\", \"WARNING\", \"ERROR\", \"CRITICAL\"\n            - use_feedback (bool): EXPERIMENTAL. Whether to use feedback from previous runs of the tree.\n                If True, the tree will use TrainingUpdate objects that have been saved in previous runs of the decision tree.\n                These are implemented via few-shot examples for the decision node.\n                They are collected in the 'feedback' collection (ELYSIA_FEEDBACK__).\n                Relevant examples are retrieved from the collection based on searching the collection via the user's prompt.\n            - base_use_reasoning (bool): Whether to use reasoning output for the base model.\n                If True, the model will generate reasoning before coming to its solution.\n            - complex_use_reasoning (bool): Whether to use reasoning output for the complex model.\n                If True, the model will generate reasoning before coming to its solution.\n            - Additional API keys to set. E.g. `openai_apikey=\"...\"`, if this argument ends with `apikey` or `api_key`,\n                it will be added to the `API_KEYS` dictionary.\n\n    \"\"\"\n    if replace:\n        self.base_init()\n\n    # convert all kwargs to lowercase for consistency\n    kwargs = {kwarg.lower(): kwargs[kwarg] for kwarg in kwargs}\n\n    if \"base_model\" in kwargs:\n        if \"base_provider\" not in kwargs:\n            raise ValueError(\n                \"Provider must be specified if base_model is set. \"\n                \"E.g. `elysia.config.configure(base_model='gpt-4o-mini', base_provider='openai')`\"\n            )\n\n        if kwargs[\"base_provider\"] == \"ollama\" and (\n            not kwargs[\"model_api_base\"] or \"MODEL_API_BASE\" not in dir(self)\n        ):\n            raise ValueError(\n                \"Using local models via ollama requires MODEL_API_BASE to be set. \"\n                \"This is likely to be http://localhost:11434. \"\n                \"e.g. `elysia.config.configure(model_api_base='http://localhost:11434')`\"\n            )\n\n        self.BASE_MODEL = kwargs[\"base_model\"]\n        self.BASE_PROVIDER = kwargs[\"base_provider\"]\n\n        kwargs.pop(\"base_model\")\n        kwargs.pop(\"base_provider\")\n\n        # self.load_base_dspy_model()\n\n    if \"complex_model\" in kwargs:\n        if \"complex_provider\" not in kwargs:\n            raise ValueError(\n                \"Provider must be specified if complex_model is set. \"\n                \"E.g. `elysia.config.configure(complex_model='gpt-4o', complex_provider='openai')`\"\n            )\n\n        if kwargs[\"complex_provider\"] == \"ollama\" and (\n            not kwargs[\"model_api_base\"] or \"MODEL_API_BASE\" not in dir(self)\n        ):\n            raise ValueError(\n                \"Using local models via ollama requires MODEL_API_BASE to be set. \"\n                \"This is likely to be http://localhost:11434. \"\n                \"e.g. `elysia.config.configure(model_api_base='http://localhost:11434')`\"\n            )\n\n        self.COMPLEX_MODEL = kwargs[\"complex_model\"]\n        self.COMPLEX_PROVIDER = kwargs[\"complex_provider\"]\n\n        kwargs.pop(\"complex_model\")\n        kwargs.pop(\"complex_provider\")\n\n        # self.load_complex_dspy_model()\n\n    if \"model_api_base\" in kwargs:\n        self.MODEL_API_BASE = kwargs[\"model_api_base\"]\n        kwargs.pop(\"model_api_base\")\n\n    if \"wcd_url\" in kwargs:\n        self.WCD_URL = kwargs[\"wcd_url\"]\n        kwargs.pop(\"wcd_url\")\n\n    if \"wcd_api_key\" in kwargs:\n        self.WCD_API_KEY = kwargs[\"wcd_api_key\"]\n        kwargs.pop(\"wcd_api_key\")\n\n    if \"weaviate_url\" in kwargs:\n        self.WCD_URL = kwargs[\"weaviate_url\"]\n        kwargs.pop(\"weaviate_url\")\n\n    if \"weaviate_api_key\" in kwargs:\n        self.WCD_API_KEY = kwargs[\"weaviate_api_key\"]\n        kwargs.pop(\"weaviate_api_key\")\n\n    if \"logging_level\" in kwargs or \"logger_level\" in kwargs:\n\n        self.LOGGING_LEVEL = (\n            kwargs[\"logging_level\"]\n            if \"logging_level\" in kwargs\n            else kwargs[\"logger_level\"]\n        )\n        self.LOGGING_LEVEL_INT = logging.getLevelNamesMapping()[self.LOGGING_LEVEL]\n        self.logger.setLevel(self.LOGGING_LEVEL)\n        if \"logging_level\" in kwargs:\n            kwargs.pop(\"logging_level\")\n        if \"logger_level\" in kwargs:\n            kwargs.pop(\"logger_level\")\n        if \"logging_level_int\" in kwargs:\n            kwargs.pop(\"logging_level_int\")\n        if \"logger_level_int\" in kwargs:\n            kwargs.pop(\"logger_level_int\")\n\n    if \"logging_level_int\" in kwargs or \"logger_level_int\" in kwargs:\n\n        self.LOGGING_LEVEL_INT = (\n            kwargs[\"logging_level_int\"]\n            if \"logging_level_int\" in kwargs\n            else kwargs[\"logger_level_int\"]\n        )\n        self.LOGGING_LEVEL = {\n            v: k for k, v in logging.getLevelNamesMapping().items()\n        }[self.LOGGING_LEVEL_INT]\n        self.logger.setLevel(self.LOGGING_LEVEL)\n\n    if \"settings_id\" in kwargs:\n        self.SETTINGS_ID = kwargs[\"settings_id\"]\n        kwargs.pop(\"settings_id\")\n\n    if \"use_feedback\" in kwargs:\n        self.USE_FEEDBACK = kwargs[\"use_feedback\"]\n        kwargs.pop(\"use_feedback\")\n\n    if \"base_use_reasoning\" in kwargs:\n        self.BASE_USE_REASONING = kwargs[\"base_use_reasoning\"]\n        kwargs.pop(\"base_use_reasoning\")\n\n    if \"complex_use_reasoning\" in kwargs:\n        self.COMPLEX_USE_REASONING = kwargs[\"complex_use_reasoning\"]\n        kwargs.pop(\"complex_use_reasoning\")\n\n    if \"api_keys\" in kwargs and isinstance(kwargs[\"api_keys\"], dict):\n        for key, value in kwargs[\"api_keys\"].items():\n            self.set_api_key(value, key)\n        kwargs.pop(\"api_keys\")\n\n    # remainder of kwargs are API keys or saved there\n    removed_kwargs = []\n    for key, value in kwargs.items():\n        if is_api_key(key):\n            self.set_api_key(value, key)\n            removed_kwargs.append(key)\n\n    for key in removed_kwargs:\n        kwargs.pop(key)\n\n    # remaining kwargs are not API keys\n    if len(kwargs) &gt; 0:\n        self.logger.warning(\n            \"Unknown arguments to configure: \" + \", \".join(kwargs.keys())\n        )\n</code></pre>"},{"location":"Reference/Settings/#elysia.config.Settings.configure_logger","title":"<code>configure_logger(level='NOTSET')</code>","text":"<p>Configure the logger with a RichHandler.</p> <p>Parameters:</p> Name Type Description Default <code>level</code> <code>Literal['DEBUG', 'INFO', 'WARNING', 'ERROR', 'CRITICAL', 'NOTSET']</code> <p>The logging level to use.</p> <code>'NOTSET'</code> Source code in <code>elysia/config.py</code> <pre><code>def configure_logger(\n    self,\n    level: Literal[\n        \"DEBUG\", \"INFO\", \"WARNING\", \"ERROR\", \"CRITICAL\", \"NOTSET\"\n    ] = \"NOTSET\",\n):\n    \"\"\"\n    Configure the logger with a RichHandler.\n\n    Args:\n        level (Literal[\"DEBUG\", \"INFO\", \"WARNING\", \"ERROR\", \"CRITICAL\", \"NOTSET\"]): The logging level to use.\n    \"\"\"\n    self.logger.setLevel(level)\n    self.LOGGING_LEVEL = level\n    self.LOGGING_LEVEL_INT = logging.getLevelNamesMapping()[level]\n</code></pre>"},{"location":"Reference/Settings/#elysia.config.Settings.setup_app_logger","title":"<code>setup_app_logger(logger)</code>","text":"<p>Override existing logger with the app-level logger.</p> <p>Parameters:</p> Name Type Description Default <code>logger</code> <code>Logger</code> <p>The logger to use.</p> required Source code in <code>elysia/config.py</code> <pre><code>def setup_app_logger(self, logger: logging.Logger):\n    \"\"\"\n    Override existing logger with the app-level logger.\n\n    Args:\n        logger (Logger): The logger to use.\n    \"\"\"\n    self.logger = logger\n    self.LOGGING_LEVEL_INT = logger.level\n    inverted_logging_mapping = {\n        v: k for k, v in logging.getLevelNamesMapping().items()\n    }\n    self.LOGGING_LEVEL = inverted_logging_mapping[self.LOGGING_LEVEL_INT]\n</code></pre>"},{"location":"Reference/Settings/#elysia.config.configure","title":"<code>configure(**kwargs)</code>","text":"<p>Configure the settings for Elysia for the global settings object.</p> <p>Parameters:</p> Name Type Description Default <code>**kwargs</code> <code>str</code> <p>One or more of the following: - base_model (str): The base model to use. e.g. \"gpt-4o-mini\" - complex_model (str): The complex model to use. e.g. \"gpt-4o\" - base_provider (str): The provider to use for base_model. E.g. \"openai\" or \"openrouter/openai\" - complex_provider (str): The provider to use for complex_model. E.g. \"openai\" or \"openrouter/openai\" - model_api_base (str): The API base to use. - wcd_url (str): The Weaviate cloud URL to use. - wcd_api_key (str): The Weaviate cloud API key to use. - logging_level (str): The logging level to use. e.g. \"DEBUG\", \"INFO\", \"WARNING\", \"ERROR\", \"CRITICAL\" - use_feedback (bool): EXPERIMENTAL. Whether to use feedback from previous runs of the tree.     If True, the tree will use TrainingUpdate objects that have been saved in previous runs of the decision tree.     These are implemented via few-shot examples for the decision node.     They are collected in the 'feedback' collection (ELYSIA_FEEDBACK__).     Relevant examples are retrieved from the collection based on searching the collection via the user's prompt. - Additional API keys to set. E.g. <code>openai_apikey=\"...\"</code>, if this argument ends with <code>apikey</code> or <code>api_key</code>,     it will be added to the <code>API_KEYS</code> dictionary.</p> <code>{}</code> Source code in <code>elysia/config.py</code> <pre><code>def configure(**kwargs) -&gt; None:\n    \"\"\"\n    Configure the settings for Elysia for the global settings object.\n\n    Args:\n        **kwargs (str): One or more of the following:\n            - base_model (str): The base model to use. e.g. \"gpt-4o-mini\"\n            - complex_model (str): The complex model to use. e.g. \"gpt-4o\"\n            - base_provider (str): The provider to use for base_model. E.g. \"openai\" or \"openrouter/openai\"\n            - complex_provider (str): The provider to use for complex_model. E.g. \"openai\" or \"openrouter/openai\"\n            - model_api_base (str): The API base to use.\n            - wcd_url (str): The Weaviate cloud URL to use.\n            - wcd_api_key (str): The Weaviate cloud API key to use.\n            - logging_level (str): The logging level to use. e.g. \"DEBUG\", \"INFO\", \"WARNING\", \"ERROR\", \"CRITICAL\"\n            - use_feedback (bool): EXPERIMENTAL. Whether to use feedback from previous runs of the tree.\n                If True, the tree will use TrainingUpdate objects that have been saved in previous runs of the decision tree.\n                These are implemented via few-shot examples for the decision node.\n                They are collected in the 'feedback' collection (ELYSIA_FEEDBACK__).\n                Relevant examples are retrieved from the collection based on searching the collection via the user's prompt.\n            - Additional API keys to set. E.g. `openai_apikey=\"...\"`, if this argument ends with `apikey` or `api_key`,\n                it will be added to the `API_KEYS` dictionary.\n\n    \"\"\"\n    settings.configure(**kwargs)\n</code></pre>"},{"location":"Reference/Tree/","title":"Tree","text":""},{"location":"Reference/Tree/#elysia.tree.tree.Tree","title":"<code>Tree</code>","text":"<p>The main class for the Elysia decision tree. Calling this method will execute the decision tree based on the user's prompt, and available collections and tools.</p> Source code in <code>elysia/tree/tree.py</code> <pre><code>class Tree:\n    \"\"\"\n    The main class for the Elysia decision tree.\n    Calling this method will execute the decision tree based on the user's prompt, and available collections and tools.\n    \"\"\"\n\n    def __init__(\n        self,\n        branch_initialisation: Literal[\n            \"default\", \"one_branch\", \"multi_branch\", \"empty\"\n        ] = \"default\",\n        style: str = \"No style provided.\",\n        agent_description: str = \"No description provided.\",\n        end_goal: str = \"No end goal provided.\",\n        user_id: str | None = None,\n        conversation_id: str | None = None,\n        low_memory: bool = False,\n        use_elysia_collections: bool = True,\n        settings: Settings | None = None,\n    ) -&gt; None:\n        \"\"\"\n        Args:\n            branch_initialisation (str): The initialisation method for the branches,\n                currently supports some pre-defined initialisations: \"multi_branch\", \"one_branch\".\n                Set to \"empty\" to start with no branches and to add them, and the tools, yourself.\n            style (str): The writing style of the agent. Automatically set for \"multi_branch\" and \"one_branch\" initialisation, but overrided if non-empty.\n            agent_description (str): The description of the agent. Automatically set for \"multi_branch\" and \"one_branch\" initialisation, but overrided if non-empty.\n            end_goal (str): The end goal of the agent. Automatically set for \"multi_branch\" and \"one_branch\" initialisation, but overrided if non-empty.\n            user_id (str): The id of the user, e.g. \"123-456\",\n                unneeded outside of user management/hosting Elysia app\n            conversation_id (str): The id of the conversation, e.g. \"123-456\",\n                unneeded outside of conversation management/hosting Elysia app\n            low_memory (bool): Whether to run the tree in low memory mode.\n                If True, the tree will not load the (dspy) models within the tree.\n                Set to False for normal operation.\n            use_elysia_collections (bool): Whether to use weaviate collections as processed by Elysia.\n                If False, the tree will not use the processed collections.\n            settings (Settings): The settings for the tree, an object of elysia.Settings.\n                This is automatically set to the environment settings if not provided.\n        \"\"\"\n        # Define base variables of the tree\n        if user_id is None:\n            self.user_id = str(uuid.uuid4())\n        else:\n            self.user_id = user_id\n\n        if conversation_id is None:\n            self.conversation_id = str(uuid.uuid4())\n        else:\n            self.conversation_id = conversation_id\n\n        if settings is None:\n            self.settings = environment_settings\n        else:\n            assert isinstance(\n                settings, Settings\n            ), \"settings must be an instance of Settings\"\n            self.settings = settings\n\n        self.use_elysia_collections = use_elysia_collections\n\n        # Initialise some tree variables\n        self.decision_nodes: dict[str, DecisionNode] = {}\n        self.decision_history = [[]]\n        self.tree_index = -1\n        self.suggestions = []\n        self.actions_called = {}\n        self.query_id_to_prompt = {}\n        self.prompt_to_query_id = {}\n        self.retrieved_objects = []\n        self.store_retrieved_objects = False\n        self.conversation_title = None\n        self.low_memory = low_memory\n        self._base_lm = None\n        self._complex_lm = None\n        self._config_modified = False\n        self.root = None\n\n        # Define the inputs to prompts\n        self.tree_data = TreeData(\n            environment=Environment(),\n            collection_data=CollectionData(\n                collection_names=[], logger=self.settings.logger\n            ),\n            atlas=Atlas(\n                style=style,\n                agent_description=agent_description,\n                end_goal=end_goal,\n            ),\n            recursion_limit=5,\n            settings=self.settings,\n        )\n\n        # initialise the timers\n        self.tracker = Tracker(\n            tracker_names=[\"decision_node\"],\n            logger=self.settings.logger,\n        )\n\n        # Set the initialisations\n        self.tools = {}\n        self.set_branch_initialisation(branch_initialisation)\n        self.tree_data.atlas.style = style\n        self.tree_data.atlas.agent_description = agent_description\n        self.tree_data.atlas.end_goal = end_goal\n\n        self.tools[\"forced_text_response\"] = ForcedTextResponse()\n\n        # some variables for storing feedback\n        self.action_information = []\n        self.history = {}\n        self.training_updates = []\n\n        # -- Get the root node and construct the tree\n        self._get_root()\n        self.tree = {}\n        self._construct_tree(self.root, self.tree)\n\n        # initialise the returner (for frontend)\n        self.returner = TreeReturner(\n            user_id=self.user_id,\n            conversation_id=self.conversation_id,\n        )\n\n        # Print the tree if required\n        self.settings.logger.debug(\n            \"Initialised tree with the following decision nodes:\"\n        )\n        for decision_node in self.decision_nodes.values():\n            self.settings.logger.debug(\n                f\"  - [magenta]{decision_node.id}[/magenta]: {list(decision_node.options.keys())}\"\n            )\n\n    @property\n    def base_lm(self) -&gt; dspy.LM:\n        if self.low_memory:\n            return load_base_lm(self.settings)\n        else:\n            if self._base_lm is None:\n                self._base_lm = load_base_lm(self.settings)\n            return self._base_lm\n\n    @property\n    def complex_lm(self) -&gt; dspy.LM:\n        if self.low_memory:\n            return load_complex_lm(self.settings)\n        else:\n            if self._complex_lm is None:\n                self._complex_lm = load_complex_lm(self.settings)\n            return self._complex_lm\n\n    def multi_branch_init(self) -&gt; None:\n        self.add_branch(\n            root=True,\n            branch_id=\"base\",\n            instruction=\"\"\"\n            Choose a base-level task based on the user's prompt and available information.\n            You can search, which includes aggregating or querying information - this should be used if the user needs (more) information.\n            You can end the conversation by choosing text response, or summarise some retrieved information.\n            Base your decision on what information is available and what the user is asking for - you can search multiple times if needed,\n            but you should not search if you have already found all the information you need.\n            \"\"\",\n            status=\"Choosing a base-level task...\",\n        )\n        self.add_tool(branch_id=\"base\", tool=CitedSummarizer)\n        self.add_tool(branch_id=\"base\", tool=FakeTextResponse)\n\n        self.add_branch(\n            root=False,\n            branch_id=\"search\",\n            from_branch_id=\"base\",\n            instruction=\"\"\"\n            Choose between querying the knowledge base via semantic/keyword search, or aggregating information by performing operations, on the knowledge base.\n            Querying is when the user is looking for specific information related to the content of the dataset, requiring a specific search query. This is for retrieving specific information via a _query_, similar to a search engine.\n            Aggregating is when the user is looking for a specific operations on the dataset, such as summary statistics of the quantity of some items. Aggregation can also include grouping information by some property and returning statistics about the groups.\n            \"\"\",\n            description=f\"\"\"\n            Search the knowledge base. This should be used when the user is lacking information for this particular prompt. This retrieves information only and provides no output to the user except the information.\n            Choose to query (semantic or keyword search on a knowledge base), or aggregate information (calculate properties/summary statistics/averages and operations on the knowledge bases).\n            \"\"\",\n            status=\"Searching the knowledge base...\",\n        )\n        self.add_tool(branch_id=\"search\", tool=Query, summariser_in_tree=True)\n        self.add_tool(branch_id=\"search\", tool=Aggregate)\n        self.add_tool(branch_id=\"base\", tool=Visualise)\n        self.add_tool(SummariseItems, branch_id=\"search\", from_tool_ids=[\"query\"])\n\n    def one_branch_init(self) -&gt; None:\n        self.add_branch(\n            root=True,\n            branch_id=\"base\",\n            instruction=\"\"\"\n            Choose a base-level task based on the user's prompt and available information.\n            Decide based on the tools you have available as well as their descriptions.\n            Read them thoroughly and match the actions to the user prompt.\n            \"\"\",\n            status=\"Choosing a base-level task...\",\n        )\n        self.add_tool(branch_id=\"base\", tool=CitedSummarizer)\n        self.add_tool(branch_id=\"base\", tool=FakeTextResponse)\n        self.add_tool(branch_id=\"base\", tool=Aggregate)\n        self.add_tool(branch_id=\"base\", tool=Query, summariser_in_tree=True)\n        self.add_tool(branch_id=\"base\", tool=Visualise)\n        self.add_tool(SummariseItems, branch_id=\"base\", from_tool_ids=[\"query\"])\n\n    def empty_init(self) -&gt; None:\n        self.add_branch(\n            root=True,\n            branch_id=\"base\",\n            instruction=\"\"\"\n            Choose a base-level task based on the user's prompt and available information.\n            Decide based on the tools you have available as well as their descriptions.\n            Read them thoroughly and match the actions to the user prompt.\n            \"\"\",\n            status=\"Choosing a base-level task...\",\n        )\n\n    def clear_tree(self) -&gt; None:\n        self.decision_nodes = {}\n        self.root = None\n\n    def set_branch_initialisation(self, initialisation: str | None) -&gt; None:\n        self.clear_tree()\n\n        if (\n            initialisation is None\n            or initialisation == \"\"\n            or initialisation == \"one_branch\"\n            or initialisation == \"default\"\n        ):\n            self.one_branch_init()\n        elif initialisation == \"multi_branch\":\n            self.multi_branch_init()\n        elif initialisation == \"empty\":\n            self.empty_init()\n        else:\n            raise ValueError(f\"Invalid branch initialisation: {initialisation}\")\n\n        self.branch_initialisation = initialisation\n\n    def smart_setup(self) -&gt; None:\n        \"\"\"\n        Configures the `settings` object of the tree with the `Settings.smart_setup()` method.\n        \"\"\"\n\n        self.settings = deepcopy(self.settings)\n        self.settings.SETTINGS_ID = str(uuid.uuid4())\n        self._config_modified = True\n        self.settings.smart_setup()\n\n    def configure(self, **kwargs) -&gt; None:\n        \"\"\"\n        Configure the tree with new settings.\n        Wrapper for the settings.configure() method.\n        Will not affect any settings preceding this (e.g. in TreeManager).\n        \"\"\"\n        self.settings = deepcopy(self.settings)\n        self.settings.SETTINGS_ID = str(uuid.uuid4())\n        self._config_modified = True\n        self.tree_data.settings = self.settings\n        self.settings.configure(**kwargs)\n\n    def change_style(self, style: str) -&gt; None:\n        self.tree_data.atlas.style = style\n        self._config_modified = True\n\n    def change_agent_description(self, agent_description: str) -&gt; None:\n        self.tree_data.atlas.agent_description = agent_description\n        self._config_modified = True\n\n    def change_end_goal(self, end_goal: str) -&gt; None:\n        self.tree_data.atlas.end_goal = end_goal\n        self._config_modified = True\n\n    def _get_root(self) -&gt; None:\n        for decision_node in self.decision_nodes.values():\n            if decision_node.root:\n                if self.root is not None and self.root != decision_node.id:\n                    raise ValueError(\"Multiple root decision nodes found\")\n\n                self.root = decision_node.id\n\n        if self.root is None:\n            raise ValueError(\"No root decision node found\")\n\n    def _construct_tree(\n        self, node_id: str | None, tree: dict, branch: bool = True\n    ) -&gt; dict:\n        if node_id is None:\n            raise ValueError(\"Node ID is None\")\n\n        decision_node = self.decision_nodes[node_id]\n\n        # Ensure the order of the keys in each option is the same\n        key_order = [\n            \"name\",\n            \"id\",\n            \"description\",\n            \"instruction\",\n            \"reasoning\",\n            \"branch\",\n            \"options\",\n        ]\n\n        # Set the base node information\n        tree[\"name\"] = node_id.capitalize().replace(\"_\", \" \")\n        tree[\"id\"] = node_id\n        if node_id == self.root:\n            tree[\"description\"] = \"\"\n        tree[\"instruction\"] = remove_whitespace(\n            decision_node.instruction.replace(\"\\n\", \"\")\n        )\n        tree[\"reasoning\"] = \"\"\n        tree[\"branch\"] = branch\n        tree[\"options\"] = {}\n\n        # Order the top-level dictionary\n        tree = {key: tree[key] for key in key_order if key in tree}\n\n        # Initialize all options first with ordered dictionaries\n        for option in decision_node.options:\n            tree[\"options\"][option] = {\n                \"description\": remove_whitespace(\n                    str(decision_node.options[option][\"description\"]).replace(\"\\n\", \"\")\n                )\n            }\n\n        # Then handle the recursive cases\n        for option in decision_node.options:\n            next_node: DecisionNode | None = decision_node.options[option][\"next\"]  # type: ignore\n            if (\n                decision_node.options[option][\"action\"] is not None\n                and next_node is None\n            ):\n                tree[\"options\"][option][\"name\"] = option.capitalize().replace(\"_\", \" \")\n                tree[\"options\"][option][\"id\"] = option\n                tree[\"options\"][option][\"instruction\"] = \"\"\n                tree[\"options\"][option][\"reasoning\"] = \"\"\n                tree[\"options\"][option][\"branch\"] = False\n                tree[\"options\"][option][\"options\"] = {}\n\n            elif next_node is not None:\n                tree[\"options\"][option] = self._construct_tree(\n                    next_node.id,\n                    tree[\"options\"][option],\n                    branch=decision_node.options[option][\"action\"] is None,\n                )\n            else:\n                tree[\"options\"][option][\"name\"] = option.capitalize().replace(\"_\", \" \")\n                tree[\"options\"][option][\"id\"] = option\n                tree[\"options\"][option][\"instruction\"] = \"\"\n                tree[\"options\"][option][\"reasoning\"] = \"\"\n                tree[\"options\"][option][\"branch\"] = True\n                tree[\"options\"][option][\"options\"] = {}\n\n            # Order each option's dictionary\n            tree[\"options\"][option] = {\n                key: tree[\"options\"][option][key]\n                for key in key_order\n                if key in tree[\"options\"][option]\n            }\n\n        return tree\n\n    async def set_collection_names(\n        self,\n        collection_names: list[str],\n        client_manager: ClientManager,\n    ) -&gt; None:\n        self.settings.logger.debug(\n            f\"Using the following collection names: {collection_names}\"\n        )\n\n        collection_names = await self.tree_data.set_collection_names(\n            collection_names, client_manager\n        )\n\n    def _remove_empty_branches(self) -&gt; list[str]:\n        empty_branches = []\n        for branch_id, branch in self.decision_nodes.items():\n            if len(branch.options) == 0:\n                empty_branches.append(branch_id)\n\n        for branch_id in self.decision_nodes:\n            for empty_branch in empty_branches:\n                self.decision_nodes[branch_id].remove_option(empty_branch)\n\n        for empty_branch in empty_branches:\n            if empty_branch != self.root:\n                self.settings.logger.warning(\n                    f\"Removing empty branch: {empty_branch} \"\n                    \"No tools are attached to this branch, so it has been removed. \"\n                    f\"To add a tool to this branch, use .add_tool(tool_name, branch_id={empty_branch})\"\n                )\n                del self.decision_nodes[empty_branch]\n\n        return empty_branches\n\n    def _get_function_inputs(self, tool_name: str, inputs: dict) -&gt; dict:\n        if tool_name in self.tools:\n            # any non-provided inputs are set to the default\n            default_inputs = self.tools[tool_name].get_default_inputs()\n            for default_input_name in default_inputs:\n                if default_input_name not in inputs:\n                    inputs[default_input_name] = default_inputs[default_input_name]\n\n            # if the inputs match the 'schema' of keys: description, type, default, value, then take the value\n            for input_name in inputs:\n                if (\n                    isinstance(inputs[input_name], dict)\n                    and \"value\" in inputs[input_name]\n                ):\n                    inputs[input_name] = inputs[input_name][\"value\"]\n\n            return inputs\n        else:\n            return {}\n\n    async def _check_rules(\n        self, branch_id: str, client_manager: ClientManager\n    ) -&gt; tuple[list[str], dict]:\n        branch = self.decision_nodes[branch_id]\n        nodes_with_rules_met = []\n        rule_tool_inputs = {}\n        for function_name, option in branch.options.items():\n            if function_name not in self.tools:\n                pass\n            elif \"run_if_true\" in dir(self.tools[function_name]):\n                rule_met, rule_tool_inputs = await self.tools[\n                    function_name\n                ].run_if_true(\n                    tree_data=self.tree_data,\n                    client_manager=client_manager,\n                    base_lm=self.base_lm,\n                    complex_lm=self.complex_lm,\n                )\n                if rule_met:\n                    nodes_with_rules_met.append(function_name)\n                    if rule_tool_inputs is None or rule_tool_inputs == {}:\n                        rule_tool_inputs[function_name] = self.tools[\n                            function_name\n                        ].get_default_inputs()\n                    else:\n                        rule_tool_inputs[function_name] = rule_tool_inputs\n\n        return nodes_with_rules_met, rule_tool_inputs\n\n    def set_conversation_id(self, conversation_id: str) -&gt; None:\n        self.conversation_id = conversation_id\n        self.returner.conversation_id = conversation_id\n\n    def set_user_id(self, user_id: str) -&gt; None:\n        self.user_id = user_id\n        self.returner.user_id = user_id\n\n    def soft_reset(self) -&gt; None:\n        # conversation history is not reset\n        # environment is not reset\n        if self.low_memory:\n            self.history = {}\n\n        self.recursion_counter = 0\n        self.tree_data.num_trees_completed = 0\n        self.decision_history = [[]]\n        self.training_updates = []\n        self.tree_data.soft_reset()\n        self.action_information = []\n        self.tree_index += 1\n        self.retrieved_objects = []\n        self.returner.set_tree_index(self.tree_index)\n\n    def save_history(self, query_id: str, time_taken_seconds: float) -&gt; None:\n        \"\"\"\n        What the tree did, results for saving feedback.\n        \"\"\"\n        training_update = deepcopy(\n            [update.to_json() for update in self.training_updates]\n        )\n\n        self.history[query_id] = {\n            \"num_trees_completed\": self.tree_data.num_trees_completed,\n            \"tree_data\": deepcopy(self.tree_data),\n            \"action_information\": deepcopy(self.action_information),\n            \"decision_history\": [\n                item for sublist in deepcopy(self.decision_history) for item in sublist\n            ],\n            \"base_lm_used\": self.settings.BASE_MODEL,\n            \"complex_lm_used\": self.settings.COMPLEX_MODEL,\n            \"time_taken_seconds\": time_taken_seconds,\n            \"training_updates\": training_update,\n            \"initialisation\": f\"{self.branch_initialisation}\",\n        }\n        # can reset training updates now\n        self.training_updates = []\n\n    def set_start_time(self) -&gt; None:\n        self.start_time = time.time()\n\n    def add_tool(\n        self,\n        tool,\n        branch_id: str | None = None,\n        from_tool_ids: list[str] = [],\n        root: bool = False,\n        **kwargs,\n    ) -&gt; None:\n        \"\"\"\n        Add a Tool to a branch or on top of an existing tool.\n        The tool needs to be an instance of the Tool class.\n\n        Args:\n            tool (Tool): The tool to add\n            branch_id (str): The id of the branch to add the tool to\n                If not specified, the tool will be added to the root branch\n            from_tool_ids (list[str]): The ids of the tools to add the new tool after\n                If not specified, the tool will be added to the base of the branch\n            root (bool): Whether the tool is the root tool\n                If not specified, the tool will be added to the root branch\n            kwargs (any): Additional keyword arguments to pass to the initialisation of the tool\n\n        Example 1:\n            To add a tool, `Query`, to a branch called 'search', you can do this:\n            ```python\n            tree.add_tool(Query, branch_id=\"search\")\n            ```\n            This will add the `Query` tool to the branch 'search'.\n            If the branch 'search' doesn't exist, it will raise an error.\n            To add a branch, use the `.add_branch()` method.\n\n\n        Example 2:\n            Assume your tree has a \"search\" branch with two tools: 'query' and 'aggregate'.\n            You can add a tool, `CheckResult`, after the 'query' tool like this:\n            ```python\n            tree.add_tool(CheckResult, branch_id=\"search\", from_tool_ids=[\"query\"])\n            ```\n            This will add the `CheckResult` tool to the \"search\" branch, after the 'query' tool.\n            So the \"search\" branch will still only have two options: 'query' and 'aggregate'.\n            But after 'query', there will be a new option for the `CheckResult` tool.\n\n        Example 3:\n            You can add a tool, `SendEmail`, after the `CheckResult` (from Example 2) tool like this:\n            ```python\n            tree.add_tool(SendEmail, from_tool_ids=[\"query\", \"check_result\"], root=True)\n            ```\n            It will add an additional option to the root branch, after the 'query' and 'check_result' tools.\n        \"\"\"\n\n        if (\n            inspect.getfullargspec(tool.__init__).varkw is None\n            or inspect.getfullargspec(tool.__call__).varkw is None\n        ):\n            raise TypeError(\"tool __init__ and __call__ must accept **kwargs\")\n\n        if not inspect.isasyncgenfunction(tool.__call__):\n            raise TypeError(\n                \"__call__ must be an async generator function. \"\n                \"I.e. it must yield objects.\"\n            )\n\n        if isinstance(tool, Tool):\n            tool_instance = tool\n        else:\n            tool_instance = tool(\n                logger=self.settings.logger,\n                **kwargs,\n            )\n\n        if not isinstance(tool_instance, Tool):\n            raise TypeError(\"tool must be an instance of the Tool class\")\n\n        if \"__call__\" not in dir(tool_instance):\n            raise TypeError(\"tool must be callable (have a __call__ method)\")\n\n        if \"__init__\" not in dir(tool_instance):\n            raise TypeError(\"tool must have an __init__ method\")\n\n        if hasattr(tool_instance, \"is_tool_available\"):\n            if not inspect.iscoroutinefunction(tool_instance.is_tool_available):\n                raise TypeError(\n                    \"is_tool_available must be an async function that returns a single boolean value\"\n                )\n\n        if hasattr(tool_instance, \"run_if_true\"):\n            if not inspect.iscoroutinefunction(tool_instance.run_if_true):\n                raise TypeError(\n                    \"run_if_true must be an async function that returns a single boolean value\"\n                )\n\n        if root:\n            if branch_id is not None:\n                self.settings.logger.warning(\n                    f\"In .add_tool(), `root` is True, so `branch_id` ('{branch_id}') will be ignored. \"\n                    f\"Tool: '{tool_instance.name}' will be added to the root branch ('{self.root}').\"\n                )\n            branch_id = self.root\n\n        if branch_id is None:\n            branch_id = self.root\n\n        if branch_id not in self.decision_nodes:\n            raise ValueError(\n                f\"Branch '{branch_id}' not found. Use .add_branch() to add a branch before adding a tool. \"\n                f\"Or, set `root=True` to add the tool to the root branch ('{self.root}').\"\n            )\n\n        current_decision_node = self.decision_nodes[branch_id]\n        for from_tool_id in from_tool_ids:\n            if isinstance(current_decision_node, DecisionNode):\n                if from_tool_id not in current_decision_node.options:\n                    raise ValueError(\n                        f\"Tool '{from_tool_id}' not found in branch '{branch_id}'. \"\n                        f\"Available options are: {list(current_decision_node.options.keys())}\"\n                    )\n\n                current_decision_node = current_decision_node.options[from_tool_id][\n                    \"next\"\n                ]\n\n        self.tools[tool_instance.name] = tool_instance\n\n        if from_tool_ids == []:\n            self.decision_nodes[branch_id].add_option(\n                id=tool_instance.name,\n                description=tool_instance.description,\n                inputs=tool_instance.inputs,\n                action=self.tools[tool_instance.name],\n                end=tool_instance.end,\n                status=tool_instance.status,\n            )\n        else:\n\n            new_branch_id = branch_id\n            for from_tool_id in from_tool_ids:\n                new_branch_id += f\".{from_tool_id}\"\n\n            # only create a new decision node if one doesn't exist here\n            if new_branch_id not in self.decision_nodes:\n                decision_node = DecisionNode(\n                    id=new_branch_id,\n                    instruction=f\"Choose one of the actions based on their descriptions and the user prompt.\",\n                    options={},\n                    root=False,\n                    logger=self.settings.logger,\n                    use_elysia_collections=self.use_elysia_collections,\n                )\n                self.decision_nodes[new_branch_id] = decision_node\n\n                prev_branch_id = branch_id\n                for from_tool_id in from_tool_ids[:-1]:\n                    prev_branch_id += f\".{from_tool_id}\"\n\n                self.decision_nodes[prev_branch_id].options[from_tool_ids[-1]][\n                    \"next\"\n                ] = self.decision_nodes[new_branch_id]\n\n            # add the tool to the new decision node\n            self.decision_nodes[new_branch_id].add_option(\n                id=tool_instance.name,\n                description=tool_instance.description,\n                inputs=tool_instance.inputs,\n                action=self.tools[tool_instance.name],\n                end=tool_instance.end,\n                status=tool_instance.status,\n            )\n\n        self.tracker.add_tracker(tool_instance.name)\n\n        # reconstruct tree\n        self._get_root()\n        self.tree = {}\n        self._construct_tree(self.root, self.tree)\n\n    def remove_tool(\n        self,\n        tool_name: str,\n        branch_id: str | None = None,\n        from_tool_ids: list[str] = [],\n        root: bool = False,\n    ) -&gt; None:\n        \"\"\"\n        Remove a Tool from a branch.\n\n        Args:\n            tool_name (str): The name of the tool to remove.\n            branch_id (str): The id of the branch to remove the tool from,\n                if not specified, the tool will be removed from the root branch.\n            from_tool_ids (list[str]): The ids of the tools to which precedes the tool to remove.\n            root (bool): Whether the branch the tool is in is the root branch.\n        \"\"\"\n        if root:\n            if branch_id is not None:\n                self.settings.logger.warning(\n                    f\"In .add_tool(), `root` is True, so `branch_id` ('{branch_id}') will be ignored. \"\n                    f\"Tool: '{tool_name}' will be removed from the root branch ('{self.root}').\"\n                )\n            branch_id = self.root\n\n        if branch_id is None:\n            branch_id = self.root\n\n        if branch_id not in self.decision_nodes:\n            raise ValueError(f\"Branch {branch_id} not found.\")\n\n        if (\n            tool_name not in self.decision_nodes[branch_id].options\n            and from_tool_ids == []\n        ):\n            raise ValueError(f\"Tool {tool_name} not found in branch {branch_id}.\")\n\n        current_decision_node = self.decision_nodes[branch_id]\n        for from_tool_id in from_tool_ids:\n            if isinstance(current_decision_node, DecisionNode):\n                if from_tool_id not in current_decision_node.options:\n                    raise ValueError(\n                        f\"Tool '{from_tool_id}' not found in branch '{current_decision_node.id}'. \"\n                        f\"Available options are: {list(current_decision_node.options.keys())}\"\n                    )\n                current_decision_node = current_decision_node.options[from_tool_id][\n                    \"next\"\n                ]\n\n        if (\n            isinstance(current_decision_node, DecisionNode)\n            and tool_name not in current_decision_node.options\n        ):\n            raise ValueError(\n                f\"Tool '{tool_name}' not found in branch '{current_decision_node.id}'. \"\n                f\"Available options are: {list(current_decision_node.options.keys())}\"\n            )\n\n        if from_tool_ids == []:\n            self.decision_nodes[branch_id].remove_option(tool_name)\n        else:\n            tool_branch_id = branch_id\n            for from_tool_id in from_tool_ids:\n                tool_branch_id += f\".{from_tool_id}\"\n            tool_branch_id += f\".{tool_name}\"\n\n            prev_branch_id = branch_id\n            for from_tool_id in from_tool_ids:\n                prev_branch_id += f\".{from_tool_id}\"\n\n            self.decision_nodes[prev_branch_id].remove_option(tool_name)\n            if self.decision_nodes[prev_branch_id].options == {}:\n                del self.decision_nodes[prev_branch_id]\n                stem_branch_id = prev_branch_id[: prev_branch_id.rfind(\".\")]\n                for stem_branch_option in self.decision_nodes[\n                    stem_branch_id\n                ].options.values():\n                    if (\n                        stem_branch_option[\"next\"] is not None\n                        and isinstance(stem_branch_option[\"next\"], DecisionNode)\n                        and stem_branch_option[\"next\"].id == prev_branch_id\n                    ):\n                        stem_branch_option[\"next\"] = None\n\n            if (\n                tool_branch_id in self.decision_nodes\n                and self.decision_nodes[tool_branch_id].options != {}\n            ):\n                self.settings.logger.warning(\n                    f\"The following tools stem from '{tool_branch_id}', \"\n                    f\"and have also been removed: {list(self.decision_nodes[tool_branch_id].options.keys())}\"\n                )\n\n            # find any decision nodes that stem from this\n            nodes_to_remove = []\n            for decision_node_id in self.decision_nodes:\n                if decision_node_id.startswith(tool_branch_id):\n                    if decision_node_id != tool_branch_id:\n                        self.settings.logger.warning(\n                            f\"Decision node '{decision_node_id}' stems from '{tool_branch_id}'. \"\n                            f\"Removing tool '{tool_name}' has also removed '{decision_node_id}'.\"\n                        )\n                    nodes_to_remove.append(decision_node_id)\n\n            for decision_node_id in nodes_to_remove:\n                del self.decision_nodes[decision_node_id]\n\n        del self.tools[tool_name]\n        self.tracker.remove_tracker(tool_name)\n\n        # reconstruct tree\n        self._get_root()\n        self.tree = {}\n        self._construct_tree(self.root, self.tree)\n\n    def add_branch(\n        self,\n        branch_id: str,\n        instruction: str,\n        description: str = \"\",\n        root: bool = False,\n        from_branch_id: str = \"\",\n        from_tool_ids: list[str] = [],\n        status: str = \"\",\n    ) -&gt; None:\n        \"\"\"\n        Add a branch to the tree.\n\n        args:\n            branch_id (str): The id of the branch being added.\n            instruction (str): The general instruction for the branch, what is this branch containing?\n                What kind of tools or actions are being decided on this branch?\n                Only displayed to the decision maker when this branch is chosen.\n            description (str): A description of the branch, if it is to be chosen from a previous branch.\n                How does the model know whether to choose this branch or not?\n            root (bool): Whether this is the root branch, i.e. the beginning of the tree.\n            from_branch_id (str): The id of the branch that this branch is stemming from.\n            from_tool_ids (list[str]): The ids of the tools that precede this branch being added (after the `from_branch_id` branch).\n            status (str): The status message to be displayed when this branch is chosen.\n        \"\"\"\n        if not root and description == \"\":\n            raise ValueError(\"Description is required for non-root branches.\")\n        if not root and from_branch_id == \"\":\n            raise ValueError(\n                \"`from_branch_id` is required for non-root branches. \"\n                \"Set `root=True` to create a root branch or choose where this branch stems from.\"\n            )\n        if root and description != \"\":\n            self.settings.logger.warning(f\"Description is not used for root branches. \")\n            description = \"\"\n\n        if root and from_branch_id != \"\":\n            self.settings.logger.warning(\n                \"`from_branch_id` is not used for root branches. \"\n                \"(As this is the root branch, it does not stem from any other branch.)\"\n                \"If you wish this to be stemming from a previous branch, set `root=False`.\"\n            )\n            from_branch_id = \"\"\n\n        if status == \"\":\n            status = f\"Running {branch_id}...\"\n\n        decision_node = DecisionNode(\n            id=branch_id,\n            instruction=instruction,\n            options={},\n            root=root,\n            logger=self.settings.logger,\n            use_elysia_collections=self.use_elysia_collections,\n        )\n        self.decision_nodes[branch_id] = decision_node\n\n        if not root:\n\n            if from_tool_ids == []:\n                self.decision_nodes[from_branch_id].add_option(\n                    id=branch_id,\n                    description=description,\n                    inputs={},\n                    action=None,\n                    end=False,\n                    status=status,\n                    next=self.decision_nodes[branch_id],\n                )\n\n            else:\n\n                current_decision_node = self.decision_nodes[from_branch_id]\n                for from_tool_id in from_tool_ids:\n                    if isinstance(current_decision_node, DecisionNode):\n                        if from_tool_id not in current_decision_node.options:\n                            raise ValueError(\n                                f\"Tool '{from_tool_id}' not found in branch '{from_branch_id}'. \"\n                                f\"Available options are: {list(current_decision_node.options.keys())}\"\n                            )\n                        current_decision_node = current_decision_node.options[\n                            from_tool_id\n                        ][\"next\"]\n\n                new_branch_id = from_branch_id\n                for from_tool_id in from_tool_ids:\n                    new_branch_id += f\".{from_tool_id}\"\n\n                # only create a new decision node if one doesn't exist here\n                if new_branch_id not in self.decision_nodes:\n                    decision_node = DecisionNode(\n                        id=new_branch_id,\n                        instruction=f\"Choose one of the actions based on their descriptions and the user prompt.\",\n                        options={},\n                        root=False,\n                        logger=self.settings.logger,\n                        use_elysia_collections=self.use_elysia_collections,\n                    )\n                    self.decision_nodes[new_branch_id] = decision_node\n\n                    prev_branch_id = branch_id\n                    for from_tool_id in from_tool_ids[:-1]:\n                        prev_branch_id += f\".{from_tool_id}\"\n\n                    self.decision_nodes[prev_branch_id].options[from_tool_ids[-1]][\n                        \"next\"\n                    ] = self.decision_nodes[new_branch_id]\n\n                # add the tool to the new decision node\n                self.decision_nodes[new_branch_id].add_option(\n                    id=branch_id,\n                    description=description,\n                    inputs={},\n                    action=None,\n                    end=False,\n                    status=status,\n                    next=self.decision_nodes[branch_id],\n                )\n\n        if root and (self.root is not None):\n            # replace root branch with this one\n            self.decision_nodes[self.root] = decision_node\n            self.settings.logger.debug(\n                f\"Replacing root branch '{self.root}' with '{branch_id}'.\"\n            )\n            old_root = self.root\n            self.root = branch_id\n            self.remove_branch(old_root)\n\n        # reconstruct tree\n        self._get_root()\n        self.tree = {}\n        self._construct_tree(self.root, self.tree)\n\n    def remove_branch(self, branch_id: str) -&gt; None:\n        \"\"\"\n        Remove a branch from the tree.\n\n        Args:\n            branch_id (str): The id of the branch to remove\n        \"\"\"\n        # Validate branch exists\n        if branch_id not in self.decision_nodes:\n            self.settings.logger.warning(\n                f\"Branch {branch_id} not found, nothing to remove.\"\n            )\n            return\n\n        # Special handling for root node\n        if (\n            branch_id == self.root\n            and sum(1 for node in self.decision_nodes.values() if node.root) == 1\n        ):\n            self.settings.logger.error(\n                \"Cannot remove root branch if there is only one root branch.\"\n            )\n            raise ValueError(\n                \"Cannot remove the root branch when there is only one root branch. \"\n                \"Create a new root branch via .add_branch(..., root=True) first. \"\n                \"(You could be trying to replace a root branch with the same ID as the one you are trying to remove. \"\n                \"Try a different name for the new root branch.)\"\n            )\n\n        for decision_node_id in self.decision_nodes:\n            self.decision_nodes[decision_node_id].remove_option(branch_id)\n\n        if branch_id in self.decision_nodes:\n            del self.decision_nodes[branch_id]\n\n        # reconstruct tree\n        self._get_root()\n        self.tree = {}\n        self._construct_tree(self.root, self.tree)\n\n    def view(\n        self,\n        indent: int = 0,\n        prefix: str = \"\",\n        max_width: int = 80,\n        tree_dict: dict | None = None,\n    ):\n        \"\"\"\n        Format a tree dictionary into a nice hierarchical text representation.\n\n        Args:\n            tree_dict: The tree dictionary to format\n            indent: Current indentation level\n            prefix: Prefix for the current line (for tree structure visualization)\n            max_width: Maximum width for text wrapping\n\n        Returns:\n            str: Formatted tree string\n        \"\"\"\n        if tree_dict is None:\n            tree_dict = self.tree\n\n        result = []\n\n        name = tree_dict.get(\"name\", \"Unknown\")\n        node_id = tree_dict.get(\"id\", \"\")\n        description = tree_dict.get(\"description\", \"\")\n        is_branch = tree_dict.get(\"branch\", False)\n\n        indent_str = \"  \" * indent\n        node_line = (\n            f\"{indent_str}{prefix}\ud83d\udcc1 {name}\"\n            if is_branch\n            else f\"{indent_str}{prefix}\ud83d\udd27 {name}\"\n        )\n\n        result.append(node_line)\n\n        if description:\n            desc_indent = len(indent_str) + 4  # Extra space for description\n            available_width = max_width - desc_indent\n\n            wrapped_desc = textwrap.fill(\n                description,\n                width=available_width,\n                initial_indent=\"\",\n                subsequent_indent=\"\",\n            )\n\n            for i, line in enumerate(wrapped_desc.split(\"\\n\")):\n                if i == 0:\n                    result.append(f\"{indent_str}    \ud83d\udcac {line}\")\n                else:\n                    result.append(f\"{indent_str}       {line}\")\n\n            result.append(\"\")\n\n        options = tree_dict.get(\"options\", {})\n        if options:\n            option_items = list(options.items())\n            for i, (key, option) in enumerate(option_items):\n                is_last = i == len(option_items) - 1\n                child_prefix = \"\u2514\u2500\u2500 \" if is_last else \"\u251c\u2500\u2500 \"\n                child_result = self.view(\n                    indent + 1, child_prefix, max_width, tree_dict=option\n                )\n                result.append(child_result)\n\n                if indent == 0 and not is_last:\n                    result.append(\"\")\n\n        return \"\\n\".join(result)\n\n    @property\n    def conversation_history(self):\n        return self.tree_data.conversation_history\n\n    @property\n    def environment(self):\n        return self.tree_data.environment\n\n    async def create_conversation_title_async(self) -&gt; str:\n        \"\"\"\n        Create a title for the tree (async) using the base LM.\n        Also assigns the `conversation_title` attribute to the tree.\n\n        Returns:\n            (str): The title for the tree.\n        \"\"\"\n        with ElysiaKeyManager(self.settings):\n            self.conversation_title = await create_conversation_title(\n                self.tree_data.conversation_history, self.base_lm\n            )\n        return self.conversation_title\n\n    def create_conversation_title(self) -&gt; str:\n        \"\"\"\n        Create a title for the tree using the base LM.\n        Also assigns the `conversation_title` attribute to the tree.\n\n        Returns:\n            (str): The title for the tree.\n        \"\"\"\n        return asyncio_run(self.create_conversation_title_async())\n\n    async def get_follow_up_suggestions_async(\n        self, context: str | None = None, num_suggestions: int = 2\n    ) -&gt; list[str]:\n        \"\"\"\n        Get follow-up suggestions for the current user prompt via a base model LLM call.\n\n        E.g., if the user asks \"What was the most recent Github Issue?\",\n            and the results show a message from 'Jane Doe',\n            the follow-up suggestions might be \"What other issues did Jane Doe work on?\"\n\n        Args:\n            context (str | None): A description of the type of follow-up questions to suggest\n            num_suggestions (int): The number of follow-up suggestions to return (length of the list output)\n\n        Returns:\n            (list[str]): A list of follow-up suggestions\n        \"\"\"\n        with ElysiaKeyManager(self.settings):\n            suggestions = await get_follow_up_suggestions(\n                self.tree_data,\n                self.suggestions,\n                self.base_lm,\n                context=context,\n                num_suggestions=num_suggestions,\n            )\n        if suggestions != []:\n            self.settings.logger.debug(f\"Follow-up suggestions: {suggestions}\")\n        else:\n            self.settings.logger.error(\"No follow-up suggestions found.\")\n\n        self.suggestions.extend(suggestions)\n        return suggestions\n\n    def get_follow_up_suggestions(\n        self,\n        context: str | None = None,\n        num_suggestions: int = 2,\n    ) -&gt; list[str]:\n        \"\"\"\n        Get follow-up suggestions for the current user prompt via a base model LLM call (sync wrapper for get_follow_up_suggestions_async).\n\n        E.g., if the user asks \"What was the most recent Github Issue?\",\n            and the results show a message from 'Jane Doe',\n            the follow-up suggestions might be \"What other issues did Jane Doe work on?\"\n\n        Args:\n            context (str | None): A description of the type of follow-up questions to suggest\n            num_suggestions (int): The number of follow-up suggestions to return (length of the list output)\n\n        Returns:\n            (list[str]): A list of follow-up suggestions\n        \"\"\"\n        return asyncio_run(\n            self.get_follow_up_suggestions_async(context, num_suggestions)\n        )\n\n    def _update_conversation_history(self, role: str, message: str) -&gt; None:\n        if message != \"\":\n            # If the first message, create a new message\n            if len(self.tree_data.conversation_history) == 0:\n                self.tree_data.update_list(\n                    \"conversation_history\", {\"role\": role, \"content\": message}\n                )\n            # If the last message is from the same role, append to the content\n            elif self.tree_data.conversation_history[-1][\"role\"] == role:\n                if self.tree_data.conversation_history[-1][\"content\"].endswith(\" \"):\n                    self.tree_data.conversation_history[-1][\"content\"] += message\n                else:\n                    self.tree_data.conversation_history[-1][\"content\"] += \" \" + message\n            # Otherwise, create a new message\n            else:\n                self.tree_data.update_list(\n                    \"conversation_history\", {\"role\": role, \"content\": message}\n                )\n\n    def _update_actions_called(self, result: Result, decision: Decision) -&gt; None:\n        if self.user_prompt not in self.actions_called:\n            self.actions_called[self.user_prompt] = []\n            self.actions_called[self.user_prompt].append(\n                {\n                    \"name\": decision.function_name,\n                    \"inputs\": decision.function_inputs,\n                    \"reasoning\": decision.reasoning,\n                    \"output\": None,\n                }\n            )\n        if not self.low_memory:\n            self.actions_called[self.user_prompt][-1][\"output\"] = result.objects\n        else:\n            self.actions_called[self.user_prompt][-1][\"output\"] = []\n\n    def _add_refs(self, objects: list[dict], tool_name: str, name: str) -&gt; None:\n\n        if (\n            tool_name not in self.tree_data.environment.environment\n            or name not in self.tree_data.environment.environment[tool_name]\n        ):\n            len_objects = 0\n        else:\n            len_objects = len(self.tree_data.environment.environment[tool_name][name])\n\n        for i, obj in enumerate(objects):\n            if \"_REF_ID\" not in obj:\n                _REF_ID = f\"{tool_name}_{name}_{len_objects}_{i}\"\n                obj[\"_REF_ID\"] = _REF_ID\n\n    def _update_environment(self, result: Result, decision: Decision) -&gt; None:\n        \"\"\"\n        Given a yielded result from an action or otherwise, update the environment.\n        I.e. the items within the LLM knowledge base/prompt for future decisions/actions\n        All Result subclasses have their .to_json() method added to the environment.\n        As well, all Result subclasses have their llm_parse() method added to the tasks_completed.\n        \"\"\"\n\n        # add to environment (store of retrieved/called objects)\n        self.tree_data.environment.add(decision.function_name, result)\n\n        # make note of which objects were retrieved _this session_ (for returning)\n        if self.store_retrieved_objects:\n            self.retrieved_objects.append(result.to_json(mapping=False))\n\n        # add to log of actions called\n        self.action_information.append(\n            {\n                \"action_name\": decision.function_name,\n                **{key: value for key, value in result.metadata.items()},\n            }\n        )\n\n        # add to tasks completed (parsed info / train of thought for LLM)\n        self.tree_data.update_tasks_completed(\n            prompt=self.user_prompt,\n            task=decision.function_name,\n            num_trees_completed=self.tree_data.num_trees_completed,\n            reasoning=decision.reasoning,\n            inputs=decision.function_inputs,\n            parsed_info=result.llm_parse(),\n            action=True,\n        )\n\n        # add to log of actions called\n        self._update_actions_called(result, decision)\n\n    def _add_error(self, function_name: str, error: Error) -&gt; None:\n        if function_name not in self.tree_data.errors:\n            self.tree_data.errors[function_name] = []\n\n        self.tree_data.update_tasks_completed(\n            prompt=self.user_prompt,\n            task=function_name,\n            num_trees_completed=self.tree_data.num_trees_completed,\n            error=True,\n        )\n\n        if error.feedback != \"An unknown issue occurred.\":\n            self.tree_data.errors[function_name].append(\n                \"Avoidable error: \"\n                f\"{error.feedback} \"\n                \"(this error is likely to be solved by incorporating the feedback in a future tool call)\"\n            )\n        else:\n            self.tree_data.errors[function_name].append(\n                \"Unknown error: \"\n                f\"{error.error_message} \"\n                \"(this error is likely outside of your capacity to be solved - \"\n                \"judge the error message based on other information and if it seems fixable, call this tool again \"\n                \"if it is repeated, you may need to try something else or inform the user of the issue)\"\n            )\n\n    async def _evaluate_result(\n        self,\n        result: Result | TreeUpdate | Error | TrainingUpdate | Text | Update,\n        decision: Decision,\n    ) -&gt; tuple[dict | None, bool]:\n        error = False\n\n        if isinstance(result, Result):\n            self._add_refs(result.objects, decision.function_name, result.name)\n            self._update_environment(result, decision)\n\n        if isinstance(result, TrainingUpdate):\n            self.training_updates.append(result)\n            return None, error\n\n        if isinstance(result, Error):\n            self._add_error(decision.function_name, result)\n            if self.settings.LOGGING_LEVEL_INT &lt;= 20:\n                print(\n                    Panel.fit(\n                        (\n                            result.error_message\n                            if result.feedback == \"An unknown issue occurred.\"\n                            else result.feedback\n                        ),\n                        title=\"Error\",\n                        border_style=\"red\",\n                        padding=(1, 1),\n                    )\n                )\n            error = True\n\n        if isinstance(result, Text):\n            self._update_conversation_history(\"assistant\", result.text)\n            if self.settings.LOGGING_LEVEL_INT &lt;= 20:\n                print(\n                    Panel.fit(\n                        result.text,\n                        title=\"Assistant response\",\n                        border_style=\"cyan\",\n                        padding=(1, 1),\n                    )\n                )\n\n        return (\n            await self.returner(\n                result,\n                self.prompt_to_query_id[self.user_prompt],\n            ),\n            error,\n        )\n\n    async def _get_available_tools(\n        self, current_decision_node: DecisionNode, client_manager: ClientManager\n    ) -&gt; tuple[list[str], list[tuple[str, str]]]:\n        available_tools = []\n        unavailable_tools = []\n        for tool in current_decision_node.options.keys():\n            if current_decision_node.options[tool][\"action\"] is None:\n                available_tools.append(tool)\n            elif \"is_tool_available\" in dir(self.tools[tool]) and await self.tools[\n                tool\n            ].is_tool_available(\n                tree_data=self.tree_data,\n                base_lm=self.base_lm,\n                complex_lm=self.complex_lm,\n                client_manager=client_manager,\n            ):\n                available_tools.append(tool)\n            else:\n                is_tool_available_doc = (\n                    self.tools[tool].is_tool_available.__doc__.strip()\n                    if self.tools[tool].is_tool_available.__doc__\n                    else \"\"\n                )\n                unavailable_tools.append((tool, is_tool_available_doc))\n        return available_tools, unavailable_tools\n\n    def _get_successive_actions(\n        self, successive_actions: dict, current_options: dict\n    ) -&gt; dict:\n\n        for branch in current_options:\n            successive_actions[branch] = {}\n            if current_options[branch][\"options\"] != {}:\n                successive_actions[branch] = self._get_successive_actions(\n                    successive_actions[branch], current_options[branch][\"options\"]\n                )\n        return successive_actions\n\n    def log_token_usage(self) -&gt; None:\n        if not self.low_memory:\n            avg_input_base = self.tracker.get_average_input_tokens(\"base_lm\")\n            avg_output_base = self.tracker.get_average_output_tokens(\"base_lm\")\n            total_input_base = self.tracker.get_total_input_tokens(\"base_lm\")\n            total_output_base = self.tracker.get_total_output_tokens(\"base_lm\")\n            avg_input_complex = self.tracker.get_average_input_tokens(\"complex_lm\")\n            avg_output_complex = self.tracker.get_average_output_tokens(\"complex_lm\")\n            total_input_complex = self.tracker.get_total_input_tokens(\"complex_lm\")\n            total_output_complex = self.tracker.get_total_output_tokens(\"complex_lm\")\n            total_cost_base = self.tracker.get_total_cost(\"base_lm\")\n            total_cost_complex = self.tracker.get_total_cost(\"complex_lm\")\n            avg_cost_base = self.tracker.get_average_cost(\"base_lm\")\n            avg_cost_complex = self.tracker.get_average_cost(\"complex_lm\")\n            num_calls_base = self.tracker.get_num_calls(\"base_lm\")\n            num_calls_complex = self.tracker.get_num_calls(\"complex_lm\")\n\n            if num_calls_base &gt; 0:\n                self.settings.logger.debug(\n                    f\"Base Model Usage: \\n\"\n                    f\"  - Calls: [magenta]{num_calls_base}[/magenta]\\n\"\n                    f\"  - Input Tokens: [magenta]{total_input_base}[/magenta] (Avg. [magenta]{int(avg_input_base)}[/magenta] per call)\\n\"\n                    f\"  - Output Tokens: [cyan]{total_output_base}[/cyan] (Avg. [cyan]{int(avg_output_base)}[/cyan] per call)\\n\"\n                    f\"  - Total Cost: [yellow]${total_cost_base:.4f}[/yellow] (Avg. [yellow]${avg_cost_base:.4f}[/yellow] per call)\\n\"\n                )\n            else:\n                self.settings.logger.debug(\n                    f\"Base Model Usage: [magenta]0[/magenta] calls\"\n                )\n            if num_calls_complex &gt; 0:\n                self.settings.logger.debug(\n                    f\"Complex Model Usage: \\n\"\n                    f\"  - Calls: [magenta]{num_calls_complex}[/magenta]\\n\"\n                    f\"  - Input Tokens: [magenta]{total_input_complex}[/magenta] (Avg. [magenta]{int(avg_input_complex)}[/magenta] per call)\\n\"\n                    f\"  - Output Tokens: [cyan]{total_output_complex}[/cyan] (Avg. [cyan]{int(avg_output_complex)}[/cyan] per call)\\n\"\n                    f\"  - Total Cost: [yellow]${total_cost_complex:.4f}[/yellow] (Avg. [yellow]${avg_cost_complex:.4f}[/yellow] per call)\\n\"\n                )\n            else:\n                self.settings.logger.debug(\n                    f\"Complex Model Usage: [magenta]0[/magenta] calls\"\n                )\n\n    async def async_run(\n        self,\n        user_prompt: str,\n        collection_names: list[str] = [],\n        client_manager: ClientManager | None = None,\n        training_route: str = \"\",\n        query_id: str | None = None,\n        close_clients_after_completion: bool = True,\n        _first_run: bool = True,\n        **kwargs,\n    ) -&gt; AsyncGenerator[dict | None, None]:\n        \"\"\"\n        Async version of .run() for running Elysia in an async environment.\n        See .run() for full documentation.\n        \"\"\"\n\n        if client_manager is None:\n            client_manager = ClientManager(\n                wcd_url=self.settings.WCD_URL,\n                wcd_api_key=self.settings.WCD_API_KEY,\n                logger=self.settings.logger,\n                client_timeout=None,\n                **self.settings.API_KEYS,\n            )\n\n        # If training route is provided, split it into a list\n        if training_route != \"\":\n            route_list = training_route.split(\"/\")\n        else:\n            route_list = []\n\n        # Some initial steps if this is the first run (no recursion yet)\n        if _first_run:\n\n            self.settings.logger.debug(f\"Style: {self.tree_data.atlas.style}\")\n            self.settings.logger.debug(\n                f\"Agent description: {self.tree_data.atlas.agent_description}\"\n            )\n            self.settings.logger.debug(f\"End goal: {self.tree_data.atlas.end_goal}\")\n\n            if query_id is None:\n                query_id = str(uuid.uuid4())\n\n            self.returner.add_prompt(user_prompt, query_id)\n\n            # Reset the tree (clear temporary data specific to the last user prompt)\n            self.soft_reset()\n\n            check_base_lm_settings(self.settings)\n            check_complex_lm_settings(self.settings)\n\n            # Initialise some objects\n            self.set_start_time()\n            self.query_id_to_prompt[query_id] = user_prompt\n            self.prompt_to_query_id[user_prompt] = query_id\n            self.tree_data.set_property(\"user_prompt\", user_prompt)\n            self._update_conversation_history(\"user\", user_prompt)\n            self.user_prompt = user_prompt\n\n            # check and start clients if not already started\n            if client_manager.is_client:\n                await client_manager.start_clients()\n\n                # Initialise the collections\n                if self.use_elysia_collections:\n                    if collection_names == []:\n                        async with client_manager.connect_to_async_client() as client:\n                            collection_names = await retrieve_all_collection_names(\n                                client\n                            )\n                    await self.set_collection_names(\n                        collection_names,\n                        client_manager,\n                    )\n\n            # If there are any empty branches, remove them (no tools attached to them)\n            self._remove_empty_branches()\n\n            if self.settings.LOGGING_LEVEL_INT &lt;= 20:\n                print(\n                    Panel.fit(\n                        user_prompt,\n                        title=\"User prompt\",\n                        border_style=\"yellow\",\n                        padding=(1, 1),\n                    )\n                )\n\n        # Start the tree at the root node\n        if self.root is not None:\n            current_decision_node: DecisionNode = self.decision_nodes[self.root]\n        else:\n            raise ValueError(\"No root node found!\")\n\n        # Loop through the tree until the end is reached\n        while True:\n\n            available_tools, unavailable_tools = await self._get_available_tools(\n                current_decision_node, client_manager\n            )\n\n            if len(available_tools) == 0:\n                self.settings.logger.error(\"No tools available to use!\")\n                raise ValueError(\n                    \"No tools available to use! \"\n                    \"Check the tool definitions and the `is_tool_available` methods.\"\n                )\n\n            init_options = deepcopy(self.tree[\"options\"])\n            successive_actions = self._get_successive_actions(\n                successive_actions={},\n                current_options=init_options,\n            )\n\n            # Evaluate any tools which have hardcoded rules that have been met\n            nodes_with_rules_met, rule_tool_inputs = await self._check_rules(\n                current_decision_node.id, client_manager\n            )\n\n            if len(nodes_with_rules_met) &gt; 0:\n                for rule in nodes_with_rules_met:\n                    rule_decision = Decision(rule, {}, \"\", False, False)\n                    with ElysiaKeyManager(self.settings):\n                        async for result in self.tools[rule](\n                            tree_data=self.tree_data,\n                            inputs=rule_tool_inputs[rule],\n                            base_lm=self.base_lm,\n                            complex_lm=self.complex_lm,\n                            client_manager=client_manager,\n                        ):\n                            action_result, _ = await self._evaluate_result(\n                                result, rule_decision\n                            )\n                            if action_result is not None:\n                                yield action_result\n\n            # If training route is provided, decide from the training route\n            if len(route_list) &gt; 0:\n                self.settings.logger.debug(f\"Route that will be used: {route_list}\")\n\n                (\n                    self.current_decision,\n                    training_route,\n                ) = current_decision_node.decide_from_route(route_list)\n\n                force_text_response = (\n                    self.current_decision.function_name == \"text_response\"\n                )\n\n            # Under normal circumstances decide from the decision node\n            else:\n                self.tracker.start_tracking(\"decision_node\")\n                self.tree_data.set_current_task(\"elysia_decision_node\")\n                with ElysiaKeyManager(self.settings):\n                    self.current_decision, results = await current_decision_node(\n                        tree_data=self.tree_data,\n                        base_lm=self.base_lm,\n                        complex_lm=self.complex_lm,\n                        available_tools=available_tools,\n                        unavailable_tools=unavailable_tools,\n                        successive_actions=successive_actions,\n                        client_manager=client_manager,\n                    )\n\n                for result in results:\n                    action_result, _ = await self._evaluate_result(\n                        result, self.current_decision\n                    )\n                    if action_result is not None:\n                        yield action_result\n\n                self.tracker.end_tracking(\n                    \"decision_node\",\n                    \"Decision Node\",\n                    self.base_lm if not self.low_memory else None,\n                    self.complex_lm if not self.low_memory else None,\n                )\n\n                # Force text response (later) if model chooses end actions\n                # but no response will be generated from the node, set flag now\n                force_text_response = (\n                    not current_decision_node.options[\n                        self.current_decision.function_name\n                    ][\"end\"]\n                    and self.current_decision.end_actions\n                )\n\n            # Set default values for the function inputs for current call\n            self.current_decision.function_inputs = self._get_function_inputs(\n                self.current_decision.function_name,\n                self.current_decision.function_inputs,\n            )\n\n            # end criteria, task picked is \"text_response\" or model chooses to end conversation\n            completed = (\n                self.current_decision.function_name == \"text_response\"\n                or self.current_decision.end_actions\n                or self.current_decision.impossible\n                or self.tree_data.num_trees_completed &gt; self.tree_data.recursion_limit\n            )\n\n            # assign action function\n            action_fn: Tool | None = current_decision_node.options[\n                self.current_decision.function_name\n            ][\n                \"action\"\n            ]  # type: ignore\n\n            # update the decision history\n            self.decision_history[-1].append(self.current_decision.function_name)\n\n            # print the current node information\n            if self.settings.LOGGING_LEVEL_INT &lt;= 20:\n                print(\n                    Panel.fit(\n                        f\"[bold]Node:[/bold] [magenta]{current_decision_node.id}[/magenta]\\n\"\n                        f\"[bold]Decision:[/bold] [green]{self.current_decision.function_name}[/green]\\n\"\n                        f\"[bold]Reasoning:[/bold] {self.current_decision.reasoning}\\n\",\n                        title=\"Current Decision\",\n                        border_style=\"magenta\",\n                        padding=(1, 1),\n                    )\n                )\n\n            self.tree_data.update_tasks_completed(\n                prompt=self.user_prompt,\n                task=self.current_decision.function_name,\n                num_trees_completed=self.tree_data.num_trees_completed,\n                reasoning=self.current_decision.reasoning,\n                action=action_fn is not None,\n            )\n\n            # evaluate the action if this is not a branch\n            if action_fn is not None:\n                self.tracker.start_tracking(self.current_decision.function_name)\n                self.tree_data.set_current_task(self.current_decision.function_name)\n                successful_action = True\n                with ElysiaKeyManager(self.settings):\n                    async for result in action_fn(\n                        tree_data=self.tree_data,\n                        inputs=self.current_decision.function_inputs,\n                        base_lm=self.base_lm,\n                        complex_lm=self.complex_lm,\n                        client_manager=client_manager,\n                        **kwargs,\n                    ):\n                        action_result, error = await self._evaluate_result(\n                            result, self.current_decision\n                        )\n\n                        if action_result is not None:\n                            yield action_result\n\n                        successful_action = not error and successful_action\n\n                if not successful_action:\n                    completed = (\n                        False\n                        or self.tree_data.num_trees_completed\n                        &gt; self.tree_data.recursion_limit\n                    )\n\n                if successful_action:\n                    self.tree_data.clear_error(self.current_decision.function_name)\n\n                self.tracker.end_tracking(\n                    self.current_decision.function_name,\n                    self.current_decision.function_name,\n                    self.base_lm if not self.low_memory else None,\n                    self.complex_lm if not self.low_memory else None,\n                )\n\n            yield (\n                await self._evaluate_result(\n                    TreeUpdate(\n                        from_node=current_decision_node.id,\n                        to_node=self.current_decision.function_name,\n                        reasoning=(\n                            self.current_decision.reasoning\n                            if self.settings.BASE_USE_REASONING\n                            else \"\"\n                        ),\n                        reset_tree=current_decision_node.options[\n                            self.current_decision.function_name\n                        ][\"next\"]\n                        is None\n                        and (not completed),\n                    ),\n                    self.current_decision,\n                )\n            )[0]\n\n            # check if the current node is the end of the tree\n            if (\n                current_decision_node.options[self.current_decision.function_name][\n                    \"next\"\n                ]\n                is None\n                or completed\n            ):\n                break\n            else:\n                current_decision_node = current_decision_node.options[\n                    self.current_decision.function_name\n                ][\n                    \"next\"\n                ]  # type: ignore\n\n        self.tree_data.num_trees_completed += 1\n\n        # end of all trees\n        if completed:\n\n            # firstly, if we reached the end of a tree at a node that shouldn't be the end, call text response tool here to respond\n            if (\n                not current_decision_node.options[self.current_decision.function_name][\n                    \"end\"\n                ]\n                or force_text_response\n            ):\n                with ElysiaKeyManager(self.settings):\n                    async for result in self.tools[\"forced_text_response\"](\n                        tree_data=self.tree_data,\n                        inputs={},\n                        base_lm=self.base_lm,\n                        complex_lm=self.complex_lm,\n                    ):\n                        action_result, _ = await self._evaluate_result(\n                            result, self.current_decision\n                        )\n                        if action_result is not None:\n                            yield action_result\n\n            self.save_history(\n                query_id=self.prompt_to_query_id[user_prompt],\n                time_taken_seconds=time.time() - self.start_time,\n            )\n\n            yield await self.returner(\n                Completed(), query_id=self.prompt_to_query_id[user_prompt]\n            )\n\n            self.settings.logger.debug(\n                f\"[bold green]Model identified overall goal as completed![/bold green]\"\n            )\n            self.settings.logger.debug(\n                f\"Total time taken for decision tree: {time.time() - self.start_time:.2f} seconds\"\n            )\n            self.settings.logger.debug(\n                f\"Decision Node Avg. Time: {self.tracker.get_average_time('decision_node'):.2f} seconds\"\n            )\n            self.log_token_usage()\n\n            avg_times = []\n            for i, iteration in enumerate(self.decision_history):\n                if iteration != []:\n                    avg_times = [\n                        (\n                            f\"  - {task} ([magenta]Avg. {self.tracker.get_average_time(task):.2f} seconds[/magenta])\\n\"\n                            if task in self.tracker.trackers\n                            else \"\"\n                        )\n                        for task in iteration\n                    ]\n                    self.settings.logger.debug(\n                        f\"Tasks completed (iteration {i+1}):\\n\" + \"\".join(avg_times)\n                    )\n\n            if close_clients_after_completion and client_manager.is_client:\n                await client_manager.close_clients()\n\n        # otherwise, end of the tree for this iteration, and recursively call process() to restart the tree\n        else:\n            self.settings.logger.debug(\n                f\"Model did [bold red]not[/bold red] yet complete overall goal! \"\n            )\n            self.settings.logger.debug(\n                f\"Restarting tree (Recursion: {self.tree_data.num_trees_completed+1}/{self.tree_data.recursion_limit})...\"\n            )\n\n            # recursive call to restart the tree since the goal was not completed\n            self.decision_history.append([])\n            async for result in self.async_run(\n                user_prompt,\n                collection_names,\n                client_manager,\n                training_route=training_route,\n                query_id=query_id,\n                _first_run=False,\n            ):\n                yield result\n\n    def run(\n        self,\n        user_prompt: str,\n        collection_names: list[str] = [],\n        client_manager: ClientManager | None = None,\n        training_route: str = \"\",\n        query_id: str | None = None,\n        close_clients_after_completion: bool = True,\n    ) -&gt; tuple[str, list[dict]]:\n        \"\"\"\n        Run the Elysia decision tree.\n\n        Args:\n            user_prompt (str): The input from the user.\n            collection_names (list[str]): The names of the collections to use.\n                If not provided, Elysia will attempt to retrieve all collection names from the client.\n            client_manager (ClientManager): The client manager to use.\n                If not provided, a new ClientManager will be created.\n            training_route (str): The route to use for training.\n                Separate tools/branches you want to use with a \"/\".\n                e.g. \"query/text_response\" will only use the \"query\" tool and the \"text_response\" tool, and end the tree there.\n            query_id (str): The id of the query.\n                Only necessary if you are hosting Elysia on a server with multiple users.\n                If not provided, a new query id will be generated.\n            close_clients_after_completion (bool): Whether to close the clients after the tree is completed.\n                Leave as True for most use cases, but if you don't want to close the clients for the ClientManager, set to False.\n                For example, if you are managing your own clients (e.g. in an app), you may want to set this to False.\n\n        Returns:\n            (str): The concatenation of all the responses from the tree.\n            (list[dict]): The retrieved objects from the tree.\n        \"\"\"\n\n        self.store_retrieved_objects = True\n\n        async def run_process():\n            async for result in self.async_run(\n                user_prompt,\n                collection_names,\n                client_manager,\n                training_route,\n                query_id,\n                close_clients_after_completion,\n            ):\n                pass\n            return self.retrieved_objects\n\n        async def run_with_live():\n            console = Console()\n\n            with console.status(\"[bold indigo]Thinking...\") as status:\n                async for result in self.async_run(\n                    user_prompt,\n                    collection_names,\n                    client_manager,\n                    training_route,\n                    query_id,\n                    close_clients_after_completion,\n                ):\n                    if (\n                        result is not None\n                        and \"type\" in result\n                        and result[\"type\"] == \"status\"\n                        and isinstance(result[\"payload\"], dict)\n                        and \"text\" in result[\"payload\"]\n                    ):\n                        payload: dict = result[\"payload\"]  # type: ignore\n                        status.update(f\"[bold indigo]{payload['text']}\")\n\n            return self.retrieved_objects\n\n        if self.settings.LOGGING_LEVEL_INT &lt;= 20:\n            yielded_results = asyncio_run(run_with_live())\n        else:\n            yielded_results = asyncio_run(run_process())\n\n        text = self.tree_data.conversation_history[-1][\"content\"]\n\n        return text, yielded_results\n\n    def detailed_memory_usage(self) -&gt; dict:\n        \"\"\"\n        Returns a detailed breakdown of memory usage for all major objects in the Tree class.\n\n        Returns:\n            dict: Dictionary containing memory sizes (in bytes) for each major component\n        \"\"\"\n        memory_usage = {}\n\n        # Core data structures\n        memory_usage[\"tree_data\"] = asizeof.asizeof(self.tree_data)\n        memory_usage[\"tree_data\"] = asizeof.asizeof(self.tree_data)\n        memory_usage[\"tree_data\"] = asizeof.asizeof(self.tree_data)\n        memory_usage[\"collection_data\"] = asizeof.asizeof(\n            self.tree_data.collection_data\n        )\n\n        # Decision nodes and tools\n        memory_usage[\"decision_nodes\"] = {\n            node_id: asizeof.asizeof(node)\n            for node_id, node in self.decision_nodes.items()\n        }\n        memory_usage[\"tools\"] = {\n            tool_name: asizeof.asizeof(tool) for tool_name, tool in self.tools.items()\n        }\n\n        # History and tracking\n        memory_usage[\"decision_history\"] = asizeof.asizeof(self.decision_history)\n        memory_usage[\"history\"] = asizeof.asizeof(self.history)\n        memory_usage[\"training_updates\"] = asizeof.asizeof(self.training_updates)\n        memory_usage[\"action_information\"] = asizeof.asizeof(self.action_information)\n\n        # Mapping dictionaries\n        memory_usage[\"query_mappings\"] = {\n            \"query_id_to_prompt\": asizeof.asizeof(self.query_id_to_prompt),\n            \"prompt_to_query_id\": asizeof.asizeof(self.prompt_to_query_id),\n        }\n\n        # Calculate total\n        memory_usage[\"total\"] = sum(\n            (v if isinstance(v, int) else sum(v.values()) if isinstance(v, dict) else 0)\n            for v in memory_usage.values()\n        )\n\n        return memory_usage\n\n    def export_to_json(self) -&gt; dict:\n        \"\"\"\n        Export the tree to a JSON object, to be used for loading the tree via import_from_json().\n\n        Returns:\n            (dict): The JSON object.\n        \"\"\"\n        try:\n            return {\n                \"user_id\": self.user_id,\n                \"conversation_id\": self.conversation_id,\n                \"conversation_title\": self.conversation_title,\n                \"branch_initialisation\": self.branch_initialisation,\n                \"use_elysia_collections\": self.use_elysia_collections,\n                \"tree_index\": self.tree_index,\n                \"store_retrieved_objects\": self.store_retrieved_objects,\n                \"low_memory\": self.low_memory,\n                \"tree_data\": self.tree_data.to_json(remove_unserialisable=True),\n                \"settings\": self.settings.to_json(),\n                \"tool_names\": list(self.tools.keys()),\n                \"frontend_rebuild\": self.returner.store,\n            }\n        except Exception as e:\n            self.settings.logger.error(f\"Error exporting tree to JSON: {str(e)}\")\n            raise e\n\n    async def export_to_weaviate(\n        self, collection_name: str, client_manager: ClientManager | None = None\n    ) -&gt; None:\n        \"\"\"\n        Export the tree to a Weaviate collection.\n\n        Args:\n            collection_name (str): The name of the collection to export to.\n            client_manager (ClientManager): The client manager to use.\n                If not provided, a new ClientManager will be created from environment variables.\n        \"\"\"\n        if client_manager is None:\n            client_manager = ClientManager()\n            close_after_use = True\n        else:\n            close_after_use = False\n\n        async with client_manager.connect_to_async_client() as client:\n\n            if not await client.collections.exists(collection_name):\n                await client.collections.create(\n                    collection_name,\n                    vectorizer_config=wc.Configure.Vectorizer.none(),\n                    inverted_index_config=wc.Configure.inverted_index(\n                        index_timestamps=True\n                    ),\n                    properties=[\n                        wc.Property(\n                            name=\"user_id\",\n                            data_type=wc.DataType.TEXT,\n                        ),\n                        wc.Property(\n                            name=\"conversation_id\",\n                            data_type=wc.DataType.TEXT,\n                        ),\n                        wc.Property(\n                            name=\"tree\",\n                            data_type=wc.DataType.TEXT,\n                        ),\n                        wc.Property(\n                            name=\"title\",\n                            data_type=wc.DataType.TEXT,\n                        ),\n                    ],\n                )\n\n            collection = client.collections.get(collection_name)\n\n            json_data_str = json.dumps(self.export_to_json())\n\n            uuid = generate_uuid5(self.conversation_id)\n\n            if await collection.data.exists(uuid):\n                await collection.data.update(\n                    uuid=uuid,\n                    properties={\n                        \"user_id\": self.user_id,\n                        \"conversation_id\": self.conversation_id,\n                        \"tree\": json_data_str,\n                        \"title\": self.conversation_title,\n                    },\n                )\n                self.settings.logger.info(\n                    f\"Successfully updated existing tree in collection '{collection_name}' with id '{self.conversation_id}'\"\n                )\n            else:\n                await collection.data.insert(\n                    uuid=uuid,\n                    properties={\n                        \"user_id\": self.user_id,\n                        \"conversation_id\": self.conversation_id,\n                        \"tree\": json_data_str,\n                        \"title\": self.conversation_title,\n                    },\n                )\n                self.settings.logger.info(\n                    f\"Successfully inserted new tree in collection '{collection_name}' with id '{self.conversation_id}'\"\n                )\n\n        if close_after_use:\n            await client_manager.close_clients()\n\n    @classmethod\n    def import_from_json(cls, json_data: dict) -&gt; \"Tree\":\n        \"\"\"\n        Import a tree from a JSON object, outputted by the export_to_json() method.\n\n        Args:\n            json_data (dict): The JSON object to import the tree from.\n\n        Returns:\n            (Tree): The new tree instance loaded from the JSON object.\n        \"\"\"\n        settings = Settings.from_json(json_data[\"settings\"])\n        logger = settings.logger\n        tree = cls(\n            user_id=json_data[\"user_id\"],\n            conversation_id=json_data[\"conversation_id\"],\n            branch_initialisation=json_data[\"branch_initialisation\"],\n            style=json_data[\"tree_data\"][\"atlas\"][\"style\"],\n            agent_description=json_data[\"tree_data\"][\"atlas\"][\"agent_description\"],\n            end_goal=json_data[\"tree_data\"][\"atlas\"][\"end_goal\"],\n            low_memory=json_data[\"low_memory\"],\n            use_elysia_collections=json_data[\"use_elysia_collections\"],\n            settings=settings,\n        )\n\n        tree.returner.store = json_data[\"frontend_rebuild\"]\n        tree.tree_data = TreeData.from_json(json_data[\"tree_data\"])\n        tree.set_branch_initialisation(json_data[\"branch_initialisation\"])\n\n        # check tools\n        for tool_name in json_data[\"tool_names\"]:\n            if tool_name not in tree.tools:\n                logger.warning(\n                    f\"In saved tree, custom tool '{tool_name}' found. \"\n                    \"This will not be loaded in the new tree. \"\n                    \"You will need to add it to the tree manually.\"\n                )\n\n        return tree\n\n    @classmethod\n    async def import_from_weaviate(\n        cls,\n        collection_name: str,\n        conversation_id: str,\n        client_manager: ClientManager | None = None,\n    ) -&gt; \"Tree\":\n        \"\"\"\n        Import a tree from a Weaviate collection.\n\n        Args:\n            collection_name (str): The name of the collection to import from.\n            conversation_id (str): The id of the conversation to import.\n            client_manager (ClientManager): The client manager to use.\n                If not provided, a new ClientManager will be created from environment variables.\n\n        Returns:\n            (Tree): The tree object.\n        \"\"\"\n\n        if client_manager is None:\n            client_manager = ClientManager()\n            close_after_use = True\n        else:\n            close_after_use = False\n\n        async with client_manager.connect_to_async_client() as client:\n\n            if not await client.collections.exists(collection_name):\n                raise ValueError(\n                    f\"Collection '{collection_name}' does not exist in this Weaviate instance.\"\n                )\n\n            collection = client.collections.get(collection_name)\n            uuid = generate_uuid5(conversation_id)\n            # if not await collection.data.exists(uuid):\n            #     raise ValueError(\n            #         f\"No tree found for conversation id '{conversation_id}' in collection '{collection_name}'.\"\n            #     )\n\n            response = await collection.query.fetch_object_by_id(uuid)\n\n        if close_after_use:\n            await client_manager.close_clients()\n\n        if response is None:\n            raise ValueError(\n                f\"No tree found for conversation id '{conversation_id}' in collection '{collection_name}'.\"\n            )\n\n        json_data_str = response.properties[\"tree\"]\n        json_data = json.loads(json_data_str)  # type: ignore\n\n        return cls.import_from_json(json_data)\n\n    def __call__(self, *args, **kwargs) -&gt; tuple[str, list[dict]]:\n        return self.run(*args, **kwargs)\n</code></pre>"},{"location":"Reference/Tree/#elysia.tree.tree.Tree.__init__","title":"<code>__init__(branch_initialisation='default', style='No style provided.', agent_description='No description provided.', end_goal='No end goal provided.', user_id=None, conversation_id=None, low_memory=False, use_elysia_collections=True, settings=None)</code>","text":"<p>Parameters:</p> Name Type Description Default <code>branch_initialisation</code> <code>str</code> <p>The initialisation method for the branches, currently supports some pre-defined initialisations: \"multi_branch\", \"one_branch\". Set to \"empty\" to start with no branches and to add them, and the tools, yourself.</p> <code>'default'</code> <code>style</code> <code>str</code> <p>The writing style of the agent. Automatically set for \"multi_branch\" and \"one_branch\" initialisation, but overrided if non-empty.</p> <code>'No style provided.'</code> <code>agent_description</code> <code>str</code> <p>The description of the agent. Automatically set for \"multi_branch\" and \"one_branch\" initialisation, but overrided if non-empty.</p> <code>'No description provided.'</code> <code>end_goal</code> <code>str</code> <p>The end goal of the agent. Automatically set for \"multi_branch\" and \"one_branch\" initialisation, but overrided if non-empty.</p> <code>'No end goal provided.'</code> <code>user_id</code> <code>str</code> <p>The id of the user, e.g. \"123-456\", unneeded outside of user management/hosting Elysia app</p> <code>None</code> <code>conversation_id</code> <code>str</code> <p>The id of the conversation, e.g. \"123-456\", unneeded outside of conversation management/hosting Elysia app</p> <code>None</code> <code>low_memory</code> <code>bool</code> <p>Whether to run the tree in low memory mode. If True, the tree will not load the (dspy) models within the tree. Set to False for normal operation.</p> <code>False</code> <code>use_elysia_collections</code> <code>bool</code> <p>Whether to use weaviate collections as processed by Elysia. If False, the tree will not use the processed collections.</p> <code>True</code> <code>settings</code> <code>Settings</code> <p>The settings for the tree, an object of elysia.Settings. This is automatically set to the environment settings if not provided.</p> <code>None</code> Source code in <code>elysia/tree/tree.py</code> <pre><code>def __init__(\n    self,\n    branch_initialisation: Literal[\n        \"default\", \"one_branch\", \"multi_branch\", \"empty\"\n    ] = \"default\",\n    style: str = \"No style provided.\",\n    agent_description: str = \"No description provided.\",\n    end_goal: str = \"No end goal provided.\",\n    user_id: str | None = None,\n    conversation_id: str | None = None,\n    low_memory: bool = False,\n    use_elysia_collections: bool = True,\n    settings: Settings | None = None,\n) -&gt; None:\n    \"\"\"\n    Args:\n        branch_initialisation (str): The initialisation method for the branches,\n            currently supports some pre-defined initialisations: \"multi_branch\", \"one_branch\".\n            Set to \"empty\" to start with no branches and to add them, and the tools, yourself.\n        style (str): The writing style of the agent. Automatically set for \"multi_branch\" and \"one_branch\" initialisation, but overrided if non-empty.\n        agent_description (str): The description of the agent. Automatically set for \"multi_branch\" and \"one_branch\" initialisation, but overrided if non-empty.\n        end_goal (str): The end goal of the agent. Automatically set for \"multi_branch\" and \"one_branch\" initialisation, but overrided if non-empty.\n        user_id (str): The id of the user, e.g. \"123-456\",\n            unneeded outside of user management/hosting Elysia app\n        conversation_id (str): The id of the conversation, e.g. \"123-456\",\n            unneeded outside of conversation management/hosting Elysia app\n        low_memory (bool): Whether to run the tree in low memory mode.\n            If True, the tree will not load the (dspy) models within the tree.\n            Set to False for normal operation.\n        use_elysia_collections (bool): Whether to use weaviate collections as processed by Elysia.\n            If False, the tree will not use the processed collections.\n        settings (Settings): The settings for the tree, an object of elysia.Settings.\n            This is automatically set to the environment settings if not provided.\n    \"\"\"\n    # Define base variables of the tree\n    if user_id is None:\n        self.user_id = str(uuid.uuid4())\n    else:\n        self.user_id = user_id\n\n    if conversation_id is None:\n        self.conversation_id = str(uuid.uuid4())\n    else:\n        self.conversation_id = conversation_id\n\n    if settings is None:\n        self.settings = environment_settings\n    else:\n        assert isinstance(\n            settings, Settings\n        ), \"settings must be an instance of Settings\"\n        self.settings = settings\n\n    self.use_elysia_collections = use_elysia_collections\n\n    # Initialise some tree variables\n    self.decision_nodes: dict[str, DecisionNode] = {}\n    self.decision_history = [[]]\n    self.tree_index = -1\n    self.suggestions = []\n    self.actions_called = {}\n    self.query_id_to_prompt = {}\n    self.prompt_to_query_id = {}\n    self.retrieved_objects = []\n    self.store_retrieved_objects = False\n    self.conversation_title = None\n    self.low_memory = low_memory\n    self._base_lm = None\n    self._complex_lm = None\n    self._config_modified = False\n    self.root = None\n\n    # Define the inputs to prompts\n    self.tree_data = TreeData(\n        environment=Environment(),\n        collection_data=CollectionData(\n            collection_names=[], logger=self.settings.logger\n        ),\n        atlas=Atlas(\n            style=style,\n            agent_description=agent_description,\n            end_goal=end_goal,\n        ),\n        recursion_limit=5,\n        settings=self.settings,\n    )\n\n    # initialise the timers\n    self.tracker = Tracker(\n        tracker_names=[\"decision_node\"],\n        logger=self.settings.logger,\n    )\n\n    # Set the initialisations\n    self.tools = {}\n    self.set_branch_initialisation(branch_initialisation)\n    self.tree_data.atlas.style = style\n    self.tree_data.atlas.agent_description = agent_description\n    self.tree_data.atlas.end_goal = end_goal\n\n    self.tools[\"forced_text_response\"] = ForcedTextResponse()\n\n    # some variables for storing feedback\n    self.action_information = []\n    self.history = {}\n    self.training_updates = []\n\n    # -- Get the root node and construct the tree\n    self._get_root()\n    self.tree = {}\n    self._construct_tree(self.root, self.tree)\n\n    # initialise the returner (for frontend)\n    self.returner = TreeReturner(\n        user_id=self.user_id,\n        conversation_id=self.conversation_id,\n    )\n\n    # Print the tree if required\n    self.settings.logger.debug(\n        \"Initialised tree with the following decision nodes:\"\n    )\n    for decision_node in self.decision_nodes.values():\n        self.settings.logger.debug(\n            f\"  - [magenta]{decision_node.id}[/magenta]: {list(decision_node.options.keys())}\"\n        )\n</code></pre>"},{"location":"Reference/Tree/#elysia.tree.tree.Tree.add_branch","title":"<code>add_branch(branch_id, instruction, description='', root=False, from_branch_id='', from_tool_ids=[], status='')</code>","text":"<p>Add a branch to the tree.</p> <p>Parameters:</p> Name Type Description Default <code>branch_id</code> <code>str</code> <p>The id of the branch being added.</p> required <code>instruction</code> <code>str</code> <p>The general instruction for the branch, what is this branch containing? What kind of tools or actions are being decided on this branch? Only displayed to the decision maker when this branch is chosen.</p> required <code>description</code> <code>str</code> <p>A description of the branch, if it is to be chosen from a previous branch. How does the model know whether to choose this branch or not?</p> <code>''</code> <code>root</code> <code>bool</code> <p>Whether this is the root branch, i.e. the beginning of the tree.</p> <code>False</code> <code>from_branch_id</code> <code>str</code> <p>The id of the branch that this branch is stemming from.</p> <code>''</code> <code>from_tool_ids</code> <code>list[str]</code> <p>The ids of the tools that precede this branch being added (after the <code>from_branch_id</code> branch).</p> <code>[]</code> <code>status</code> <code>str</code> <p>The status message to be displayed when this branch is chosen.</p> <code>''</code> Source code in <code>elysia/tree/tree.py</code> <pre><code>def add_branch(\n    self,\n    branch_id: str,\n    instruction: str,\n    description: str = \"\",\n    root: bool = False,\n    from_branch_id: str = \"\",\n    from_tool_ids: list[str] = [],\n    status: str = \"\",\n) -&gt; None:\n    \"\"\"\n    Add a branch to the tree.\n\n    args:\n        branch_id (str): The id of the branch being added.\n        instruction (str): The general instruction for the branch, what is this branch containing?\n            What kind of tools or actions are being decided on this branch?\n            Only displayed to the decision maker when this branch is chosen.\n        description (str): A description of the branch, if it is to be chosen from a previous branch.\n            How does the model know whether to choose this branch or not?\n        root (bool): Whether this is the root branch, i.e. the beginning of the tree.\n        from_branch_id (str): The id of the branch that this branch is stemming from.\n        from_tool_ids (list[str]): The ids of the tools that precede this branch being added (after the `from_branch_id` branch).\n        status (str): The status message to be displayed when this branch is chosen.\n    \"\"\"\n    if not root and description == \"\":\n        raise ValueError(\"Description is required for non-root branches.\")\n    if not root and from_branch_id == \"\":\n        raise ValueError(\n            \"`from_branch_id` is required for non-root branches. \"\n            \"Set `root=True` to create a root branch or choose where this branch stems from.\"\n        )\n    if root and description != \"\":\n        self.settings.logger.warning(f\"Description is not used for root branches. \")\n        description = \"\"\n\n    if root and from_branch_id != \"\":\n        self.settings.logger.warning(\n            \"`from_branch_id` is not used for root branches. \"\n            \"(As this is the root branch, it does not stem from any other branch.)\"\n            \"If you wish this to be stemming from a previous branch, set `root=False`.\"\n        )\n        from_branch_id = \"\"\n\n    if status == \"\":\n        status = f\"Running {branch_id}...\"\n\n    decision_node = DecisionNode(\n        id=branch_id,\n        instruction=instruction,\n        options={},\n        root=root,\n        logger=self.settings.logger,\n        use_elysia_collections=self.use_elysia_collections,\n    )\n    self.decision_nodes[branch_id] = decision_node\n\n    if not root:\n\n        if from_tool_ids == []:\n            self.decision_nodes[from_branch_id].add_option(\n                id=branch_id,\n                description=description,\n                inputs={},\n                action=None,\n                end=False,\n                status=status,\n                next=self.decision_nodes[branch_id],\n            )\n\n        else:\n\n            current_decision_node = self.decision_nodes[from_branch_id]\n            for from_tool_id in from_tool_ids:\n                if isinstance(current_decision_node, DecisionNode):\n                    if from_tool_id not in current_decision_node.options:\n                        raise ValueError(\n                            f\"Tool '{from_tool_id}' not found in branch '{from_branch_id}'. \"\n                            f\"Available options are: {list(current_decision_node.options.keys())}\"\n                        )\n                    current_decision_node = current_decision_node.options[\n                        from_tool_id\n                    ][\"next\"]\n\n            new_branch_id = from_branch_id\n            for from_tool_id in from_tool_ids:\n                new_branch_id += f\".{from_tool_id}\"\n\n            # only create a new decision node if one doesn't exist here\n            if new_branch_id not in self.decision_nodes:\n                decision_node = DecisionNode(\n                    id=new_branch_id,\n                    instruction=f\"Choose one of the actions based on their descriptions and the user prompt.\",\n                    options={},\n                    root=False,\n                    logger=self.settings.logger,\n                    use_elysia_collections=self.use_elysia_collections,\n                )\n                self.decision_nodes[new_branch_id] = decision_node\n\n                prev_branch_id = branch_id\n                for from_tool_id in from_tool_ids[:-1]:\n                    prev_branch_id += f\".{from_tool_id}\"\n\n                self.decision_nodes[prev_branch_id].options[from_tool_ids[-1]][\n                    \"next\"\n                ] = self.decision_nodes[new_branch_id]\n\n            # add the tool to the new decision node\n            self.decision_nodes[new_branch_id].add_option(\n                id=branch_id,\n                description=description,\n                inputs={},\n                action=None,\n                end=False,\n                status=status,\n                next=self.decision_nodes[branch_id],\n            )\n\n    if root and (self.root is not None):\n        # replace root branch with this one\n        self.decision_nodes[self.root] = decision_node\n        self.settings.logger.debug(\n            f\"Replacing root branch '{self.root}' with '{branch_id}'.\"\n        )\n        old_root = self.root\n        self.root = branch_id\n        self.remove_branch(old_root)\n\n    # reconstruct tree\n    self._get_root()\n    self.tree = {}\n    self._construct_tree(self.root, self.tree)\n</code></pre>"},{"location":"Reference/Tree/#elysia.tree.tree.Tree.add_tool","title":"<code>add_tool(tool, branch_id=None, from_tool_ids=[], root=False, **kwargs)</code>","text":"<p>Add a Tool to a branch or on top of an existing tool. The tool needs to be an instance of the Tool class.</p> <p>Parameters:</p> Name Type Description Default <code>tool</code> <code>Tool</code> <p>The tool to add</p> required <code>branch_id</code> <code>str</code> <p>The id of the branch to add the tool to If not specified, the tool will be added to the root branch</p> <code>None</code> <code>from_tool_ids</code> <code>list[str]</code> <p>The ids of the tools to add the new tool after If not specified, the tool will be added to the base of the branch</p> <code>[]</code> <code>root</code> <code>bool</code> <p>Whether the tool is the root tool If not specified, the tool will be added to the root branch</p> <code>False</code> <code>kwargs</code> <code>any</code> <p>Additional keyword arguments to pass to the initialisation of the tool</p> <code>{}</code> Example 1 <p>To add a tool, <code>Query</code>, to a branch called 'search', you can do this: <pre><code>tree.add_tool(Query, branch_id=\"search\")\n</code></pre> This will add the <code>Query</code> tool to the branch 'search'. If the branch 'search' doesn't exist, it will raise an error. To add a branch, use the <code>.add_branch()</code> method.</p> Example 2 <p>Assume your tree has a \"search\" branch with two tools: 'query' and 'aggregate'. You can add a tool, <code>CheckResult</code>, after the 'query' tool like this: <pre><code>tree.add_tool(CheckResult, branch_id=\"search\", from_tool_ids=[\"query\"])\n</code></pre> This will add the <code>CheckResult</code> tool to the \"search\" branch, after the 'query' tool. So the \"search\" branch will still only have two options: 'query' and 'aggregate'. But after 'query', there will be a new option for the <code>CheckResult</code> tool.</p> Example 3 <p>You can add a tool, <code>SendEmail</code>, after the <code>CheckResult</code> (from Example 2) tool like this: <pre><code>tree.add_tool(SendEmail, from_tool_ids=[\"query\", \"check_result\"], root=True)\n</code></pre> It will add an additional option to the root branch, after the 'query' and 'check_result' tools.</p> Source code in <code>elysia/tree/tree.py</code> <pre><code>def add_tool(\n    self,\n    tool,\n    branch_id: str | None = None,\n    from_tool_ids: list[str] = [],\n    root: bool = False,\n    **kwargs,\n) -&gt; None:\n    \"\"\"\n    Add a Tool to a branch or on top of an existing tool.\n    The tool needs to be an instance of the Tool class.\n\n    Args:\n        tool (Tool): The tool to add\n        branch_id (str): The id of the branch to add the tool to\n            If not specified, the tool will be added to the root branch\n        from_tool_ids (list[str]): The ids of the tools to add the new tool after\n            If not specified, the tool will be added to the base of the branch\n        root (bool): Whether the tool is the root tool\n            If not specified, the tool will be added to the root branch\n        kwargs (any): Additional keyword arguments to pass to the initialisation of the tool\n\n    Example 1:\n        To add a tool, `Query`, to a branch called 'search', you can do this:\n        ```python\n        tree.add_tool(Query, branch_id=\"search\")\n        ```\n        This will add the `Query` tool to the branch 'search'.\n        If the branch 'search' doesn't exist, it will raise an error.\n        To add a branch, use the `.add_branch()` method.\n\n\n    Example 2:\n        Assume your tree has a \"search\" branch with two tools: 'query' and 'aggregate'.\n        You can add a tool, `CheckResult`, after the 'query' tool like this:\n        ```python\n        tree.add_tool(CheckResult, branch_id=\"search\", from_tool_ids=[\"query\"])\n        ```\n        This will add the `CheckResult` tool to the \"search\" branch, after the 'query' tool.\n        So the \"search\" branch will still only have two options: 'query' and 'aggregate'.\n        But after 'query', there will be a new option for the `CheckResult` tool.\n\n    Example 3:\n        You can add a tool, `SendEmail`, after the `CheckResult` (from Example 2) tool like this:\n        ```python\n        tree.add_tool(SendEmail, from_tool_ids=[\"query\", \"check_result\"], root=True)\n        ```\n        It will add an additional option to the root branch, after the 'query' and 'check_result' tools.\n    \"\"\"\n\n    if (\n        inspect.getfullargspec(tool.__init__).varkw is None\n        or inspect.getfullargspec(tool.__call__).varkw is None\n    ):\n        raise TypeError(\"tool __init__ and __call__ must accept **kwargs\")\n\n    if not inspect.isasyncgenfunction(tool.__call__):\n        raise TypeError(\n            \"__call__ must be an async generator function. \"\n            \"I.e. it must yield objects.\"\n        )\n\n    if isinstance(tool, Tool):\n        tool_instance = tool\n    else:\n        tool_instance = tool(\n            logger=self.settings.logger,\n            **kwargs,\n        )\n\n    if not isinstance(tool_instance, Tool):\n        raise TypeError(\"tool must be an instance of the Tool class\")\n\n    if \"__call__\" not in dir(tool_instance):\n        raise TypeError(\"tool must be callable (have a __call__ method)\")\n\n    if \"__init__\" not in dir(tool_instance):\n        raise TypeError(\"tool must have an __init__ method\")\n\n    if hasattr(tool_instance, \"is_tool_available\"):\n        if not inspect.iscoroutinefunction(tool_instance.is_tool_available):\n            raise TypeError(\n                \"is_tool_available must be an async function that returns a single boolean value\"\n            )\n\n    if hasattr(tool_instance, \"run_if_true\"):\n        if not inspect.iscoroutinefunction(tool_instance.run_if_true):\n            raise TypeError(\n                \"run_if_true must be an async function that returns a single boolean value\"\n            )\n\n    if root:\n        if branch_id is not None:\n            self.settings.logger.warning(\n                f\"In .add_tool(), `root` is True, so `branch_id` ('{branch_id}') will be ignored. \"\n                f\"Tool: '{tool_instance.name}' will be added to the root branch ('{self.root}').\"\n            )\n        branch_id = self.root\n\n    if branch_id is None:\n        branch_id = self.root\n\n    if branch_id not in self.decision_nodes:\n        raise ValueError(\n            f\"Branch '{branch_id}' not found. Use .add_branch() to add a branch before adding a tool. \"\n            f\"Or, set `root=True` to add the tool to the root branch ('{self.root}').\"\n        )\n\n    current_decision_node = self.decision_nodes[branch_id]\n    for from_tool_id in from_tool_ids:\n        if isinstance(current_decision_node, DecisionNode):\n            if from_tool_id not in current_decision_node.options:\n                raise ValueError(\n                    f\"Tool '{from_tool_id}' not found in branch '{branch_id}'. \"\n                    f\"Available options are: {list(current_decision_node.options.keys())}\"\n                )\n\n            current_decision_node = current_decision_node.options[from_tool_id][\n                \"next\"\n            ]\n\n    self.tools[tool_instance.name] = tool_instance\n\n    if from_tool_ids == []:\n        self.decision_nodes[branch_id].add_option(\n            id=tool_instance.name,\n            description=tool_instance.description,\n            inputs=tool_instance.inputs,\n            action=self.tools[tool_instance.name],\n            end=tool_instance.end,\n            status=tool_instance.status,\n        )\n    else:\n\n        new_branch_id = branch_id\n        for from_tool_id in from_tool_ids:\n            new_branch_id += f\".{from_tool_id}\"\n\n        # only create a new decision node if one doesn't exist here\n        if new_branch_id not in self.decision_nodes:\n            decision_node = DecisionNode(\n                id=new_branch_id,\n                instruction=f\"Choose one of the actions based on their descriptions and the user prompt.\",\n                options={},\n                root=False,\n                logger=self.settings.logger,\n                use_elysia_collections=self.use_elysia_collections,\n            )\n            self.decision_nodes[new_branch_id] = decision_node\n\n            prev_branch_id = branch_id\n            for from_tool_id in from_tool_ids[:-1]:\n                prev_branch_id += f\".{from_tool_id}\"\n\n            self.decision_nodes[prev_branch_id].options[from_tool_ids[-1]][\n                \"next\"\n            ] = self.decision_nodes[new_branch_id]\n\n        # add the tool to the new decision node\n        self.decision_nodes[new_branch_id].add_option(\n            id=tool_instance.name,\n            description=tool_instance.description,\n            inputs=tool_instance.inputs,\n            action=self.tools[tool_instance.name],\n            end=tool_instance.end,\n            status=tool_instance.status,\n        )\n\n    self.tracker.add_tracker(tool_instance.name)\n\n    # reconstruct tree\n    self._get_root()\n    self.tree = {}\n    self._construct_tree(self.root, self.tree)\n</code></pre>"},{"location":"Reference/Tree/#elysia.tree.tree.Tree.async_run","title":"<code>async_run(user_prompt, collection_names=[], client_manager=None, training_route='', query_id=None, close_clients_after_completion=True, _first_run=True, **kwargs)</code>  <code>async</code>","text":"<p>Async version of .run() for running Elysia in an async environment. See .run() for full documentation.</p> Source code in <code>elysia/tree/tree.py</code> <pre><code>async def async_run(\n    self,\n    user_prompt: str,\n    collection_names: list[str] = [],\n    client_manager: ClientManager | None = None,\n    training_route: str = \"\",\n    query_id: str | None = None,\n    close_clients_after_completion: bool = True,\n    _first_run: bool = True,\n    **kwargs,\n) -&gt; AsyncGenerator[dict | None, None]:\n    \"\"\"\n    Async version of .run() for running Elysia in an async environment.\n    See .run() for full documentation.\n    \"\"\"\n\n    if client_manager is None:\n        client_manager = ClientManager(\n            wcd_url=self.settings.WCD_URL,\n            wcd_api_key=self.settings.WCD_API_KEY,\n            logger=self.settings.logger,\n            client_timeout=None,\n            **self.settings.API_KEYS,\n        )\n\n    # If training route is provided, split it into a list\n    if training_route != \"\":\n        route_list = training_route.split(\"/\")\n    else:\n        route_list = []\n\n    # Some initial steps if this is the first run (no recursion yet)\n    if _first_run:\n\n        self.settings.logger.debug(f\"Style: {self.tree_data.atlas.style}\")\n        self.settings.logger.debug(\n            f\"Agent description: {self.tree_data.atlas.agent_description}\"\n        )\n        self.settings.logger.debug(f\"End goal: {self.tree_data.atlas.end_goal}\")\n\n        if query_id is None:\n            query_id = str(uuid.uuid4())\n\n        self.returner.add_prompt(user_prompt, query_id)\n\n        # Reset the tree (clear temporary data specific to the last user prompt)\n        self.soft_reset()\n\n        check_base_lm_settings(self.settings)\n        check_complex_lm_settings(self.settings)\n\n        # Initialise some objects\n        self.set_start_time()\n        self.query_id_to_prompt[query_id] = user_prompt\n        self.prompt_to_query_id[user_prompt] = query_id\n        self.tree_data.set_property(\"user_prompt\", user_prompt)\n        self._update_conversation_history(\"user\", user_prompt)\n        self.user_prompt = user_prompt\n\n        # check and start clients if not already started\n        if client_manager.is_client:\n            await client_manager.start_clients()\n\n            # Initialise the collections\n            if self.use_elysia_collections:\n                if collection_names == []:\n                    async with client_manager.connect_to_async_client() as client:\n                        collection_names = await retrieve_all_collection_names(\n                            client\n                        )\n                await self.set_collection_names(\n                    collection_names,\n                    client_manager,\n                )\n\n        # If there are any empty branches, remove them (no tools attached to them)\n        self._remove_empty_branches()\n\n        if self.settings.LOGGING_LEVEL_INT &lt;= 20:\n            print(\n                Panel.fit(\n                    user_prompt,\n                    title=\"User prompt\",\n                    border_style=\"yellow\",\n                    padding=(1, 1),\n                )\n            )\n\n    # Start the tree at the root node\n    if self.root is not None:\n        current_decision_node: DecisionNode = self.decision_nodes[self.root]\n    else:\n        raise ValueError(\"No root node found!\")\n\n    # Loop through the tree until the end is reached\n    while True:\n\n        available_tools, unavailable_tools = await self._get_available_tools(\n            current_decision_node, client_manager\n        )\n\n        if len(available_tools) == 0:\n            self.settings.logger.error(\"No tools available to use!\")\n            raise ValueError(\n                \"No tools available to use! \"\n                \"Check the tool definitions and the `is_tool_available` methods.\"\n            )\n\n        init_options = deepcopy(self.tree[\"options\"])\n        successive_actions = self._get_successive_actions(\n            successive_actions={},\n            current_options=init_options,\n        )\n\n        # Evaluate any tools which have hardcoded rules that have been met\n        nodes_with_rules_met, rule_tool_inputs = await self._check_rules(\n            current_decision_node.id, client_manager\n        )\n\n        if len(nodes_with_rules_met) &gt; 0:\n            for rule in nodes_with_rules_met:\n                rule_decision = Decision(rule, {}, \"\", False, False)\n                with ElysiaKeyManager(self.settings):\n                    async for result in self.tools[rule](\n                        tree_data=self.tree_data,\n                        inputs=rule_tool_inputs[rule],\n                        base_lm=self.base_lm,\n                        complex_lm=self.complex_lm,\n                        client_manager=client_manager,\n                    ):\n                        action_result, _ = await self._evaluate_result(\n                            result, rule_decision\n                        )\n                        if action_result is not None:\n                            yield action_result\n\n        # If training route is provided, decide from the training route\n        if len(route_list) &gt; 0:\n            self.settings.logger.debug(f\"Route that will be used: {route_list}\")\n\n            (\n                self.current_decision,\n                training_route,\n            ) = current_decision_node.decide_from_route(route_list)\n\n            force_text_response = (\n                self.current_decision.function_name == \"text_response\"\n            )\n\n        # Under normal circumstances decide from the decision node\n        else:\n            self.tracker.start_tracking(\"decision_node\")\n            self.tree_data.set_current_task(\"elysia_decision_node\")\n            with ElysiaKeyManager(self.settings):\n                self.current_decision, results = await current_decision_node(\n                    tree_data=self.tree_data,\n                    base_lm=self.base_lm,\n                    complex_lm=self.complex_lm,\n                    available_tools=available_tools,\n                    unavailable_tools=unavailable_tools,\n                    successive_actions=successive_actions,\n                    client_manager=client_manager,\n                )\n\n            for result in results:\n                action_result, _ = await self._evaluate_result(\n                    result, self.current_decision\n                )\n                if action_result is not None:\n                    yield action_result\n\n            self.tracker.end_tracking(\n                \"decision_node\",\n                \"Decision Node\",\n                self.base_lm if not self.low_memory else None,\n                self.complex_lm if not self.low_memory else None,\n            )\n\n            # Force text response (later) if model chooses end actions\n            # but no response will be generated from the node, set flag now\n            force_text_response = (\n                not current_decision_node.options[\n                    self.current_decision.function_name\n                ][\"end\"]\n                and self.current_decision.end_actions\n            )\n\n        # Set default values for the function inputs for current call\n        self.current_decision.function_inputs = self._get_function_inputs(\n            self.current_decision.function_name,\n            self.current_decision.function_inputs,\n        )\n\n        # end criteria, task picked is \"text_response\" or model chooses to end conversation\n        completed = (\n            self.current_decision.function_name == \"text_response\"\n            or self.current_decision.end_actions\n            or self.current_decision.impossible\n            or self.tree_data.num_trees_completed &gt; self.tree_data.recursion_limit\n        )\n\n        # assign action function\n        action_fn: Tool | None = current_decision_node.options[\n            self.current_decision.function_name\n        ][\n            \"action\"\n        ]  # type: ignore\n\n        # update the decision history\n        self.decision_history[-1].append(self.current_decision.function_name)\n\n        # print the current node information\n        if self.settings.LOGGING_LEVEL_INT &lt;= 20:\n            print(\n                Panel.fit(\n                    f\"[bold]Node:[/bold] [magenta]{current_decision_node.id}[/magenta]\\n\"\n                    f\"[bold]Decision:[/bold] [green]{self.current_decision.function_name}[/green]\\n\"\n                    f\"[bold]Reasoning:[/bold] {self.current_decision.reasoning}\\n\",\n                    title=\"Current Decision\",\n                    border_style=\"magenta\",\n                    padding=(1, 1),\n                )\n            )\n\n        self.tree_data.update_tasks_completed(\n            prompt=self.user_prompt,\n            task=self.current_decision.function_name,\n            num_trees_completed=self.tree_data.num_trees_completed,\n            reasoning=self.current_decision.reasoning,\n            action=action_fn is not None,\n        )\n\n        # evaluate the action if this is not a branch\n        if action_fn is not None:\n            self.tracker.start_tracking(self.current_decision.function_name)\n            self.tree_data.set_current_task(self.current_decision.function_name)\n            successful_action = True\n            with ElysiaKeyManager(self.settings):\n                async for result in action_fn(\n                    tree_data=self.tree_data,\n                    inputs=self.current_decision.function_inputs,\n                    base_lm=self.base_lm,\n                    complex_lm=self.complex_lm,\n                    client_manager=client_manager,\n                    **kwargs,\n                ):\n                    action_result, error = await self._evaluate_result(\n                        result, self.current_decision\n                    )\n\n                    if action_result is not None:\n                        yield action_result\n\n                    successful_action = not error and successful_action\n\n            if not successful_action:\n                completed = (\n                    False\n                    or self.tree_data.num_trees_completed\n                    &gt; self.tree_data.recursion_limit\n                )\n\n            if successful_action:\n                self.tree_data.clear_error(self.current_decision.function_name)\n\n            self.tracker.end_tracking(\n                self.current_decision.function_name,\n                self.current_decision.function_name,\n                self.base_lm if not self.low_memory else None,\n                self.complex_lm if not self.low_memory else None,\n            )\n\n        yield (\n            await self._evaluate_result(\n                TreeUpdate(\n                    from_node=current_decision_node.id,\n                    to_node=self.current_decision.function_name,\n                    reasoning=(\n                        self.current_decision.reasoning\n                        if self.settings.BASE_USE_REASONING\n                        else \"\"\n                    ),\n                    reset_tree=current_decision_node.options[\n                        self.current_decision.function_name\n                    ][\"next\"]\n                    is None\n                    and (not completed),\n                ),\n                self.current_decision,\n            )\n        )[0]\n\n        # check if the current node is the end of the tree\n        if (\n            current_decision_node.options[self.current_decision.function_name][\n                \"next\"\n            ]\n            is None\n            or completed\n        ):\n            break\n        else:\n            current_decision_node = current_decision_node.options[\n                self.current_decision.function_name\n            ][\n                \"next\"\n            ]  # type: ignore\n\n    self.tree_data.num_trees_completed += 1\n\n    # end of all trees\n    if completed:\n\n        # firstly, if we reached the end of a tree at a node that shouldn't be the end, call text response tool here to respond\n        if (\n            not current_decision_node.options[self.current_decision.function_name][\n                \"end\"\n            ]\n            or force_text_response\n        ):\n            with ElysiaKeyManager(self.settings):\n                async for result in self.tools[\"forced_text_response\"](\n                    tree_data=self.tree_data,\n                    inputs={},\n                    base_lm=self.base_lm,\n                    complex_lm=self.complex_lm,\n                ):\n                    action_result, _ = await self._evaluate_result(\n                        result, self.current_decision\n                    )\n                    if action_result is not None:\n                        yield action_result\n\n        self.save_history(\n            query_id=self.prompt_to_query_id[user_prompt],\n            time_taken_seconds=time.time() - self.start_time,\n        )\n\n        yield await self.returner(\n            Completed(), query_id=self.prompt_to_query_id[user_prompt]\n        )\n\n        self.settings.logger.debug(\n            f\"[bold green]Model identified overall goal as completed![/bold green]\"\n        )\n        self.settings.logger.debug(\n            f\"Total time taken for decision tree: {time.time() - self.start_time:.2f} seconds\"\n        )\n        self.settings.logger.debug(\n            f\"Decision Node Avg. Time: {self.tracker.get_average_time('decision_node'):.2f} seconds\"\n        )\n        self.log_token_usage()\n\n        avg_times = []\n        for i, iteration in enumerate(self.decision_history):\n            if iteration != []:\n                avg_times = [\n                    (\n                        f\"  - {task} ([magenta]Avg. {self.tracker.get_average_time(task):.2f} seconds[/magenta])\\n\"\n                        if task in self.tracker.trackers\n                        else \"\"\n                    )\n                    for task in iteration\n                ]\n                self.settings.logger.debug(\n                    f\"Tasks completed (iteration {i+1}):\\n\" + \"\".join(avg_times)\n                )\n\n        if close_clients_after_completion and client_manager.is_client:\n            await client_manager.close_clients()\n\n    # otherwise, end of the tree for this iteration, and recursively call process() to restart the tree\n    else:\n        self.settings.logger.debug(\n            f\"Model did [bold red]not[/bold red] yet complete overall goal! \"\n        )\n        self.settings.logger.debug(\n            f\"Restarting tree (Recursion: {self.tree_data.num_trees_completed+1}/{self.tree_data.recursion_limit})...\"\n        )\n\n        # recursive call to restart the tree since the goal was not completed\n        self.decision_history.append([])\n        async for result in self.async_run(\n            user_prompt,\n            collection_names,\n            client_manager,\n            training_route=training_route,\n            query_id=query_id,\n            _first_run=False,\n        ):\n            yield result\n</code></pre>"},{"location":"Reference/Tree/#elysia.tree.tree.Tree.configure","title":"<code>configure(**kwargs)</code>","text":"<p>Configure the tree with new settings. Wrapper for the settings.configure() method. Will not affect any settings preceding this (e.g. in TreeManager).</p> Source code in <code>elysia/tree/tree.py</code> <pre><code>def configure(self, **kwargs) -&gt; None:\n    \"\"\"\n    Configure the tree with new settings.\n    Wrapper for the settings.configure() method.\n    Will not affect any settings preceding this (e.g. in TreeManager).\n    \"\"\"\n    self.settings = deepcopy(self.settings)\n    self.settings.SETTINGS_ID = str(uuid.uuid4())\n    self._config_modified = True\n    self.tree_data.settings = self.settings\n    self.settings.configure(**kwargs)\n</code></pre>"},{"location":"Reference/Tree/#elysia.tree.tree.Tree.create_conversation_title","title":"<code>create_conversation_title()</code>","text":"<p>Create a title for the tree using the base LM. Also assigns the <code>conversation_title</code> attribute to the tree.</p> <p>Returns:</p> Type Description <code>str</code> <p>The title for the tree.</p> Source code in <code>elysia/tree/tree.py</code> <pre><code>def create_conversation_title(self) -&gt; str:\n    \"\"\"\n    Create a title for the tree using the base LM.\n    Also assigns the `conversation_title` attribute to the tree.\n\n    Returns:\n        (str): The title for the tree.\n    \"\"\"\n    return asyncio_run(self.create_conversation_title_async())\n</code></pre>"},{"location":"Reference/Tree/#elysia.tree.tree.Tree.create_conversation_title_async","title":"<code>create_conversation_title_async()</code>  <code>async</code>","text":"<p>Create a title for the tree (async) using the base LM. Also assigns the <code>conversation_title</code> attribute to the tree.</p> <p>Returns:</p> Type Description <code>str</code> <p>The title for the tree.</p> Source code in <code>elysia/tree/tree.py</code> <pre><code>async def create_conversation_title_async(self) -&gt; str:\n    \"\"\"\n    Create a title for the tree (async) using the base LM.\n    Also assigns the `conversation_title` attribute to the tree.\n\n    Returns:\n        (str): The title for the tree.\n    \"\"\"\n    with ElysiaKeyManager(self.settings):\n        self.conversation_title = await create_conversation_title(\n            self.tree_data.conversation_history, self.base_lm\n        )\n    return self.conversation_title\n</code></pre>"},{"location":"Reference/Tree/#elysia.tree.tree.Tree.detailed_memory_usage","title":"<code>detailed_memory_usage()</code>","text":"<p>Returns a detailed breakdown of memory usage for all major objects in the Tree class.</p> <p>Returns:</p> Name Type Description <code>dict</code> <code>dict</code> <p>Dictionary containing memory sizes (in bytes) for each major component</p> Source code in <code>elysia/tree/tree.py</code> <pre><code>def detailed_memory_usage(self) -&gt; dict:\n    \"\"\"\n    Returns a detailed breakdown of memory usage for all major objects in the Tree class.\n\n    Returns:\n        dict: Dictionary containing memory sizes (in bytes) for each major component\n    \"\"\"\n    memory_usage = {}\n\n    # Core data structures\n    memory_usage[\"tree_data\"] = asizeof.asizeof(self.tree_data)\n    memory_usage[\"tree_data\"] = asizeof.asizeof(self.tree_data)\n    memory_usage[\"tree_data\"] = asizeof.asizeof(self.tree_data)\n    memory_usage[\"collection_data\"] = asizeof.asizeof(\n        self.tree_data.collection_data\n    )\n\n    # Decision nodes and tools\n    memory_usage[\"decision_nodes\"] = {\n        node_id: asizeof.asizeof(node)\n        for node_id, node in self.decision_nodes.items()\n    }\n    memory_usage[\"tools\"] = {\n        tool_name: asizeof.asizeof(tool) for tool_name, tool in self.tools.items()\n    }\n\n    # History and tracking\n    memory_usage[\"decision_history\"] = asizeof.asizeof(self.decision_history)\n    memory_usage[\"history\"] = asizeof.asizeof(self.history)\n    memory_usage[\"training_updates\"] = asizeof.asizeof(self.training_updates)\n    memory_usage[\"action_information\"] = asizeof.asizeof(self.action_information)\n\n    # Mapping dictionaries\n    memory_usage[\"query_mappings\"] = {\n        \"query_id_to_prompt\": asizeof.asizeof(self.query_id_to_prompt),\n        \"prompt_to_query_id\": asizeof.asizeof(self.prompt_to_query_id),\n    }\n\n    # Calculate total\n    memory_usage[\"total\"] = sum(\n        (v if isinstance(v, int) else sum(v.values()) if isinstance(v, dict) else 0)\n        for v in memory_usage.values()\n    )\n\n    return memory_usage\n</code></pre>"},{"location":"Reference/Tree/#elysia.tree.tree.Tree.export_to_json","title":"<code>export_to_json()</code>","text":"<p>Export the tree to a JSON object, to be used for loading the tree via import_from_json().</p> <p>Returns:</p> Type Description <code>dict</code> <p>The JSON object.</p> Source code in <code>elysia/tree/tree.py</code> <pre><code>def export_to_json(self) -&gt; dict:\n    \"\"\"\n    Export the tree to a JSON object, to be used for loading the tree via import_from_json().\n\n    Returns:\n        (dict): The JSON object.\n    \"\"\"\n    try:\n        return {\n            \"user_id\": self.user_id,\n            \"conversation_id\": self.conversation_id,\n            \"conversation_title\": self.conversation_title,\n            \"branch_initialisation\": self.branch_initialisation,\n            \"use_elysia_collections\": self.use_elysia_collections,\n            \"tree_index\": self.tree_index,\n            \"store_retrieved_objects\": self.store_retrieved_objects,\n            \"low_memory\": self.low_memory,\n            \"tree_data\": self.tree_data.to_json(remove_unserialisable=True),\n            \"settings\": self.settings.to_json(),\n            \"tool_names\": list(self.tools.keys()),\n            \"frontend_rebuild\": self.returner.store,\n        }\n    except Exception as e:\n        self.settings.logger.error(f\"Error exporting tree to JSON: {str(e)}\")\n        raise e\n</code></pre>"},{"location":"Reference/Tree/#elysia.tree.tree.Tree.export_to_weaviate","title":"<code>export_to_weaviate(collection_name, client_manager=None)</code>  <code>async</code>","text":"<p>Export the tree to a Weaviate collection.</p> <p>Parameters:</p> Name Type Description Default <code>collection_name</code> <code>str</code> <p>The name of the collection to export to.</p> required <code>client_manager</code> <code>ClientManager</code> <p>The client manager to use. If not provided, a new ClientManager will be created from environment variables.</p> <code>None</code> Source code in <code>elysia/tree/tree.py</code> <pre><code>async def export_to_weaviate(\n    self, collection_name: str, client_manager: ClientManager | None = None\n) -&gt; None:\n    \"\"\"\n    Export the tree to a Weaviate collection.\n\n    Args:\n        collection_name (str): The name of the collection to export to.\n        client_manager (ClientManager): The client manager to use.\n            If not provided, a new ClientManager will be created from environment variables.\n    \"\"\"\n    if client_manager is None:\n        client_manager = ClientManager()\n        close_after_use = True\n    else:\n        close_after_use = False\n\n    async with client_manager.connect_to_async_client() as client:\n\n        if not await client.collections.exists(collection_name):\n            await client.collections.create(\n                collection_name,\n                vectorizer_config=wc.Configure.Vectorizer.none(),\n                inverted_index_config=wc.Configure.inverted_index(\n                    index_timestamps=True\n                ),\n                properties=[\n                    wc.Property(\n                        name=\"user_id\",\n                        data_type=wc.DataType.TEXT,\n                    ),\n                    wc.Property(\n                        name=\"conversation_id\",\n                        data_type=wc.DataType.TEXT,\n                    ),\n                    wc.Property(\n                        name=\"tree\",\n                        data_type=wc.DataType.TEXT,\n                    ),\n                    wc.Property(\n                        name=\"title\",\n                        data_type=wc.DataType.TEXT,\n                    ),\n                ],\n            )\n\n        collection = client.collections.get(collection_name)\n\n        json_data_str = json.dumps(self.export_to_json())\n\n        uuid = generate_uuid5(self.conversation_id)\n\n        if await collection.data.exists(uuid):\n            await collection.data.update(\n                uuid=uuid,\n                properties={\n                    \"user_id\": self.user_id,\n                    \"conversation_id\": self.conversation_id,\n                    \"tree\": json_data_str,\n                    \"title\": self.conversation_title,\n                },\n            )\n            self.settings.logger.info(\n                f\"Successfully updated existing tree in collection '{collection_name}' with id '{self.conversation_id}'\"\n            )\n        else:\n            await collection.data.insert(\n                uuid=uuid,\n                properties={\n                    \"user_id\": self.user_id,\n                    \"conversation_id\": self.conversation_id,\n                    \"tree\": json_data_str,\n                    \"title\": self.conversation_title,\n                },\n            )\n            self.settings.logger.info(\n                f\"Successfully inserted new tree in collection '{collection_name}' with id '{self.conversation_id}'\"\n            )\n\n    if close_after_use:\n        await client_manager.close_clients()\n</code></pre>"},{"location":"Reference/Tree/#elysia.tree.tree.Tree.get_follow_up_suggestions","title":"<code>get_follow_up_suggestions(context=None, num_suggestions=2)</code>","text":"<p>Get follow-up suggestions for the current user prompt via a base model LLM call (sync wrapper for get_follow_up_suggestions_async).</p> <p>E.g., if the user asks \"What was the most recent Github Issue?\",     and the results show a message from 'Jane Doe',     the follow-up suggestions might be \"What other issues did Jane Doe work on?\"</p> <p>Parameters:</p> Name Type Description Default <code>context</code> <code>str | None</code> <p>A description of the type of follow-up questions to suggest</p> <code>None</code> <code>num_suggestions</code> <code>int</code> <p>The number of follow-up suggestions to return (length of the list output)</p> <code>2</code> <p>Returns:</p> Type Description <code>list[str]</code> <p>A list of follow-up suggestions</p> Source code in <code>elysia/tree/tree.py</code> <pre><code>def get_follow_up_suggestions(\n    self,\n    context: str | None = None,\n    num_suggestions: int = 2,\n) -&gt; list[str]:\n    \"\"\"\n    Get follow-up suggestions for the current user prompt via a base model LLM call (sync wrapper for get_follow_up_suggestions_async).\n\n    E.g., if the user asks \"What was the most recent Github Issue?\",\n        and the results show a message from 'Jane Doe',\n        the follow-up suggestions might be \"What other issues did Jane Doe work on?\"\n\n    Args:\n        context (str | None): A description of the type of follow-up questions to suggest\n        num_suggestions (int): The number of follow-up suggestions to return (length of the list output)\n\n    Returns:\n        (list[str]): A list of follow-up suggestions\n    \"\"\"\n    return asyncio_run(\n        self.get_follow_up_suggestions_async(context, num_suggestions)\n    )\n</code></pre>"},{"location":"Reference/Tree/#elysia.tree.tree.Tree.get_follow_up_suggestions_async","title":"<code>get_follow_up_suggestions_async(context=None, num_suggestions=2)</code>  <code>async</code>","text":"<p>Get follow-up suggestions for the current user prompt via a base model LLM call.</p> <p>E.g., if the user asks \"What was the most recent Github Issue?\",     and the results show a message from 'Jane Doe',     the follow-up suggestions might be \"What other issues did Jane Doe work on?\"</p> <p>Parameters:</p> Name Type Description Default <code>context</code> <code>str | None</code> <p>A description of the type of follow-up questions to suggest</p> <code>None</code> <code>num_suggestions</code> <code>int</code> <p>The number of follow-up suggestions to return (length of the list output)</p> <code>2</code> <p>Returns:</p> Type Description <code>list[str]</code> <p>A list of follow-up suggestions</p> Source code in <code>elysia/tree/tree.py</code> <pre><code>async def get_follow_up_suggestions_async(\n    self, context: str | None = None, num_suggestions: int = 2\n) -&gt; list[str]:\n    \"\"\"\n    Get follow-up suggestions for the current user prompt via a base model LLM call.\n\n    E.g., if the user asks \"What was the most recent Github Issue?\",\n        and the results show a message from 'Jane Doe',\n        the follow-up suggestions might be \"What other issues did Jane Doe work on?\"\n\n    Args:\n        context (str | None): A description of the type of follow-up questions to suggest\n        num_suggestions (int): The number of follow-up suggestions to return (length of the list output)\n\n    Returns:\n        (list[str]): A list of follow-up suggestions\n    \"\"\"\n    with ElysiaKeyManager(self.settings):\n        suggestions = await get_follow_up_suggestions(\n            self.tree_data,\n            self.suggestions,\n            self.base_lm,\n            context=context,\n            num_suggestions=num_suggestions,\n        )\n    if suggestions != []:\n        self.settings.logger.debug(f\"Follow-up suggestions: {suggestions}\")\n    else:\n        self.settings.logger.error(\"No follow-up suggestions found.\")\n\n    self.suggestions.extend(suggestions)\n    return suggestions\n</code></pre>"},{"location":"Reference/Tree/#elysia.tree.tree.Tree.import_from_json","title":"<code>import_from_json(json_data)</code>  <code>classmethod</code>","text":"<p>Import a tree from a JSON object, outputted by the export_to_json() method.</p> <p>Parameters:</p> Name Type Description Default <code>json_data</code> <code>dict</code> <p>The JSON object to import the tree from.</p> required <p>Returns:</p> Type Description <code>Tree</code> <p>The new tree instance loaded from the JSON object.</p> Source code in <code>elysia/tree/tree.py</code> <pre><code>@classmethod\ndef import_from_json(cls, json_data: dict) -&gt; \"Tree\":\n    \"\"\"\n    Import a tree from a JSON object, outputted by the export_to_json() method.\n\n    Args:\n        json_data (dict): The JSON object to import the tree from.\n\n    Returns:\n        (Tree): The new tree instance loaded from the JSON object.\n    \"\"\"\n    settings = Settings.from_json(json_data[\"settings\"])\n    logger = settings.logger\n    tree = cls(\n        user_id=json_data[\"user_id\"],\n        conversation_id=json_data[\"conversation_id\"],\n        branch_initialisation=json_data[\"branch_initialisation\"],\n        style=json_data[\"tree_data\"][\"atlas\"][\"style\"],\n        agent_description=json_data[\"tree_data\"][\"atlas\"][\"agent_description\"],\n        end_goal=json_data[\"tree_data\"][\"atlas\"][\"end_goal\"],\n        low_memory=json_data[\"low_memory\"],\n        use_elysia_collections=json_data[\"use_elysia_collections\"],\n        settings=settings,\n    )\n\n    tree.returner.store = json_data[\"frontend_rebuild\"]\n    tree.tree_data = TreeData.from_json(json_data[\"tree_data\"])\n    tree.set_branch_initialisation(json_data[\"branch_initialisation\"])\n\n    # check tools\n    for tool_name in json_data[\"tool_names\"]:\n        if tool_name not in tree.tools:\n            logger.warning(\n                f\"In saved tree, custom tool '{tool_name}' found. \"\n                \"This will not be loaded in the new tree. \"\n                \"You will need to add it to the tree manually.\"\n            )\n\n    return tree\n</code></pre>"},{"location":"Reference/Tree/#elysia.tree.tree.Tree.import_from_weaviate","title":"<code>import_from_weaviate(collection_name, conversation_id, client_manager=None)</code>  <code>async</code> <code>classmethod</code>","text":"<p>Import a tree from a Weaviate collection.</p> <p>Parameters:</p> Name Type Description Default <code>collection_name</code> <code>str</code> <p>The name of the collection to import from.</p> required <code>conversation_id</code> <code>str</code> <p>The id of the conversation to import.</p> required <code>client_manager</code> <code>ClientManager</code> <p>The client manager to use. If not provided, a new ClientManager will be created from environment variables.</p> <code>None</code> <p>Returns:</p> Type Description <code>Tree</code> <p>The tree object.</p> Source code in <code>elysia/tree/tree.py</code> <pre><code>@classmethod\nasync def import_from_weaviate(\n    cls,\n    collection_name: str,\n    conversation_id: str,\n    client_manager: ClientManager | None = None,\n) -&gt; \"Tree\":\n    \"\"\"\n    Import a tree from a Weaviate collection.\n\n    Args:\n        collection_name (str): The name of the collection to import from.\n        conversation_id (str): The id of the conversation to import.\n        client_manager (ClientManager): The client manager to use.\n            If not provided, a new ClientManager will be created from environment variables.\n\n    Returns:\n        (Tree): The tree object.\n    \"\"\"\n\n    if client_manager is None:\n        client_manager = ClientManager()\n        close_after_use = True\n    else:\n        close_after_use = False\n\n    async with client_manager.connect_to_async_client() as client:\n\n        if not await client.collections.exists(collection_name):\n            raise ValueError(\n                f\"Collection '{collection_name}' does not exist in this Weaviate instance.\"\n            )\n\n        collection = client.collections.get(collection_name)\n        uuid = generate_uuid5(conversation_id)\n        # if not await collection.data.exists(uuid):\n        #     raise ValueError(\n        #         f\"No tree found for conversation id '{conversation_id}' in collection '{collection_name}'.\"\n        #     )\n\n        response = await collection.query.fetch_object_by_id(uuid)\n\n    if close_after_use:\n        await client_manager.close_clients()\n\n    if response is None:\n        raise ValueError(\n            f\"No tree found for conversation id '{conversation_id}' in collection '{collection_name}'.\"\n        )\n\n    json_data_str = response.properties[\"tree\"]\n    json_data = json.loads(json_data_str)  # type: ignore\n\n    return cls.import_from_json(json_data)\n</code></pre>"},{"location":"Reference/Tree/#elysia.tree.tree.Tree.remove_branch","title":"<code>remove_branch(branch_id)</code>","text":"<p>Remove a branch from the tree.</p> <p>Parameters:</p> Name Type Description Default <code>branch_id</code> <code>str</code> <p>The id of the branch to remove</p> required Source code in <code>elysia/tree/tree.py</code> <pre><code>def remove_branch(self, branch_id: str) -&gt; None:\n    \"\"\"\n    Remove a branch from the tree.\n\n    Args:\n        branch_id (str): The id of the branch to remove\n    \"\"\"\n    # Validate branch exists\n    if branch_id not in self.decision_nodes:\n        self.settings.logger.warning(\n            f\"Branch {branch_id} not found, nothing to remove.\"\n        )\n        return\n\n    # Special handling for root node\n    if (\n        branch_id == self.root\n        and sum(1 for node in self.decision_nodes.values() if node.root) == 1\n    ):\n        self.settings.logger.error(\n            \"Cannot remove root branch if there is only one root branch.\"\n        )\n        raise ValueError(\n            \"Cannot remove the root branch when there is only one root branch. \"\n            \"Create a new root branch via .add_branch(..., root=True) first. \"\n            \"(You could be trying to replace a root branch with the same ID as the one you are trying to remove. \"\n            \"Try a different name for the new root branch.)\"\n        )\n\n    for decision_node_id in self.decision_nodes:\n        self.decision_nodes[decision_node_id].remove_option(branch_id)\n\n    if branch_id in self.decision_nodes:\n        del self.decision_nodes[branch_id]\n\n    # reconstruct tree\n    self._get_root()\n    self.tree = {}\n    self._construct_tree(self.root, self.tree)\n</code></pre>"},{"location":"Reference/Tree/#elysia.tree.tree.Tree.remove_tool","title":"<code>remove_tool(tool_name, branch_id=None, from_tool_ids=[], root=False)</code>","text":"<p>Remove a Tool from a branch.</p> <p>Parameters:</p> Name Type Description Default <code>tool_name</code> <code>str</code> <p>The name of the tool to remove.</p> required <code>branch_id</code> <code>str</code> <p>The id of the branch to remove the tool from, if not specified, the tool will be removed from the root branch.</p> <code>None</code> <code>from_tool_ids</code> <code>list[str]</code> <p>The ids of the tools to which precedes the tool to remove.</p> <code>[]</code> <code>root</code> <code>bool</code> <p>Whether the branch the tool is in is the root branch.</p> <code>False</code> Source code in <code>elysia/tree/tree.py</code> <pre><code>def remove_tool(\n    self,\n    tool_name: str,\n    branch_id: str | None = None,\n    from_tool_ids: list[str] = [],\n    root: bool = False,\n) -&gt; None:\n    \"\"\"\n    Remove a Tool from a branch.\n\n    Args:\n        tool_name (str): The name of the tool to remove.\n        branch_id (str): The id of the branch to remove the tool from,\n            if not specified, the tool will be removed from the root branch.\n        from_tool_ids (list[str]): The ids of the tools to which precedes the tool to remove.\n        root (bool): Whether the branch the tool is in is the root branch.\n    \"\"\"\n    if root:\n        if branch_id is not None:\n            self.settings.logger.warning(\n                f\"In .add_tool(), `root` is True, so `branch_id` ('{branch_id}') will be ignored. \"\n                f\"Tool: '{tool_name}' will be removed from the root branch ('{self.root}').\"\n            )\n        branch_id = self.root\n\n    if branch_id is None:\n        branch_id = self.root\n\n    if branch_id not in self.decision_nodes:\n        raise ValueError(f\"Branch {branch_id} not found.\")\n\n    if (\n        tool_name not in self.decision_nodes[branch_id].options\n        and from_tool_ids == []\n    ):\n        raise ValueError(f\"Tool {tool_name} not found in branch {branch_id}.\")\n\n    current_decision_node = self.decision_nodes[branch_id]\n    for from_tool_id in from_tool_ids:\n        if isinstance(current_decision_node, DecisionNode):\n            if from_tool_id not in current_decision_node.options:\n                raise ValueError(\n                    f\"Tool '{from_tool_id}' not found in branch '{current_decision_node.id}'. \"\n                    f\"Available options are: {list(current_decision_node.options.keys())}\"\n                )\n            current_decision_node = current_decision_node.options[from_tool_id][\n                \"next\"\n            ]\n\n    if (\n        isinstance(current_decision_node, DecisionNode)\n        and tool_name not in current_decision_node.options\n    ):\n        raise ValueError(\n            f\"Tool '{tool_name}' not found in branch '{current_decision_node.id}'. \"\n            f\"Available options are: {list(current_decision_node.options.keys())}\"\n        )\n\n    if from_tool_ids == []:\n        self.decision_nodes[branch_id].remove_option(tool_name)\n    else:\n        tool_branch_id = branch_id\n        for from_tool_id in from_tool_ids:\n            tool_branch_id += f\".{from_tool_id}\"\n        tool_branch_id += f\".{tool_name}\"\n\n        prev_branch_id = branch_id\n        for from_tool_id in from_tool_ids:\n            prev_branch_id += f\".{from_tool_id}\"\n\n        self.decision_nodes[prev_branch_id].remove_option(tool_name)\n        if self.decision_nodes[prev_branch_id].options == {}:\n            del self.decision_nodes[prev_branch_id]\n            stem_branch_id = prev_branch_id[: prev_branch_id.rfind(\".\")]\n            for stem_branch_option in self.decision_nodes[\n                stem_branch_id\n            ].options.values():\n                if (\n                    stem_branch_option[\"next\"] is not None\n                    and isinstance(stem_branch_option[\"next\"], DecisionNode)\n                    and stem_branch_option[\"next\"].id == prev_branch_id\n                ):\n                    stem_branch_option[\"next\"] = None\n\n        if (\n            tool_branch_id in self.decision_nodes\n            and self.decision_nodes[tool_branch_id].options != {}\n        ):\n            self.settings.logger.warning(\n                f\"The following tools stem from '{tool_branch_id}', \"\n                f\"and have also been removed: {list(self.decision_nodes[tool_branch_id].options.keys())}\"\n            )\n\n        # find any decision nodes that stem from this\n        nodes_to_remove = []\n        for decision_node_id in self.decision_nodes:\n            if decision_node_id.startswith(tool_branch_id):\n                if decision_node_id != tool_branch_id:\n                    self.settings.logger.warning(\n                        f\"Decision node '{decision_node_id}' stems from '{tool_branch_id}'. \"\n                        f\"Removing tool '{tool_name}' has also removed '{decision_node_id}'.\"\n                    )\n                nodes_to_remove.append(decision_node_id)\n\n        for decision_node_id in nodes_to_remove:\n            del self.decision_nodes[decision_node_id]\n\n    del self.tools[tool_name]\n    self.tracker.remove_tracker(tool_name)\n\n    # reconstruct tree\n    self._get_root()\n    self.tree = {}\n    self._construct_tree(self.root, self.tree)\n</code></pre>"},{"location":"Reference/Tree/#elysia.tree.tree.Tree.run","title":"<code>run(user_prompt, collection_names=[], client_manager=None, training_route='', query_id=None, close_clients_after_completion=True)</code>","text":"<p>Run the Elysia decision tree.</p> <p>Parameters:</p> Name Type Description Default <code>user_prompt</code> <code>str</code> <p>The input from the user.</p> required <code>collection_names</code> <code>list[str]</code> <p>The names of the collections to use. If not provided, Elysia will attempt to retrieve all collection names from the client.</p> <code>[]</code> <code>client_manager</code> <code>ClientManager</code> <p>The client manager to use. If not provided, a new ClientManager will be created.</p> <code>None</code> <code>training_route</code> <code>str</code> <p>The route to use for training. Separate tools/branches you want to use with a \"/\". e.g. \"query/text_response\" will only use the \"query\" tool and the \"text_response\" tool, and end the tree there.</p> <code>''</code> <code>query_id</code> <code>str</code> <p>The id of the query. Only necessary if you are hosting Elysia on a server with multiple users. If not provided, a new query id will be generated.</p> <code>None</code> <code>close_clients_after_completion</code> <code>bool</code> <p>Whether to close the clients after the tree is completed. Leave as True for most use cases, but if you don't want to close the clients for the ClientManager, set to False. For example, if you are managing your own clients (e.g. in an app), you may want to set this to False.</p> <code>True</code> <p>Returns:</p> Type Description <code>str</code> <p>The concatenation of all the responses from the tree.</p> <code>list[dict]</code> <p>The retrieved objects from the tree.</p> Source code in <code>elysia/tree/tree.py</code> <pre><code>def run(\n    self,\n    user_prompt: str,\n    collection_names: list[str] = [],\n    client_manager: ClientManager | None = None,\n    training_route: str = \"\",\n    query_id: str | None = None,\n    close_clients_after_completion: bool = True,\n) -&gt; tuple[str, list[dict]]:\n    \"\"\"\n    Run the Elysia decision tree.\n\n    Args:\n        user_prompt (str): The input from the user.\n        collection_names (list[str]): The names of the collections to use.\n            If not provided, Elysia will attempt to retrieve all collection names from the client.\n        client_manager (ClientManager): The client manager to use.\n            If not provided, a new ClientManager will be created.\n        training_route (str): The route to use for training.\n            Separate tools/branches you want to use with a \"/\".\n            e.g. \"query/text_response\" will only use the \"query\" tool and the \"text_response\" tool, and end the tree there.\n        query_id (str): The id of the query.\n            Only necessary if you are hosting Elysia on a server with multiple users.\n            If not provided, a new query id will be generated.\n        close_clients_after_completion (bool): Whether to close the clients after the tree is completed.\n            Leave as True for most use cases, but if you don't want to close the clients for the ClientManager, set to False.\n            For example, if you are managing your own clients (e.g. in an app), you may want to set this to False.\n\n    Returns:\n        (str): The concatenation of all the responses from the tree.\n        (list[dict]): The retrieved objects from the tree.\n    \"\"\"\n\n    self.store_retrieved_objects = True\n\n    async def run_process():\n        async for result in self.async_run(\n            user_prompt,\n            collection_names,\n            client_manager,\n            training_route,\n            query_id,\n            close_clients_after_completion,\n        ):\n            pass\n        return self.retrieved_objects\n\n    async def run_with_live():\n        console = Console()\n\n        with console.status(\"[bold indigo]Thinking...\") as status:\n            async for result in self.async_run(\n                user_prompt,\n                collection_names,\n                client_manager,\n                training_route,\n                query_id,\n                close_clients_after_completion,\n            ):\n                if (\n                    result is not None\n                    and \"type\" in result\n                    and result[\"type\"] == \"status\"\n                    and isinstance(result[\"payload\"], dict)\n                    and \"text\" in result[\"payload\"]\n                ):\n                    payload: dict = result[\"payload\"]  # type: ignore\n                    status.update(f\"[bold indigo]{payload['text']}\")\n\n        return self.retrieved_objects\n\n    if self.settings.LOGGING_LEVEL_INT &lt;= 20:\n        yielded_results = asyncio_run(run_with_live())\n    else:\n        yielded_results = asyncio_run(run_process())\n\n    text = self.tree_data.conversation_history[-1][\"content\"]\n\n    return text, yielded_results\n</code></pre>"},{"location":"Reference/Tree/#elysia.tree.tree.Tree.save_history","title":"<code>save_history(query_id, time_taken_seconds)</code>","text":"<p>What the tree did, results for saving feedback.</p> Source code in <code>elysia/tree/tree.py</code> <pre><code>def save_history(self, query_id: str, time_taken_seconds: float) -&gt; None:\n    \"\"\"\n    What the tree did, results for saving feedback.\n    \"\"\"\n    training_update = deepcopy(\n        [update.to_json() for update in self.training_updates]\n    )\n\n    self.history[query_id] = {\n        \"num_trees_completed\": self.tree_data.num_trees_completed,\n        \"tree_data\": deepcopy(self.tree_data),\n        \"action_information\": deepcopy(self.action_information),\n        \"decision_history\": [\n            item for sublist in deepcopy(self.decision_history) for item in sublist\n        ],\n        \"base_lm_used\": self.settings.BASE_MODEL,\n        \"complex_lm_used\": self.settings.COMPLEX_MODEL,\n        \"time_taken_seconds\": time_taken_seconds,\n        \"training_updates\": training_update,\n        \"initialisation\": f\"{self.branch_initialisation}\",\n    }\n    # can reset training updates now\n    self.training_updates = []\n</code></pre>"},{"location":"Reference/Tree/#elysia.tree.tree.Tree.smart_setup","title":"<code>smart_setup()</code>","text":"<p>Configures the <code>settings</code> object of the tree with the <code>Settings.smart_setup()</code> method.</p> Source code in <code>elysia/tree/tree.py</code> <pre><code>def smart_setup(self) -&gt; None:\n    \"\"\"\n    Configures the `settings` object of the tree with the `Settings.smart_setup()` method.\n    \"\"\"\n\n    self.settings = deepcopy(self.settings)\n    self.settings.SETTINGS_ID = str(uuid.uuid4())\n    self._config_modified = True\n    self.settings.smart_setup()\n</code></pre>"},{"location":"Reference/Tree/#elysia.tree.tree.Tree.view","title":"<code>view(indent=0, prefix='', max_width=80, tree_dict=None)</code>","text":"<p>Format a tree dictionary into a nice hierarchical text representation.</p> <p>Parameters:</p> Name Type Description Default <code>tree_dict</code> <code>dict | None</code> <p>The tree dictionary to format</p> <code>None</code> <code>indent</code> <code>int</code> <p>Current indentation level</p> <code>0</code> <code>prefix</code> <code>str</code> <p>Prefix for the current line (for tree structure visualization)</p> <code>''</code> <code>max_width</code> <code>int</code> <p>Maximum width for text wrapping</p> <code>80</code> <p>Returns:</p> Name Type Description <code>str</code> <p>Formatted tree string</p> Source code in <code>elysia/tree/tree.py</code> <pre><code>def view(\n    self,\n    indent: int = 0,\n    prefix: str = \"\",\n    max_width: int = 80,\n    tree_dict: dict | None = None,\n):\n    \"\"\"\n    Format a tree dictionary into a nice hierarchical text representation.\n\n    Args:\n        tree_dict: The tree dictionary to format\n        indent: Current indentation level\n        prefix: Prefix for the current line (for tree structure visualization)\n        max_width: Maximum width for text wrapping\n\n    Returns:\n        str: Formatted tree string\n    \"\"\"\n    if tree_dict is None:\n        tree_dict = self.tree\n\n    result = []\n\n    name = tree_dict.get(\"name\", \"Unknown\")\n    node_id = tree_dict.get(\"id\", \"\")\n    description = tree_dict.get(\"description\", \"\")\n    is_branch = tree_dict.get(\"branch\", False)\n\n    indent_str = \"  \" * indent\n    node_line = (\n        f\"{indent_str}{prefix}\ud83d\udcc1 {name}\"\n        if is_branch\n        else f\"{indent_str}{prefix}\ud83d\udd27 {name}\"\n    )\n\n    result.append(node_line)\n\n    if description:\n        desc_indent = len(indent_str) + 4  # Extra space for description\n        available_width = max_width - desc_indent\n\n        wrapped_desc = textwrap.fill(\n            description,\n            width=available_width,\n            initial_indent=\"\",\n            subsequent_indent=\"\",\n        )\n\n        for i, line in enumerate(wrapped_desc.split(\"\\n\")):\n            if i == 0:\n                result.append(f\"{indent_str}    \ud83d\udcac {line}\")\n            else:\n                result.append(f\"{indent_str}       {line}\")\n\n        result.append(\"\")\n\n    options = tree_dict.get(\"options\", {})\n    if options:\n        option_items = list(options.items())\n        for i, (key, option) in enumerate(option_items):\n            is_last = i == len(option_items) - 1\n            child_prefix = \"\u2514\u2500\u2500 \" if is_last else \"\u251c\u2500\u2500 \"\n            child_result = self.view(\n                indent + 1, child_prefix, max_width, tree_dict=option\n            )\n            result.append(child_result)\n\n            if indent == 0 and not is_last:\n                result.append(\"\")\n\n    return \"\\n\".join(result)\n</code></pre>"},{"location":"Reference/Util/","title":"Util","text":""},{"location":"Reference/Util/#elysia.util.elysia_chain_of_thought.ElysiaChainOfThought","title":"<code>ElysiaChainOfThought</code>","text":"<p>               Bases: <code>Module</code></p> <p>A custom reasoning DSPy module that reasons step by step in order to predict the output of a task. It will automatically include the most relevant inputs: - The user's prompt - The conversation history - The atlas - Any errors (from calls of the same tool)</p> <p>And you can also include optional inputs (by setting their boolean flags on initialisation to <code>True</code>): - The environment - The collection schemas - The tasks completed</p> <p>You can also specify <code>collection_names</code> to only include certain collections in the collection schemas.</p> <p>It will optionally output (by setting the boolean flags on initialisation to <code>True</code>): - The reasoning (model step by step reasoning) - A message update (if <code>message_update</code> is <code>True</code>), a brief 'update' message to the user. - Whether the task is impossible (boolean)</p> <p>You can use this module by calling the <code>.aforward()</code> method, passing all your new inputs as keyword arguments. You do not need to include keyword arguments for the other inputs, like the <code>environment</code>.</p> <p>Example: <pre><code>my_module = ElysiaChainOfThought(\n    signature=...,\n    tree_data=...,\n    message_update=True,\n    environment=True,\n    collection_schemas=True,\n    tasks_completed=True,\n)\nmy_module.aforward(input1=..., input2=..., lm=...)\n</code></pre></p> Source code in <code>elysia/util/elysia_chain_of_thought.py</code> <pre><code>class ElysiaChainOfThought(Module):\n    \"\"\"\n    A custom reasoning DSPy module that reasons step by step in order to predict the output of a task.\n    It will automatically include the most relevant inputs:\n    - The user's prompt\n    - The conversation history\n    - The atlas\n    - Any errors (from calls of the same tool)\n\n    And you can also include optional inputs (by setting their boolean flags on initialisation to `True`):\n    - The environment\n    - The collection schemas\n    - The tasks completed\n\n    You can also specify `collection_names` to only include certain collections in the collection schemas.\n\n    It will optionally output (by setting the boolean flags on initialisation to `True`):\n    - The reasoning (model step by step reasoning)\n    - A message update (if `message_update` is `True`), a brief 'update' message to the user.\n    - Whether the task is impossible (boolean)\n\n    You can use this module by calling the `.aforward()` method, passing all your *new* inputs as keyword arguments.\n    You do not need to include keyword arguments for the other inputs, like the `environment`.\n\n    Example:\n    ```python\n    my_module = ElysiaChainOfThought(\n        signature=...,\n        tree_data=...,\n        message_update=True,\n        environment=True,\n        collection_schemas=True,\n        tasks_completed=True,\n    )\n    my_module.aforward(input1=..., input2=..., lm=...)\n    ```\n    \"\"\"\n\n    def __init__(\n        self,\n        signature: Type[Signature],\n        tree_data: TreeData,\n        reasoning: bool = True,\n        impossible: bool = True,\n        message_update: bool = True,\n        environment: bool = False,\n        collection_schemas: bool = False,\n        tasks_completed: bool = False,\n        collection_names: list[str] = [],\n        **config,\n    ):\n        \"\"\"\n        Args:\n            signature (Type[dspy.Signature]): The signature of the module.\n            tree_data (TreeData): Required. The tree data from the Elysia decision tree.\n                Used to input the current state of the tree into the prompt.\n                If you are using this module as part of a tool, the `tree_data` is an input to the tool call.\n            reasoning (bool): Whether to include a reasoning input (chain of thought).\n            impossible (bool): Whether to include a boolean flag indicating whether the task is impossible.\n                This is useful for stopping the tree from continuing and returning to the base of the decision tree.\n                For example, the model judges a query impossible to execute, or the user has not provided enough information.\n            message_update (bool): Whether to include a message update input.\n                If True, the LLM output will include a brief 'update' message to the user.\n                This describes the current action the LLM is performing.\n                Designed to increase interactivity and provide the user with information before the final output.\n            environment (bool): Whether to include an environment input.\n                If True, the module will include the currently stored data from previous tasks and actions into the prompt.\n                This is useful so that the LLM knows what has already been done, and can avoid repeating actions.\n                Or to use information from the environment to perform the new action.\n            collection_schemas (bool): Whether to include a collection schema input.\n                If True, the module will include the preprocessed collection schemas in the prompt input.\n                This is useful so that the LLM knows the structure of the collections, if querying or similar.\n                Use this sparingly, as it will use a large amount of tokens.\n                You can specify `collection_names` to only include certain collections in this schema.\n            tasks_completed (bool): Whether to include a tasks completed input.\n                If True, the module will include the list of tasks completed input.\n                This is a nicely formatted list of the tasks that have been completed, with the reasoning for each task.\n                This is used so that the LLM has a 'stream of consciousness' of what has already been done,\n                as well as to stop it from repeating actions.\n                Other information is included in the `tasks_completed` field that format outputs from previous tasks.\n                This is useful for continuing a decision logic across tasks, or to reinforce key information.\n            collection_names (list[str]): A list of collection names to include in the prompt.\n                If provided, this will modify the collection schema input to only include the collections in this list.\n                This is useful if you only want to include certain collections in the prompt.\n                And to reduce token usage.\n            **config (Any): The DSPy configuration for the module.\n        \"\"\"\n\n        super().__init__()\n\n        signature = ensure_signature(signature)  # type: ignore\n\n        # Create a shallow copy of the tree_data\n        self.tree_data = copy(tree_data)\n\n        # Note which inputs are required\n        self.message_update = message_update\n        self.environment = environment\n        self.collection_schemas = collection_schemas\n        self.tasks_completed = tasks_completed\n        self.collection_names = collection_names\n        self.reasoning = reasoning\n        self.impossible = impossible\n\n        # == Inputs ==\n\n        # -- User Prompt --\n        user_prompt_desc = (\n            \"The user's original question/prompt that needs to be answered. \"\n            \"This, possibly combined with the conversation history, will be used to determine your current action.\"\n        )\n        user_prompt_prefix = \"${user_prompt}\"\n        user_prompt_field: str = dspy.InputField(\n            prefix=user_prompt_prefix, desc=user_prompt_desc\n        )\n\n        # -- Conversation History --\n        conversation_history_desc = (\n            \"Previous messages between user and assistant in chronological order: \"\n            \"[{'role': 'user'|'assistant', 'content': str}] \"\n            \"Use this to maintain conversation context and avoid repetition.\"\n        )\n        conversation_history_prefix = \"${conversation_history}\"\n        conversation_history_field: list[dict] = dspy.InputField(\n            prefix=conversation_history_prefix, desc=conversation_history_desc\n        )\n\n        # -- Atlas --\n        atlas_desc = (\n            \"Your guide to how you should proceed as an agent in this task. \"\n            \"This is pre-defined by the user.\"\n        )\n        atlas_prefix = \"${atlas}\"\n        atlas_field: Atlas = dspy.InputField(prefix=atlas_prefix, desc=atlas_desc)\n\n        # -- Errors --\n        errors_desc = (\n            \"Any errors that have occurred during the previous attempt at this action. \"\n            \"This is a list of dictionaries, containing details of the error. \"\n            \"Make an attempt at providing different output to avoid this error now. \"\n            \"If this error is repeated, or you judge it to be unsolvable, you can set `impossible` to True\"\n        )\n        errors_prefix = \"${previous_errors}\"\n        errors_field: list[dict] = dspy.InputField(\n            prefix=errors_prefix, desc=errors_desc\n        )\n\n        # -- Add to Signature --\n        extended_signature = signature.prepend(\n            name=\"user_prompt\", field=user_prompt_field, type_=str\n        )\n        extended_signature = extended_signature.append(\n            name=\"conversation_history\",\n            field=conversation_history_field,\n            type_=list[dict],\n        )\n        extended_signature = extended_signature.append(\n            name=\"atlas\", field=atlas_field, type_=Atlas\n        )\n        extended_signature = extended_signature.append(\n            name=\"previous_errors\", field=errors_field, type_=list[dict]\n        )\n\n        # == Optional Inputs / Outputs ==\n\n        # -- Environment Input --\n        if environment:\n            environment_desc = (\n                \"Information gathered from completed tasks. \"\n                \"Empty if no data has been retrieved yet. \"\n                \"Use to determine if more information is needed. \"\n                \"Additionally, use this as a reference to determine if you have already completed a task/what items are already available, to avoid repeating actions. \"\n                \"All items here are already shown to the user, so do not repeat information from these fields unless summarising, providing extra information or otherwise. \"\n                \"E.g., do not list out anything from here, only provide new content to the user.\"\n            )\n            environment_prefix = \"${environment}\"\n            environment_field: dict = dspy.InputField(\n                prefix=environment_prefix, desc=environment_desc\n            )\n            extended_signature = extended_signature.append(\n                name=\"environment\", field=environment_field, type_=dict\n            )\n\n        # -- Collection Schema Input --\n        if collection_schemas:\n            collection_schemas_desc = (\n                \"Metadata about available collections and their schemas: \"\n                \"This is a dictionary with the following fields: \"\n                \"{\\n\"\n                \"    name: collection name,\\n\"\n                \"    length: number of objects in the collection,\\n\"\n                \"    summary: summary of the collection,\\n\"\n                \"    fields: [\\n\"\n                \"        {\\n\"\n                \"            name: field_name,\\n\"\n                \"            groups: a dict with the value and count of each group.\\n\"\n                \"                a comprehensive list of all unique values that exist in the field.\\n\"\n                \"                if this is None, then no relevant groups were found.\\n\"\n                \"                these values are string, but the actual values in the collection are the 'type' of the field.\\n\"\n                \"            mean: mean of the field. if the field is text, this refers to the means length (in tokens) of the texts in this field. if the type is a list, this refers to the mean length of the lists,\\n\"\n                \"            range: minimum and maximum values of the length,\\n\"\n                \"            type: the data type of the field.\\n\"\n                \"        },\\n\"\n                \"        ...\\n\"\n                \"    ]\\n\"\n                \"}\\n\"\n            )\n            collection_schemas_prefix = \"${collection_schemas}\"\n            collection_schemas_field: dict = dspy.InputField(\n                prefix=collection_schemas_prefix, desc=collection_schemas_desc\n            )\n            extended_signature = extended_signature.append(\n                name=\"collection_schemas\", field=collection_schemas_field, type_=dict\n            )\n\n        # -- Tasks Completed Input --\n        if tasks_completed:\n            tasks_completed_desc = (\n                \"Which tasks have been completed in order. \"\n                \"These are numbered so that higher numbers are more recent. \"\n                \"Separated by prompts (so you should identify the prompt you are currently working on to see what tasks have been completed so far) \"\n                \"Also includes reasoning for each task, to continue a decision logic across tasks. \"\n                \"Use this to determine whether future searches, for this prompt are necessary, and what task(s) to choose. \"\n                \"It is IMPORTANT that you separate what actions have been completed for which prompt, so you do not think you have failed an attempt for a different prompt.\"\n            )\n            tasks_completed_prefix = \"${tasks_completed}\"\n            tasks_completed_field: str = dspy.InputField(\n                prefix=tasks_completed_prefix, desc=tasks_completed_desc\n            )\n            extended_signature = extended_signature.append(\n                name=\"tasks_completed\", field=tasks_completed_field, type_=str\n            )\n\n        # -- Impossible Field --\n        if impossible:\n            impossible_desc = (\n                \"Given the actions you have available, and the environment/information. \"\n                \"Is the task impossible to complete? \"\n                \"I.e., do you wish that you had a different task to perform/choose from and hence should return to the base of the decision tree?\"\n                \"Do not base this judgement on the entire prompt, as it is possible that other agents can perform other aspects of the request.\"\n                \"Do not judge impossibility based on if tasks have been completed, only on the current action and environment.\"\n            )\n            impossible_prefix = \"${impossible}\"\n            impossible_field: bool = dspy.OutputField(\n                prefix=impossible_prefix, desc=impossible_desc\n            )\n            extended_signature = extended_signature.prepend(\n                name=\"impossible\", field=impossible_field, type_=bool\n            )\n\n        # -- Message Update Output --\n        if message_update:\n            message_update_desc = (\n                \"Continue your current message to the user \"\n                \"(latest assistant field in conversation history) with ONE concise sentence that: \"\n                \"- Describes NEW technical details about your latest action \"\n                \"- Highlights specific parameters or logic you just applied \"\n                \"- Avoids repeating anything from conversation history \"\n                \"- Speaks directly to them (no 'the user'), gender neutral message \"\n                \"Just provide the new sentence update, not the full message from the conversation history. \"\n                \"Your response should be based on only the part of the user's request that you can work on. \"\n                \"It is possible other agents can perform other aspects of the request, so do not respond as if you cannot complete the entire request.\"\n            )\n\n            message_update_prefix = \"${message_update}\"\n            message_update_field: str = dspy.OutputField(\n                prefix=message_update_prefix, desc=message_update_desc\n            )\n            extended_signature = extended_signature.prepend(\n                name=\"message_update\", field=message_update_field, type_=str\n            )\n\n        # -- Reasoning Field --\n        if reasoning:\n            reasoning_desc = (\n                \"Reasoning: Repeat relevant parts of the any context within your environment, \"\n                \"Evaluate all relevant information from the inputs, including any previous errors if applicable, \"\n                \"use this to think step by step in order to answer the query.\"\n                \"Limit your reasoning to maximum 150 words. Only exceed this if the task is very complex.\"\n            )\n            reasoning_prefix = \"${reasoning}\"\n            reasoning_field: str = dspy.OutputField(\n                prefix=reasoning_prefix, desc=reasoning_desc\n            )\n            extended_signature = extended_signature.prepend(\n                name=\"reasoning\", field=reasoning_field, type_=str\n            )\n\n        # -- Predict --\n        self.predict = dspy.Predict(extended_signature, **config)\n        self.predict.signature.instructions += elysia_meta_prompt  # type: ignore\n\n    def _add_tree_data_inputs(self, kwargs: dict):\n\n        # Add the tree data inputs to the kwargs\n        kwargs[\"user_prompt\"] = self.tree_data.user_prompt\n        kwargs[\"conversation_history\"] = self.tree_data.conversation_history\n        kwargs[\"atlas\"] = self.tree_data.atlas\n        kwargs[\"previous_errors\"] = self.tree_data.get_errors()\n\n        # Add the optional inputs to the kwargs\n        if self.environment:\n            kwargs[\"environment\"] = self.tree_data.environment.environment\n\n        if self.collection_schemas:\n            if self.collection_names != []:\n                kwargs[\"collection_schemas\"] = (\n                    self.tree_data.output_collection_metadata(\n                        collection_names=self.collection_names, with_mappings=False\n                    )\n                )\n            else:\n                kwargs[\"collection_schemas\"] = (\n                    self.tree_data.output_collection_metadata(with_mappings=False)\n                )\n\n        if self.tasks_completed:\n            kwargs[\"tasks_completed\"] = self.tree_data.tasks_completed_string()\n\n        return kwargs\n\n    def forward(self, **kwargs):\n        kwargs = self._add_tree_data_inputs(kwargs)\n        return self.predict(**kwargs)\n\n    async def aforward(self, **kwargs):\n        kwargs = self._add_tree_data_inputs(kwargs)\n        return await self.predict.acall(**kwargs)\n\n    async def aforward_with_feedback_examples(\n        self,\n        feedback_model: str,\n        client_manager: ClientManager,\n        base_lm: dspy.LM,\n        complex_lm: dspy.LM,\n        num_base_lm_examples: int = 3,\n        return_example_uuids: bool = False,\n        **kwargs,\n    ) -&gt; tuple[dspy.Prediction, list[str]] | dspy.Prediction:\n        \"\"\"\n        Use the forward pass of the module with feedback examples.\n        This will first retrieve examples from the feedback collection, and use those as few-shot examples to run the module.\n        It retrieves based from vectorising and searching on the user's prompt, finding similar prompts from the feedback collection.\n        This is an EXPERIMENTAL feature, and may not work as expected.\n\n        If the number of examples is less than `num_base_lm_examples`, the module will use the complex LM.\n        Otherwise, it will use the base LM. This is so that the less accurate, but faster base LM can be used when guidance is available.\n        However, when there are insufficient examples, the complex LM will be used.\n\n        Args:\n            feedback_model (str): The label of the feedback data to use as examples.\n                E.g., \"decision\" is the default name given to examples for the LM in the decision tree.\n                This is used to retrieve the examples from the feedback collection.\n            client_manager (ClientManager): The client manager to use.\n            base_lm (dspy.LM): The base LM to (conditionally) use.\n            complex_lm (dspy.LM): The complex LM to (conditionally) use.\n            num_base_lm_examples (int): The threshold number of examples to use the base LM.\n                When there are fewer examples than this, the complex LM will be used.\n            **kwargs (Any): The keyword arguments to pass to the forward pass.\n                Important: All additional inputs to the DSPy module should be passed here as keyword arguments.\n                Also: Do not include `lm` in the kwargs, as this will be set automatically.\n\n        Returns:\n            (dspy.Prediction): The prediction from the forward pass.\n        \"\"\"\n\n        examples, uuids = await retrieve_feedback(\n            client_manager, self.tree_data.user_prompt, feedback_model, n=10\n        )\n        if len(examples) &gt; 0:\n            optimizer = dspy.LabeledFewShot(k=10)\n            optimized_module = optimizer.compile(self, trainset=examples)\n        else:\n            if return_example_uuids:\n                return (\n                    await self.aforward(lm=complex_lm, **kwargs),\n                    uuids,\n                )\n            else:\n                return await self.aforward(lm=complex_lm, **kwargs)\n\n        # Select the LM to use based on the number of examples\n        if len(examples) &lt; num_base_lm_examples:\n            if return_example_uuids:\n                return (\n                    await optimized_module.aforward(lm=complex_lm, **kwargs),\n                    uuids,\n                )\n            else:\n                return await optimized_module.aforward(lm=complex_lm, **kwargs)\n        else:\n            if return_example_uuids:\n                return (\n                    await optimized_module.aforward(lm=base_lm, **kwargs),\n                    uuids,\n                )\n            else:\n                return await optimized_module.aforward(lm=base_lm, **kwargs)\n</code></pre>"},{"location":"Reference/Util/#elysia.util.elysia_chain_of_thought.ElysiaChainOfThought.__init__","title":"<code>__init__(signature, tree_data, reasoning=True, impossible=True, message_update=True, environment=False, collection_schemas=False, tasks_completed=False, collection_names=[], **config)</code>","text":"<p>Parameters:</p> Name Type Description Default <code>signature</code> <code>Type[Signature]</code> <p>The signature of the module.</p> required <code>tree_data</code> <code>TreeData</code> <p>Required. The tree data from the Elysia decision tree. Used to input the current state of the tree into the prompt. If you are using this module as part of a tool, the <code>tree_data</code> is an input to the tool call.</p> required <code>reasoning</code> <code>bool</code> <p>Whether to include a reasoning input (chain of thought).</p> <code>True</code> <code>impossible</code> <code>bool</code> <p>Whether to include a boolean flag indicating whether the task is impossible. This is useful for stopping the tree from continuing and returning to the base of the decision tree. For example, the model judges a query impossible to execute, or the user has not provided enough information.</p> <code>True</code> <code>message_update</code> <code>bool</code> <p>Whether to include a message update input. If True, the LLM output will include a brief 'update' message to the user. This describes the current action the LLM is performing. Designed to increase interactivity and provide the user with information before the final output.</p> <code>True</code> <code>environment</code> <code>bool</code> <p>Whether to include an environment input. If True, the module will include the currently stored data from previous tasks and actions into the prompt. This is useful so that the LLM knows what has already been done, and can avoid repeating actions. Or to use information from the environment to perform the new action.</p> <code>False</code> <code>collection_schemas</code> <code>bool</code> <p>Whether to include a collection schema input. If True, the module will include the preprocessed collection schemas in the prompt input. This is useful so that the LLM knows the structure of the collections, if querying or similar. Use this sparingly, as it will use a large amount of tokens. You can specify <code>collection_names</code> to only include certain collections in this schema.</p> <code>False</code> <code>tasks_completed</code> <code>bool</code> <p>Whether to include a tasks completed input. If True, the module will include the list of tasks completed input. This is a nicely formatted list of the tasks that have been completed, with the reasoning for each task. This is used so that the LLM has a 'stream of consciousness' of what has already been done, as well as to stop it from repeating actions. Other information is included in the <code>tasks_completed</code> field that format outputs from previous tasks. This is useful for continuing a decision logic across tasks, or to reinforce key information.</p> <code>False</code> <code>collection_names</code> <code>list[str]</code> <p>A list of collection names to include in the prompt. If provided, this will modify the collection schema input to only include the collections in this list. This is useful if you only want to include certain collections in the prompt. And to reduce token usage.</p> <code>[]</code> <code>**config</code> <code>Any</code> <p>The DSPy configuration for the module.</p> <code>{}</code> Source code in <code>elysia/util/elysia_chain_of_thought.py</code> <pre><code>def __init__(\n    self,\n    signature: Type[Signature],\n    tree_data: TreeData,\n    reasoning: bool = True,\n    impossible: bool = True,\n    message_update: bool = True,\n    environment: bool = False,\n    collection_schemas: bool = False,\n    tasks_completed: bool = False,\n    collection_names: list[str] = [],\n    **config,\n):\n    \"\"\"\n    Args:\n        signature (Type[dspy.Signature]): The signature of the module.\n        tree_data (TreeData): Required. The tree data from the Elysia decision tree.\n            Used to input the current state of the tree into the prompt.\n            If you are using this module as part of a tool, the `tree_data` is an input to the tool call.\n        reasoning (bool): Whether to include a reasoning input (chain of thought).\n        impossible (bool): Whether to include a boolean flag indicating whether the task is impossible.\n            This is useful for stopping the tree from continuing and returning to the base of the decision tree.\n            For example, the model judges a query impossible to execute, or the user has not provided enough information.\n        message_update (bool): Whether to include a message update input.\n            If True, the LLM output will include a brief 'update' message to the user.\n            This describes the current action the LLM is performing.\n            Designed to increase interactivity and provide the user with information before the final output.\n        environment (bool): Whether to include an environment input.\n            If True, the module will include the currently stored data from previous tasks and actions into the prompt.\n            This is useful so that the LLM knows what has already been done, and can avoid repeating actions.\n            Or to use information from the environment to perform the new action.\n        collection_schemas (bool): Whether to include a collection schema input.\n            If True, the module will include the preprocessed collection schemas in the prompt input.\n            This is useful so that the LLM knows the structure of the collections, if querying or similar.\n            Use this sparingly, as it will use a large amount of tokens.\n            You can specify `collection_names` to only include certain collections in this schema.\n        tasks_completed (bool): Whether to include a tasks completed input.\n            If True, the module will include the list of tasks completed input.\n            This is a nicely formatted list of the tasks that have been completed, with the reasoning for each task.\n            This is used so that the LLM has a 'stream of consciousness' of what has already been done,\n            as well as to stop it from repeating actions.\n            Other information is included in the `tasks_completed` field that format outputs from previous tasks.\n            This is useful for continuing a decision logic across tasks, or to reinforce key information.\n        collection_names (list[str]): A list of collection names to include in the prompt.\n            If provided, this will modify the collection schema input to only include the collections in this list.\n            This is useful if you only want to include certain collections in the prompt.\n            And to reduce token usage.\n        **config (Any): The DSPy configuration for the module.\n    \"\"\"\n\n    super().__init__()\n\n    signature = ensure_signature(signature)  # type: ignore\n\n    # Create a shallow copy of the tree_data\n    self.tree_data = copy(tree_data)\n\n    # Note which inputs are required\n    self.message_update = message_update\n    self.environment = environment\n    self.collection_schemas = collection_schemas\n    self.tasks_completed = tasks_completed\n    self.collection_names = collection_names\n    self.reasoning = reasoning\n    self.impossible = impossible\n\n    # == Inputs ==\n\n    # -- User Prompt --\n    user_prompt_desc = (\n        \"The user's original question/prompt that needs to be answered. \"\n        \"This, possibly combined with the conversation history, will be used to determine your current action.\"\n    )\n    user_prompt_prefix = \"${user_prompt}\"\n    user_prompt_field: str = dspy.InputField(\n        prefix=user_prompt_prefix, desc=user_prompt_desc\n    )\n\n    # -- Conversation History --\n    conversation_history_desc = (\n        \"Previous messages between user and assistant in chronological order: \"\n        \"[{'role': 'user'|'assistant', 'content': str}] \"\n        \"Use this to maintain conversation context and avoid repetition.\"\n    )\n    conversation_history_prefix = \"${conversation_history}\"\n    conversation_history_field: list[dict] = dspy.InputField(\n        prefix=conversation_history_prefix, desc=conversation_history_desc\n    )\n\n    # -- Atlas --\n    atlas_desc = (\n        \"Your guide to how you should proceed as an agent in this task. \"\n        \"This is pre-defined by the user.\"\n    )\n    atlas_prefix = \"${atlas}\"\n    atlas_field: Atlas = dspy.InputField(prefix=atlas_prefix, desc=atlas_desc)\n\n    # -- Errors --\n    errors_desc = (\n        \"Any errors that have occurred during the previous attempt at this action. \"\n        \"This is a list of dictionaries, containing details of the error. \"\n        \"Make an attempt at providing different output to avoid this error now. \"\n        \"If this error is repeated, or you judge it to be unsolvable, you can set `impossible` to True\"\n    )\n    errors_prefix = \"${previous_errors}\"\n    errors_field: list[dict] = dspy.InputField(\n        prefix=errors_prefix, desc=errors_desc\n    )\n\n    # -- Add to Signature --\n    extended_signature = signature.prepend(\n        name=\"user_prompt\", field=user_prompt_field, type_=str\n    )\n    extended_signature = extended_signature.append(\n        name=\"conversation_history\",\n        field=conversation_history_field,\n        type_=list[dict],\n    )\n    extended_signature = extended_signature.append(\n        name=\"atlas\", field=atlas_field, type_=Atlas\n    )\n    extended_signature = extended_signature.append(\n        name=\"previous_errors\", field=errors_field, type_=list[dict]\n    )\n\n    # == Optional Inputs / Outputs ==\n\n    # -- Environment Input --\n    if environment:\n        environment_desc = (\n            \"Information gathered from completed tasks. \"\n            \"Empty if no data has been retrieved yet. \"\n            \"Use to determine if more information is needed. \"\n            \"Additionally, use this as a reference to determine if you have already completed a task/what items are already available, to avoid repeating actions. \"\n            \"All items here are already shown to the user, so do not repeat information from these fields unless summarising, providing extra information or otherwise. \"\n            \"E.g., do not list out anything from here, only provide new content to the user.\"\n        )\n        environment_prefix = \"${environment}\"\n        environment_field: dict = dspy.InputField(\n            prefix=environment_prefix, desc=environment_desc\n        )\n        extended_signature = extended_signature.append(\n            name=\"environment\", field=environment_field, type_=dict\n        )\n\n    # -- Collection Schema Input --\n    if collection_schemas:\n        collection_schemas_desc = (\n            \"Metadata about available collections and their schemas: \"\n            \"This is a dictionary with the following fields: \"\n            \"{\\n\"\n            \"    name: collection name,\\n\"\n            \"    length: number of objects in the collection,\\n\"\n            \"    summary: summary of the collection,\\n\"\n            \"    fields: [\\n\"\n            \"        {\\n\"\n            \"            name: field_name,\\n\"\n            \"            groups: a dict with the value and count of each group.\\n\"\n            \"                a comprehensive list of all unique values that exist in the field.\\n\"\n            \"                if this is None, then no relevant groups were found.\\n\"\n            \"                these values are string, but the actual values in the collection are the 'type' of the field.\\n\"\n            \"            mean: mean of the field. if the field is text, this refers to the means length (in tokens) of the texts in this field. if the type is a list, this refers to the mean length of the lists,\\n\"\n            \"            range: minimum and maximum values of the length,\\n\"\n            \"            type: the data type of the field.\\n\"\n            \"        },\\n\"\n            \"        ...\\n\"\n            \"    ]\\n\"\n            \"}\\n\"\n        )\n        collection_schemas_prefix = \"${collection_schemas}\"\n        collection_schemas_field: dict = dspy.InputField(\n            prefix=collection_schemas_prefix, desc=collection_schemas_desc\n        )\n        extended_signature = extended_signature.append(\n            name=\"collection_schemas\", field=collection_schemas_field, type_=dict\n        )\n\n    # -- Tasks Completed Input --\n    if tasks_completed:\n        tasks_completed_desc = (\n            \"Which tasks have been completed in order. \"\n            \"These are numbered so that higher numbers are more recent. \"\n            \"Separated by prompts (so you should identify the prompt you are currently working on to see what tasks have been completed so far) \"\n            \"Also includes reasoning for each task, to continue a decision logic across tasks. \"\n            \"Use this to determine whether future searches, for this prompt are necessary, and what task(s) to choose. \"\n            \"It is IMPORTANT that you separate what actions have been completed for which prompt, so you do not think you have failed an attempt for a different prompt.\"\n        )\n        tasks_completed_prefix = \"${tasks_completed}\"\n        tasks_completed_field: str = dspy.InputField(\n            prefix=tasks_completed_prefix, desc=tasks_completed_desc\n        )\n        extended_signature = extended_signature.append(\n            name=\"tasks_completed\", field=tasks_completed_field, type_=str\n        )\n\n    # -- Impossible Field --\n    if impossible:\n        impossible_desc = (\n            \"Given the actions you have available, and the environment/information. \"\n            \"Is the task impossible to complete? \"\n            \"I.e., do you wish that you had a different task to perform/choose from and hence should return to the base of the decision tree?\"\n            \"Do not base this judgement on the entire prompt, as it is possible that other agents can perform other aspects of the request.\"\n            \"Do not judge impossibility based on if tasks have been completed, only on the current action and environment.\"\n        )\n        impossible_prefix = \"${impossible}\"\n        impossible_field: bool = dspy.OutputField(\n            prefix=impossible_prefix, desc=impossible_desc\n        )\n        extended_signature = extended_signature.prepend(\n            name=\"impossible\", field=impossible_field, type_=bool\n        )\n\n    # -- Message Update Output --\n    if message_update:\n        message_update_desc = (\n            \"Continue your current message to the user \"\n            \"(latest assistant field in conversation history) with ONE concise sentence that: \"\n            \"- Describes NEW technical details about your latest action \"\n            \"- Highlights specific parameters or logic you just applied \"\n            \"- Avoids repeating anything from conversation history \"\n            \"- Speaks directly to them (no 'the user'), gender neutral message \"\n            \"Just provide the new sentence update, not the full message from the conversation history. \"\n            \"Your response should be based on only the part of the user's request that you can work on. \"\n            \"It is possible other agents can perform other aspects of the request, so do not respond as if you cannot complete the entire request.\"\n        )\n\n        message_update_prefix = \"${message_update}\"\n        message_update_field: str = dspy.OutputField(\n            prefix=message_update_prefix, desc=message_update_desc\n        )\n        extended_signature = extended_signature.prepend(\n            name=\"message_update\", field=message_update_field, type_=str\n        )\n\n    # -- Reasoning Field --\n    if reasoning:\n        reasoning_desc = (\n            \"Reasoning: Repeat relevant parts of the any context within your environment, \"\n            \"Evaluate all relevant information from the inputs, including any previous errors if applicable, \"\n            \"use this to think step by step in order to answer the query.\"\n            \"Limit your reasoning to maximum 150 words. Only exceed this if the task is very complex.\"\n        )\n        reasoning_prefix = \"${reasoning}\"\n        reasoning_field: str = dspy.OutputField(\n            prefix=reasoning_prefix, desc=reasoning_desc\n        )\n        extended_signature = extended_signature.prepend(\n            name=\"reasoning\", field=reasoning_field, type_=str\n        )\n\n    # -- Predict --\n    self.predict = dspy.Predict(extended_signature, **config)\n    self.predict.signature.instructions += elysia_meta_prompt  # type: ignore\n</code></pre>"},{"location":"Reference/Util/#elysia.util.elysia_chain_of_thought.ElysiaChainOfThought.aforward_with_feedback_examples","title":"<code>aforward_with_feedback_examples(feedback_model, client_manager, base_lm, complex_lm, num_base_lm_examples=3, return_example_uuids=False, **kwargs)</code>  <code>async</code>","text":"<p>Use the forward pass of the module with feedback examples. This will first retrieve examples from the feedback collection, and use those as few-shot examples to run the module. It retrieves based from vectorising and searching on the user's prompt, finding similar prompts from the feedback collection. This is an EXPERIMENTAL feature, and may not work as expected.</p> <p>If the number of examples is less than <code>num_base_lm_examples</code>, the module will use the complex LM. Otherwise, it will use the base LM. This is so that the less accurate, but faster base LM can be used when guidance is available. However, when there are insufficient examples, the complex LM will be used.</p> <p>Parameters:</p> Name Type Description Default <code>feedback_model</code> <code>str</code> <p>The label of the feedback data to use as examples. E.g., \"decision\" is the default name given to examples for the LM in the decision tree. This is used to retrieve the examples from the feedback collection.</p> required <code>client_manager</code> <code>ClientManager</code> <p>The client manager to use.</p> required <code>base_lm</code> <code>LM</code> <p>The base LM to (conditionally) use.</p> required <code>complex_lm</code> <code>LM</code> <p>The complex LM to (conditionally) use.</p> required <code>num_base_lm_examples</code> <code>int</code> <p>The threshold number of examples to use the base LM. When there are fewer examples than this, the complex LM will be used.</p> <code>3</code> <code>**kwargs</code> <code>Any</code> <p>The keyword arguments to pass to the forward pass. Important: All additional inputs to the DSPy module should be passed here as keyword arguments. Also: Do not include <code>lm</code> in the kwargs, as this will be set automatically.</p> <code>{}</code> <p>Returns:</p> Type Description <code>Prediction</code> <p>The prediction from the forward pass.</p> Source code in <code>elysia/util/elysia_chain_of_thought.py</code> <pre><code>async def aforward_with_feedback_examples(\n    self,\n    feedback_model: str,\n    client_manager: ClientManager,\n    base_lm: dspy.LM,\n    complex_lm: dspy.LM,\n    num_base_lm_examples: int = 3,\n    return_example_uuids: bool = False,\n    **kwargs,\n) -&gt; tuple[dspy.Prediction, list[str]] | dspy.Prediction:\n    \"\"\"\n    Use the forward pass of the module with feedback examples.\n    This will first retrieve examples from the feedback collection, and use those as few-shot examples to run the module.\n    It retrieves based from vectorising and searching on the user's prompt, finding similar prompts from the feedback collection.\n    This is an EXPERIMENTAL feature, and may not work as expected.\n\n    If the number of examples is less than `num_base_lm_examples`, the module will use the complex LM.\n    Otherwise, it will use the base LM. This is so that the less accurate, but faster base LM can be used when guidance is available.\n    However, when there are insufficient examples, the complex LM will be used.\n\n    Args:\n        feedback_model (str): The label of the feedback data to use as examples.\n            E.g., \"decision\" is the default name given to examples for the LM in the decision tree.\n            This is used to retrieve the examples from the feedback collection.\n        client_manager (ClientManager): The client manager to use.\n        base_lm (dspy.LM): The base LM to (conditionally) use.\n        complex_lm (dspy.LM): The complex LM to (conditionally) use.\n        num_base_lm_examples (int): The threshold number of examples to use the base LM.\n            When there are fewer examples than this, the complex LM will be used.\n        **kwargs (Any): The keyword arguments to pass to the forward pass.\n            Important: All additional inputs to the DSPy module should be passed here as keyword arguments.\n            Also: Do not include `lm` in the kwargs, as this will be set automatically.\n\n    Returns:\n        (dspy.Prediction): The prediction from the forward pass.\n    \"\"\"\n\n    examples, uuids = await retrieve_feedback(\n        client_manager, self.tree_data.user_prompt, feedback_model, n=10\n    )\n    if len(examples) &gt; 0:\n        optimizer = dspy.LabeledFewShot(k=10)\n        optimized_module = optimizer.compile(self, trainset=examples)\n    else:\n        if return_example_uuids:\n            return (\n                await self.aforward(lm=complex_lm, **kwargs),\n                uuids,\n            )\n        else:\n            return await self.aforward(lm=complex_lm, **kwargs)\n\n    # Select the LM to use based on the number of examples\n    if len(examples) &lt; num_base_lm_examples:\n        if return_example_uuids:\n            return (\n                await optimized_module.aforward(lm=complex_lm, **kwargs),\n                uuids,\n            )\n        else:\n            return await optimized_module.aforward(lm=complex_lm, **kwargs)\n    else:\n        if return_example_uuids:\n            return (\n                await optimized_module.aforward(lm=base_lm, **kwargs),\n                uuids,\n            )\n        else:\n            return await optimized_module.aforward(lm=base_lm, **kwargs)\n</code></pre>"}]}